{"/home/travis/build/npmtest/node-npmtest-jsonld/test.js":"/* istanbul instrument in package npmtest_jsonld */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        switch (local.modeJs) {\n        // re-init local from window.local\n        case 'browser':\n            local = local.global.utility2.objectSetDefault(\n                local.global.utility2_rollup || local.global.local,\n                local.global.utility2\n            );\n            break;\n        // re-init local from example.js\n        case 'node':\n            local = (local.global.utility2_rollup || require('utility2'))\n                .requireExampleJsFromReadme();\n            break;\n        }\n        // export local\n        local.global.local = local;\n    }());\n\n\n\n    // run shared js-env code - function\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - function\n    case 'browser':\n        break;\n\n\n\n    // run node js-env code - function\n    case 'node':\n        break;\n    }\n\n\n\n    // run shared js-env code - post-init\n    (function () {\n        return;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // run browser js-env code - post-init\n    case 'browser':\n        local.testCase_browser_nullCase = local.testCase_browser_nullCase || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test browsers's null-case handling-behavior-behavior\n         */\n            onError(null, options);\n        };\n\n        // run tests\n        local.nop(local.modeTest &&\n            document.querySelector('#testRunButton1') &&\n            document.querySelector('#testRunButton1').click());\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        local.testCase_buildApidoc_default = local.testCase_buildApidoc_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApidoc's default handling-behavior-behavior\n         */\n            options = { modulePathList: module.paths };\n            local.buildApidoc(options, onError);\n        };\n\n        local.testCase_buildApp_default = local.testCase_buildApp_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildApp's default handling-behavior-behavior\n         */\n            local.testCase_buildReadme_default(options, local.onErrorThrow);\n            local.testCase_buildLib_default(options, local.onErrorThrow);\n            local.testCase_buildTest_default(options, local.onErrorThrow);\n            local.testCase_buildCustomOrg_default(options, local.onErrorThrow);\n            options = [];\n            local.buildApp(options, onError);\n        };\n\n        local.testCase_buildCustomOrg_default = local.testCase_buildCustomOrg_default ||\n            function (options, onError) {\n            /*\n             * this function will test buildCustomOrg's default handling-behavior\n             */\n                options = {};\n                local.buildCustomOrg(options, onError);\n            };\n\n        local.testCase_buildLib_default = local.testCase_buildLib_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildLib's default handling-behavior\n         */\n            options = {};\n            local.buildLib(options, onError);\n        };\n\n        local.testCase_buildReadme_default = local.testCase_buildReadme_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildReadme's default handling-behavior-behavior\n         */\n            options = {};\n            local.buildReadme(options, onError);\n        };\n\n        local.testCase_buildTest_default = local.testCase_buildTest_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test buildTest's default handling-behavior\n         */\n            options = {};\n            local.buildTest(options, onError);\n        };\n\n        local.testCase_webpage_default = local.testCase_webpage_default || function (\n            options,\n            onError\n        ) {\n        /*\n         * this function will test webpage's default handling-behavior\n         */\n            options = { modeCoverageMerge: true, url: local.serverLocalHost + '?modeTest=1' };\n            local.browserTest(options, onError);\n        };\n\n        // run test-server\n        local.testRunServer(local);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-jsonld/lib.npmtest_jsonld.js":"/* istanbul instrument in package npmtest_jsonld */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || local;\n        // init lib\n        local.local = local.npmtest_jsonld = local;\n        // init exports\n        if (local.modeJs === 'browser') {\n            local.global.utility2_npmtest_jsonld = local;\n        } else {\n            module.exports = local;\n            module.exports.__dirname = __dirname;\n            module.exports.module = module;\n        }\n    }());\n}());\n","/home/travis/build/npmtest/node-npmtest-jsonld/example.js":"/*\nexample.js\n\nquickstart example\n\ninstruction\n    1. save this script as example.js\n    2. run the shell command:\n        $ npm install npmtest-jsonld && PORT=8081 node example.js\n    3. play with the browser-demo on http://127.0.0.1:8081\n*/\n\n\n\n/* istanbul instrument in package npmtest_jsonld */\n/*jslint\n    bitwise: true,\n    browser: true,\n    maxerr: 8,\n    maxlen: 96,\n    node: true,\n    nomen: true,\n    regexp: true,\n    stupid: true\n*/\n(function () {\n    'use strict';\n    var local;\n\n\n\n    // run shared js-env code - pre-init\n    (function () {\n        // init local\n        local = {};\n        // init modeJs\n        local.modeJs = (function () {\n            try {\n                return typeof navigator.userAgent === 'string' &&\n                    typeof document.querySelector('body') === 'object' &&\n                    typeof XMLHttpRequest.prototype.open === 'function' &&\n                    'browser';\n            } catch (errorCaughtBrowser) {\n                return module.exports &&\n                    typeof process.versions.node === 'string' &&\n                    typeof require('http').createServer === 'function' &&\n                    'node';\n            }\n        }());\n        // init global\n        local.global = local.modeJs === 'browser'\n            ? window\n            : global;\n        // init utility2_rollup\n        local = local.global.utility2_rollup || (local.modeJs === 'browser'\n            ? local.global.utility2_npmtest_jsonld\n            : global.utility2_moduleExports);\n        // export local\n        local.global.local = local;\n    }());\n    switch (local.modeJs) {\n\n\n\n    // post-init\n    // run browser js-env code - post-init\n    /* istanbul ignore next */\n    case 'browser':\n        local.testRunBrowser = function (event) {\n            if (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('onreset'))) {\n                // reset output\n                Array.from(\n                    document.querySelectorAll('body > .resettable')\n                ).forEach(function (element) {\n                    switch (element.tagName) {\n                    case 'INPUT':\n                    case 'TEXTAREA':\n                        element.value = '';\n                        break;\n                    default:\n                        element.textContent = '';\n                    }\n                });\n            }\n            switch (event && event.currentTarget && event.currentTarget.id) {\n            case 'testRunButton1':\n                // show tests\n                if (document.querySelector('#testReportDiv1').style.display === 'none') {\n                    document.querySelector('#testReportDiv1').style.display = 'block';\n                    document.querySelector('#testRunButton1').textContent =\n                        'hide internal test';\n                    local.modeTest = true;\n                    local.testRunDefault(local);\n                // hide tests\n                } else {\n                    document.querySelector('#testReportDiv1').style.display = 'none';\n                    document.querySelector('#testRunButton1').textContent = 'run internal test';\n                }\n                break;\n            // custom-case\n            default:\n                break;\n            }\n            if (document.querySelector('#inputTextareaEval1') && (!event || (event &&\n                    event.currentTarget &&\n                    event.currentTarget.className &&\n                    event.currentTarget.className.includes &&\n                    event.currentTarget.className.includes('oneval')))) {\n                // try to eval input-code\n                try {\n                    /*jslint evil: true*/\n                    eval(document.querySelector('#inputTextareaEval1').value);\n                } catch (errorCaught) {\n                    console.error(errorCaught);\n                }\n            }\n        };\n        // log stderr and stdout to #outputTextareaStdout1\n        ['error', 'log'].forEach(function (key) {\n            console[key + '_original'] = console[key];\n            console[key] = function () {\n                var element;\n                console[key + '_original'].apply(console, arguments);\n                element = document.querySelector('#outputTextareaStdout1');\n                if (!element) {\n                    return;\n                }\n                // append text to #outputTextareaStdout1\n                element.value += Array.from(arguments).map(function (arg) {\n                    return typeof arg === 'string'\n                        ? arg\n                        : JSON.stringify(arg, null, 4);\n                }).join(' ') + '\\n';\n                // scroll textarea to bottom\n                element.scrollTop = element.scrollHeight;\n            };\n        });\n        // init event-handling\n        ['change', 'click', 'keyup'].forEach(function (event) {\n            Array.from(document.querySelectorAll('.on' + event)).forEach(function (element) {\n                element.addEventListener(event, local.testRunBrowser);\n            });\n        });\n        // run tests\n        local.testRunBrowser();\n        break;\n\n\n\n    // run node js-env code - post-init\n    /* istanbul ignore next */\n    case 'node':\n        // export local\n        module.exports = local;\n        // require modules\n        local.fs = require('fs');\n        local.http = require('http');\n        local.url = require('url');\n        // init assets\n        local.assetsDict = local.assetsDict || {};\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.index.template.html'] = '\\\n<!doctype html>\\n\\\n<html lang=\"en\">\\n\\\n<head>\\n\\\n<meta charset=\"UTF-8\">\\n\\\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\\n\\\n<title>{{env.npm_package_name}} (v{{env.npm_package_version}})</title>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n    box-sizing: false,\\n\\\n    universal-selector: false\\n\\\n*/\\n\\\n* {\\n\\\n    box-sizing: border-box;\\n\\\n}\\n\\\nbody {\\n\\\n    background: #dde;\\n\\\n    font-family: Arial, Helvetica, sans-serif;\\n\\\n    margin: 2rem;\\n\\\n}\\n\\\nbody > * {\\n\\\n    margin-bottom: 1rem;\\n\\\n}\\n\\\n.utility2FooterDiv {\\n\\\n    margin-top: 20px;\\n\\\n    text-align: center;\\n\\\n}\\n\\\n</style>\\n\\\n<style>\\n\\\n/*csslint\\n\\\n*/\\n\\\ntextarea {\\n\\\n    font-family: monospace;\\n\\\n    height: 10rem;\\n\\\n    width: 100%;\\n\\\n}\\n\\\ntextarea[readonly] {\\n\\\n    background: #ddd;\\n\\\n}\\n\\\n</style>\\n\\\n</head>\\n\\\n<body>\\n\\\n<!-- utility2-comment\\n\\\n<div id=\"ajaxProgressDiv1\" style=\"background: #d00; height: 2px; left: 0; margin: 0; padding: 0; position: fixed; top: 0; transition: background 0.5s, width 1.5s; width: 25%;\"></div>\\n\\\nutility2-comment -->\\n\\\n<h1>\\n\\\n<!-- utility2-comment\\n\\\n    <a\\n\\\n        {{#if env.npm_package_homepage}}\\n\\\n        href=\"{{env.npm_package_homepage}}\"\\n\\\n        {{/if env.npm_package_homepage}}\\n\\\n        target=\"_blank\"\\n\\\n    >\\n\\\nutility2-comment -->\\n\\\n        {{env.npm_package_name}} (v{{env.npm_package_version}})\\n\\\n<!-- utility2-comment\\n\\\n    </a>\\n\\\nutility2-comment -->\\n\\\n</h1>\\n\\\n<h3>{{env.npm_package_description}}</h3>\\n\\\n<!-- utility2-comment\\n\\\n<h4><a download href=\"assets.app.js\">download standalone app</a></h4>\\n\\\n<button class=\"onclick onreset\" id=\"testRunButton1\">run internal test</button><br>\\n\\\n<div id=\"testReportDiv1\" style=\"display: none;\"></div>\\n\\\nutility2-comment -->\\n\\\n\\n\\\n\\n\\\n\\n\\\n<label>stderr and stdout</label>\\n\\\n<textarea class=\"resettable\" id=\"outputTextareaStdout1\" readonly></textarea>\\n\\\n<!-- utility2-comment\\n\\\n{{#if isRollup}}\\n\\\n<script src=\"assets.app.js\"></script>\\n\\\n{{#unless isRollup}}\\n\\\nutility2-comment -->\\n\\\n<script src=\"assets.utility2.rollup.js\"></script>\\n\\\n<script src=\"jsonp.utility2._stateInit?callback=window.utility2._stateInit\"></script>\\n\\\n<script src=\"assets.npmtest_jsonld.rollup.js\"></script>\\n\\\n<script src=\"assets.example.js\"></script>\\n\\\n<script src=\"assets.test.js\"></script>\\n\\\n<!-- utility2-comment\\n\\\n{{/if isRollup}}\\n\\\nutility2-comment -->\\n\\\n<div class=\"utility2FooterDiv\">\\n\\\n    [ this app was created with\\n\\\n    <a href=\"https://github.com/kaizhu256/node-utility2\" target=\"_blank\">utility2</a>\\n\\\n    ]\\n\\\n</div>\\n\\\n</body>\\n\\\n</html>\\n\\\n';\n        /* jslint-ignore-end */\n        if (local.templateRender) {\n            local.assetsDict['/'] = local.templateRender(\n                local.assetsDict['/assets.index.template.html'],\n                {\n                    env: local.objectSetDefault(local.env, {\n                        npm_package_description: 'the greatest app in the world!',\n                        npm_package_name: 'my-app',\n                        npm_package_nameAlias: 'my_app',\n                        npm_package_version: '0.0.1'\n                    })\n                }\n            );\n        } else {\n            local.assetsDict['/'] = local.assetsDict['/assets.index.template.html']\n                .replace((/\\{\\{env\\.(\\w+?)\\}\\}/g), function (match0, match1) {\n                    // jslint-hack\n                    String(match0);\n                    switch (match1) {\n                    case 'npm_package_description':\n                        return 'the greatest app in the world!';\n                    case 'npm_package_name':\n                        return 'my-app';\n                    case 'npm_package_nameAlias':\n                        return 'my_app';\n                    case 'npm_package_version':\n                        return '0.0.1';\n                    }\n                });\n        }\n        // run the cli\n        if (local.global.utility2_rollup || module !== require.main) {\n            break;\n        }\n        local.assetsDict['/assets.example.js'] =\n            local.assetsDict['/assets.example.js'] ||\n            local.fs.readFileSync(__filename, 'utf8');\n        // bug-workaround - long $npm_package_buildCustomOrg\n        /* jslint-ignore-begin */\n        local.assetsDict['/assets.npmtest_jsonld.rollup.js'] =\n            local.assetsDict['/assets.npmtest_jsonld.rollup.js'] ||\n            local.fs.readFileSync(\n                local.npmtest_jsonld.__dirname + '/lib.npmtest_jsonld.js',\n                'utf8'\n            ).replace((/^#!/), '//');\n        /* jslint-ignore-end */\n        local.assetsDict['/favicon.ico'] = local.assetsDict['/favicon.ico'] || '';\n        // if $npm_config_timeout_exit exists,\n        // then exit this process after $npm_config_timeout_exit ms\n        if (Number(process.env.npm_config_timeout_exit)) {\n            setTimeout(process.exit, Number(process.env.npm_config_timeout_exit));\n        }\n        // start server\n        if (local.global.utility2_serverHttp1) {\n            break;\n        }\n        process.env.PORT = process.env.PORT || '8081';\n        console.error('server starting on port ' + process.env.PORT);\n        local.http.createServer(function (request, response) {\n            request.urlParsed = local.url.parse(request.url);\n            if (local.assetsDict[request.urlParsed.pathname] !== undefined) {\n                response.end(local.assetsDict[request.urlParsed.pathname]);\n                return;\n            }\n            response.statusCode = 404;\n            response.end();\n        }).listen(process.env.PORT);\n        break;\n    }\n}());\n","/home/travis/build/npmtest/node-npmtest-jsonld/node_modules/jsonld/js/jsonld.js":"/**\n * A JavaScript implementation of the JSON-LD API.\n *\n * @author Dave Longley\n *\n * @license BSD 3-Clause License\n * Copyright (c) 2011-2015 Digital Bazaar, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * Neither the name of the Digital Bazaar, Inc. nor the names of its\n * contributors may be used to endorse or promote products derived from\n * this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n(function() {\n\n// determine if in-browser or using node.js\nvar _nodejs = (\n  typeof process !== 'undefined' && process.versions && process.versions.node);\nvar _browser = !_nodejs &&\n  (typeof window !== 'undefined' || typeof self !== 'undefined');\nif(_browser) {\n  if(typeof global === 'undefined') {\n    if(typeof window !== 'undefined') {\n      global = window;\n    } else if(typeof self !== 'undefined') {\n      global = self;\n    } else if(typeof $ !== 'undefined') {\n      global = $;\n    }\n  }\n}\n\n// attaches jsonld API to the given object\nvar wrapper = function(jsonld) {\n\n/* Core API */\n\n/**\n * Performs JSON-LD compaction.\n *\n * @param input the JSON-LD input to compact.\n * @param ctx the context to compact with.\n * @param [options] options to use:\n *          [base] the base IRI to use.\n *          [compactArrays] true to compact arrays to single values when\n *            appropriate, false not to (default: true).\n *          [graph] true to always output a top-level graph (default: false).\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, compacted, ctx) called once the operation completes.\n */\njsonld.compact = function(input, ctx, options, callback) {\n  if(arguments.length < 2) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not compact, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  if(ctx === null) {\n    return jsonld.nextTick(function() {\n      callback(new JsonLdError(\n        'The compaction context must not be null.',\n        'jsonld.CompactError', {code: 'invalid local context'}));\n    });\n  }\n\n  // nothing to compact\n  if(input === null) {\n    return jsonld.nextTick(function() {\n      callback(null, null);\n    });\n  }\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('compactArrays' in options)) {\n    options.compactArrays = true;\n  }\n  if(!('graph' in options)) {\n    options.graph = false;\n  }\n  if(!('skipExpansion' in options)) {\n    options.skipExpansion = false;\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n  if(!('link' in options)) {\n    options.link = false;\n  }\n  if(options.link) {\n    // force skip expansion when linking, \"link\" is not part of the public\n    // API, it should only be called from framing\n    options.skipExpansion = true;\n  }\n\n  var expand = function(input, options, callback) {\n    if(options.skipExpansion) {\n      return jsonld.nextTick(function() {\n        callback(null, input);\n      });\n    }\n    jsonld.expand(input, options, callback);\n  };\n\n  // expand input then do compaction\n  expand(input, options, function(err, expanded) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before compaction.',\n        'jsonld.CompactError', {cause: err}));\n    }\n\n    // process context\n    var activeCtx = _getInitialContext(options);\n    jsonld.processContext(activeCtx, ctx, options, function(err, activeCtx) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not process context before compaction.',\n          'jsonld.CompactError', {cause: err}));\n      }\n\n      var compacted;\n      try {\n        // do compaction\n        compacted = new Processor().compact(activeCtx, null, expanded, options);\n      } catch(ex) {\n        return callback(ex);\n      }\n\n      cleanup(null, compacted, activeCtx, options);\n    });\n  });\n\n  // performs clean up after compaction\n  function cleanup(err, compacted, activeCtx, options) {\n    if(err) {\n      return callback(err);\n    }\n\n    if(options.compactArrays && !options.graph && _isArray(compacted)) {\n      if(compacted.length === 1) {\n        // simplify to a single item\n        compacted = compacted[0];\n      } else if(compacted.length === 0) {\n        // simplify to an empty object\n        compacted = {};\n      }\n    } else if(options.graph && _isObject(compacted)) {\n      // always use array if graph option is on\n      compacted = [compacted];\n    }\n\n    // follow @context key\n    if(_isObject(ctx) && '@context' in ctx) {\n      ctx = ctx['@context'];\n    }\n\n    // build output context\n    ctx = _clone(ctx);\n    if(!_isArray(ctx)) {\n      ctx = [ctx];\n    }\n    // remove empty contexts\n    var tmp = ctx;\n    ctx = [];\n    for(var i = 0; i < tmp.length; ++i) {\n      if(!_isObject(tmp[i]) || Object.keys(tmp[i]).length > 0) {\n        ctx.push(tmp[i]);\n      }\n    }\n\n    // remove array if only one context\n    var hasContext = (ctx.length > 0);\n    if(ctx.length === 1) {\n      ctx = ctx[0];\n    }\n\n    // add context and/or @graph\n    if(_isArray(compacted)) {\n      // use '@graph' keyword\n      var kwgraph = _compactIri(activeCtx, '@graph');\n      var graph = compacted;\n      compacted = {};\n      if(hasContext) {\n        compacted['@context'] = ctx;\n      }\n      compacted[kwgraph] = graph;\n    } else if(_isObject(compacted) && hasContext) {\n      // reorder keys so @context is first\n      var graph = compacted;\n      compacted = {'@context': ctx};\n      for(var key in graph) {\n        compacted[key] = graph[key];\n      }\n    }\n\n    callback(null, compacted, activeCtx);\n  }\n};\n\n/**\n * Performs JSON-LD expansion.\n *\n * @param input the JSON-LD input to expand.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [keepFreeFloatingNodes] true to keep free-floating nodes,\n *            false not to, defaults to false.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, expanded) called once the operation completes.\n */\njsonld.expand = function(input, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not expand, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n  if(!('keepFreeFloatingNodes' in options)) {\n    options.keepFreeFloatingNodes = false;\n  }\n\n  jsonld.nextTick(function() {\n    // if input is a string, attempt to dereference remote document\n    if(typeof input === 'string') {\n      var done = function(err, remoteDoc) {\n        if(err) {\n          return callback(err);\n        }\n        try {\n          if(!remoteDoc.document) {\n            throw new JsonLdError(\n              'No remote document found at the given URL.',\n              'jsonld.NullRemoteDocument');\n          }\n          if(typeof remoteDoc.document === 'string') {\n            remoteDoc.document = JSON.parse(remoteDoc.document);\n          }\n        } catch(ex) {\n          return callback(new JsonLdError(\n            'Could not retrieve a JSON-LD document from the URL. URL ' +\n            'dereferencing not implemented.', 'jsonld.LoadDocumentError', {\n              code: 'loading document failed',\n              cause: ex,\n              remoteDoc: remoteDoc\n          }));\n        }\n        expand(remoteDoc);\n      };\n      var promise = options.documentLoader(input, done);\n      if(promise && 'then' in promise) {\n        promise.then(done.bind(null, null), done);\n      }\n      return;\n    }\n    // nothing to load\n    expand({contextUrl: null, documentUrl: null, document: input});\n  });\n\n  function expand(remoteDoc) {\n    // set default base\n    if(!('base' in options)) {\n      options.base = remoteDoc.documentUrl || '';\n    }\n    // build meta-object and retrieve all @context URLs\n    var input = {\n      document: _clone(remoteDoc.document),\n      remoteContext: {'@context': remoteDoc.contextUrl}\n    };\n    if('expandContext' in options) {\n      var expandContext = _clone(options.expandContext);\n      if(typeof expandContext === 'object' && '@context' in expandContext) {\n        input.expandContext = expandContext;\n      } else {\n        input.expandContext = {'@context': expandContext};\n      }\n    }\n    _retrieveContextUrls(input, options, function(err, input) {\n      if(err) {\n        return callback(err);\n      }\n\n      var expanded;\n      try {\n        var processor = new Processor();\n        var activeCtx = _getInitialContext(options);\n        var document = input.document;\n        var remoteContext = input.remoteContext['@context'];\n\n        // process optional expandContext\n        if(input.expandContext) {\n          activeCtx = processor.processContext(\n            activeCtx, input.expandContext['@context'], options);\n        }\n\n        // process remote context from HTTP Link Header\n        if(remoteContext) {\n          activeCtx = processor.processContext(\n            activeCtx, remoteContext, options);\n        }\n\n        // expand document\n        expanded = processor.expand(\n          activeCtx, null, document, options, false);\n\n        // optimize away @graph with no other properties\n        if(_isObject(expanded) && ('@graph' in expanded) &&\n          Object.keys(expanded).length === 1) {\n          expanded = expanded['@graph'];\n        } else if(expanded === null) {\n          expanded = [];\n        }\n\n        // normalize to an array\n        if(!_isArray(expanded)) {\n          expanded = [expanded];\n        }\n      } catch(ex) {\n        return callback(ex);\n      }\n      callback(null, expanded);\n    });\n  }\n};\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the JSON-LD to flatten.\n * @param ctx the context to use to compact the flattened output, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, flattened) called once the operation completes.\n */\njsonld.flatten = function(input, ctx, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not flatten, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  } else if(typeof ctx === 'function') {\n    callback = ctx;\n    ctx = null;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // expand input\n  jsonld.expand(input, options, function(err, _input) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before flattening.',\n        'jsonld.FlattenError', {cause: err}));\n    }\n\n    var flattened;\n    try {\n      // do flattening\n      flattened = new Processor().flatten(_input);\n    } catch(ex) {\n      return callback(ex);\n    }\n\n    if(ctx === null) {\n      return callback(null, flattened);\n    }\n\n    // compact result (force @graph option to true, skip expansion)\n    options.graph = true;\n    options.skipExpansion = true;\n    jsonld.compact(flattened, ctx, options, function(err, compacted) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not compact flattened output.',\n          'jsonld.FlattenError', {cause: err}));\n      }\n      callback(null, compacted);\n    });\n  });\n};\n\n/**\n * Performs JSON-LD framing.\n *\n * @param input the JSON-LD input to frame.\n * @param frame the JSON-LD frame to use.\n * @param [options] the framing options.\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [embed] default @embed flag: '@last', '@always', '@never', '@link'\n *            (default: '@last').\n *          [explicit] default @explicit flag (default: false).\n *          [requireAll] default @requireAll flag (default: true).\n *          [omitDefault] default @omitDefault flag (default: false).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, framed) called once the operation completes.\n */\njsonld.frame = function(input, frame, options, callback) {\n  if(arguments.length < 2) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not frame, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n  if(!('embed' in options)) {\n    options.embed = '@last';\n  }\n  options.explicit = options.explicit || false;\n  if(!('requireAll' in options)) {\n    options.requireAll = true;\n  }\n  options.omitDefault = options.omitDefault || false;\n\n  jsonld.nextTick(function() {\n    // if frame is a string, attempt to dereference remote document\n    if(typeof frame === 'string') {\n      var done = function(err, remoteDoc) {\n        if(err) {\n          return callback(err);\n        }\n        try {\n          if(!remoteDoc.document) {\n            throw new JsonLdError(\n              'No remote document found at the given URL.',\n              'jsonld.NullRemoteDocument');\n          }\n          if(typeof remoteDoc.document === 'string') {\n            remoteDoc.document = JSON.parse(remoteDoc.document);\n          }\n        } catch(ex) {\n          return callback(new JsonLdError(\n            'Could not retrieve a JSON-LD document from the URL. URL ' +\n            'dereferencing not implemented.', 'jsonld.LoadDocumentError', {\n              code: 'loading document failed',\n              cause: ex,\n              remoteDoc: remoteDoc\n          }));\n        }\n        doFrame(remoteDoc);\n      };\n      var promise = options.documentLoader(frame, done);\n      if(promise && 'then' in promise) {\n        promise.then(done.bind(null, null), done);\n      }\n      return;\n    }\n    // nothing to load\n    doFrame({contextUrl: null, documentUrl: null, document: frame});\n  });\n\n  function doFrame(remoteFrame) {\n    // preserve frame context and add any Link header context\n    var frame = remoteFrame.document;\n    var ctx;\n    if(frame) {\n      ctx = frame['@context'];\n      if(remoteFrame.contextUrl) {\n        if(!ctx) {\n          ctx = remoteFrame.contextUrl;\n        } else if(_isArray(ctx)) {\n          ctx.push(remoteFrame.contextUrl);\n        } else {\n          ctx = [ctx, remoteFrame.contextUrl];\n        }\n        frame['@context'] = ctx;\n      } else {\n        ctx = ctx || {};\n      }\n    } else {\n      ctx = {};\n    }\n\n    // expand input\n    jsonld.expand(input, options, function(err, expanded) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not expand input before framing.',\n          'jsonld.FrameError', {cause: err}));\n      }\n\n      // expand frame\n      var opts = _clone(options);\n      opts.isFrame = true;\n      opts.keepFreeFloatingNodes = true;\n      jsonld.expand(frame, opts, function(err, expandedFrame) {\n        if(err) {\n          return callback(new JsonLdError(\n            'Could not expand frame before framing.',\n            'jsonld.FrameError', {cause: err}));\n        }\n\n        var framed;\n        try {\n          // do framing\n          framed = new Processor().frame(expanded, expandedFrame, opts);\n        } catch(ex) {\n          return callback(ex);\n        }\n\n        // compact result (force @graph option to true, skip expansion,\n        // check for linked embeds)\n        opts.graph = true;\n        opts.skipExpansion = true;\n        opts.link = {};\n        jsonld.compact(framed, ctx, opts, function(err, compacted, ctx) {\n          if(err) {\n            return callback(new JsonLdError(\n              'Could not compact framed output.',\n              'jsonld.FrameError', {cause: err}));\n          }\n          // get graph alias\n          var graph = _compactIri(ctx, '@graph');\n          // remove @preserve from results\n          opts.link = {};\n          compacted[graph] = _removePreserve(ctx, compacted[graph], opts);\n          callback(null, compacted);\n        });\n      });\n    });\n  }\n};\n\n/**\n * **Experimental**\n *\n * Links a JSON-LD document's nodes in memory.\n *\n * @param input the JSON-LD document to link.\n * @param ctx the JSON-LD context to apply.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, linked) called once the operation completes.\n */\njsonld.link = function(input, ctx, options, callback) {\n  // API matches running frame with a wildcard frame and embed: '@link'\n  // get arguments\n  var frame = {};\n  if(ctx) {\n    frame['@context'] = ctx;\n  }\n  frame['@embed'] = '@link';\n  jsonld.frame(input, frame, options, callback);\n};\n\n/**\n * **Deprecated**\n *\n * Performs JSON-LD objectification.\n *\n * @param input the JSON-LD document to objectify.\n * @param ctx the JSON-LD context to apply.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, linked) called once the operation completes.\n */\njsonld.objectify = function(input, ctx, options, callback) {\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // expand input\n  jsonld.expand(input, options, function(err, _input) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before linking.',\n        'jsonld.LinkError', {cause: err}));\n    }\n\n    var flattened;\n    try {\n      // flatten the graph\n      flattened = new Processor().flatten(_input);\n    } catch(ex) {\n      return callback(ex);\n    }\n\n    // compact result (force @graph option to true, skip expansion)\n    options.graph = true;\n    options.skipExpansion = true;\n    jsonld.compact(flattened, ctx, options, function(err, compacted, ctx) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not compact flattened output before linking.',\n          'jsonld.LinkError', {cause: err}));\n      }\n      // get graph alias\n      var graph = _compactIri(ctx, '@graph');\n      var top = compacted[graph][0];\n\n      var recurse = function(subject) {\n        // can't replace just a string\n        if(!_isObject(subject) && !_isArray(subject)) {\n          return;\n        }\n\n        // bottom out recursion on re-visit\n        if(_isObject(subject)) {\n          if(recurse.visited[subject['@id']]) {\n            return;\n          }\n          recurse.visited[subject['@id']] = true;\n        }\n\n        // each array element *or* object key\n        for(var k in subject) {\n          var obj = subject[k];\n          var isid = (jsonld.getContextValue(ctx, k, '@type') === '@id');\n\n          // can't replace a non-object or non-array unless it's an @id\n          if(!_isArray(obj) && !_isObject(obj) && !isid) {\n            continue;\n          }\n\n          if(_isString(obj) && isid) {\n            subject[k] = obj = top[obj];\n            recurse(obj);\n          } else if(_isArray(obj)) {\n            for(var i = 0; i < obj.length; ++i) {\n              if(_isString(obj[i]) && isid) {\n                obj[i] = top[obj[i]];\n              } else if(_isObject(obj[i]) && '@id' in obj[i]) {\n                obj[i] = top[obj[i]['@id']];\n              }\n              recurse(obj[i]);\n            }\n          } else if(_isObject(obj)) {\n            var sid = obj['@id'];\n            subject[k] = obj = top[sid];\n            recurse(obj);\n          }\n        }\n      };\n      recurse.visited = {};\n      recurse(top);\n\n      compacted.of_type = {};\n      for(var s in top) {\n        if(!('@type' in top[s])) {\n          continue;\n        }\n        var types = top[s]['@type'];\n        if(!_isArray(types)) {\n          types = [types];\n        }\n        for(var t = 0; t < types.length; ++t) {\n          if(!(types[t] in compacted.of_type)) {\n            compacted.of_type[types[t]] = [];\n          }\n          compacted.of_type[types[t]].push(top[s]);\n        }\n      }\n      callback(null, compacted);\n    });\n  });\n};\n\n/**\n * Performs RDF dataset normalization on the given input. The input is JSON-LD\n * unless the 'inputFormat' option is used. The output is an RDF dataset\n * unless the 'format' option is used.\n *\n * @param input the input to normalize as JSON-LD or as a format specified by\n *          the 'inputFormat' option.\n * @param [options] the options to use:\n *          [algorithm] the normalization algorithm to use, `URDNA2015` or\n *            `URGNA2012` (default: `URGNA2012`).\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [inputFormat] the format if input is not JSON-LD:\n *            'application/nquads' for N-Quads.\n *          [format] the format if output is a string:\n *            'application/nquads' for N-Quads.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, normalized) called once the operation completes.\n */\njsonld.normalize = function(input, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not normalize, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('algorithm' in options)) {\n    options.algorithm = 'URGNA2012';\n  }\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  if('inputFormat' in options) {\n    if(options.inputFormat !== 'application/nquads') {\n      return callback(new JsonLdError(\n        'Unknown normalization input format.',\n        'jsonld.NormalizeError'));\n    }\n    var parsedInput = _parseNQuads(input);\n    // do normalization\n    new Processor().normalize(parsedInput, options, callback);\n  } else {\n    // convert to RDF dataset then do normalization\n    var opts = _clone(options);\n    delete opts.format;\n    opts.produceGeneralizedRdf = false;\n    jsonld.toRDF(input, opts, function(err, dataset) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not convert input to RDF dataset before normalization.',\n          'jsonld.NormalizeError', {cause: err}));\n      }\n      // do normalization\n      new Processor().normalize(dataset, options, callback);\n    });\n  }\n};\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset a serialized string of RDF in a format specified by the\n *          format option or an RDF dataset to convert.\n * @param [options] the options to use:\n *          [format] the format if dataset param must first be parsed:\n *            'application/nquads' for N-Quads (default).\n *          [rdfParser] a custom RDF-parser to use to parse the dataset.\n *          [useRdfType] true to use rdf:type, false to use @type\n *            (default: false).\n *          [useNativeTypes] true to convert XSD types into native types\n *            (boolean, integer, double), false not to (default: false).\n * @param callback(err, output) called once the operation completes.\n */\njsonld.fromRDF = function(dataset, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not convert from RDF, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('useRdfType' in options)) {\n    options.useRdfType = false;\n  }\n  if(!('useNativeTypes' in options)) {\n    options.useNativeTypes = false;\n  }\n\n  if(!('format' in options) && _isString(dataset)) {\n    // set default format to nquads\n    if(!('format' in options)) {\n      options.format = 'application/nquads';\n    }\n  }\n\n  jsonld.nextTick(function() {\n    // handle special format\n    var rdfParser;\n    if(options.format) {\n      // check supported formats\n      rdfParser = options.rdfParser || _rdfParsers[options.format];\n      if(!rdfParser) {\n        return callback(new JsonLdError(\n          'Unknown input format.',\n          'jsonld.UnknownFormat', {format: options.format}));\n      }\n    } else {\n      // no-op parser, assume dataset already parsed\n      rdfParser = function() {\n        return dataset;\n      };\n    }\n\n    var callbackCalled = false;\n    try {\n      // rdf parser may be async or sync, always pass callback\n      dataset = rdfParser(dataset, function(err, dataset) {\n        callbackCalled = true;\n        if(err) {\n          return callback(err);\n        }\n        fromRDF(dataset, options, callback);\n      });\n    } catch(e) {\n      if(!callbackCalled) {\n        return callback(e);\n      }\n      throw e;\n    }\n    // handle synchronous or promise-based parser\n    if(dataset) {\n      // if dataset is actually a promise\n      if('then' in dataset) {\n        return dataset.then(function(dataset) {\n          fromRDF(dataset, options, callback);\n        }, callback);\n      }\n      // parser is synchronous\n      fromRDF(dataset, options, callback);\n    }\n\n    function fromRDF(dataset, options, callback) {\n      // convert from RDF\n      new Processor().fromRDF(dataset, options, callback);\n    }\n  });\n};\n\n/**\n * Outputs the RDF dataset found in the given JSON-LD object.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [format] the format to use to output a string:\n *            'application/nquads' for N-Quads.\n *          [produceGeneralizedRdf] true to output generalized RDF, false\n *            to produce only standard RDF (default: false).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, dataset) called once the operation completes.\n */\njsonld.toRDF = function(input, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not convert to RDF, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // expand input\n  jsonld.expand(input, options, function(err, expanded) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before serialization to RDF.',\n        'jsonld.RdfError', {cause: err}));\n    }\n\n    var dataset;\n    try {\n      // output RDF dataset\n      dataset = Processor.prototype.toRDF(expanded, options);\n      if(options.format) {\n        if(options.format === 'application/nquads') {\n          return callback(null, _toNQuads(dataset));\n        }\n        throw new JsonLdError(\n          'Unknown output format.',\n          'jsonld.UnknownFormat', {format: options.format});\n      }\n    } catch(ex) {\n      return callback(ex);\n    }\n    callback(null, dataset);\n  });\n};\n\n/**\n * **Experimental**\n *\n * Recursively flattens the nodes in the given JSON-LD input into a map of\n * node ID => node.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [namer] (deprecated)\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, nodeMap) called once the operation completes.\n */\njsonld.createNodeMap = function(input, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not create node map, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // expand input\n  jsonld.expand(input, options, function(err, _input) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before creating node map.',\n        'jsonld.CreateNodeMapError', {cause: err}));\n    }\n\n    var nodeMap;\n    try {\n      nodeMap = new Processor().createNodeMap(_input, options);\n    } catch(ex) {\n      return callback(ex);\n    }\n\n    callback(null, nodeMap);\n  });\n};\n\n/**\n * **Experimental**\n *\n * Merges two or more JSON-LD documents into a single flattened document.\n *\n * @param docs the JSON-LD documents to merge together.\n * @param ctx the context to use to compact the merged result, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [namer] (deprecated).\n *          [mergeNodes] true to merge properties for nodes with the same ID,\n *            false to ignore new properties for nodes with the same ID once\n *            the ID has been defined; note that this may not prevent merging\n *            new properties where a node is in the `object` position\n *            (default: true).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, merged) called once the operation completes.\n */\njsonld.merge = function(docs, ctx, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not merge, too few arguments.'));\n    });\n  }\n  if(!_isArray(docs)) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not merge, \"docs\" must be an array.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  } else if(typeof ctx === 'function') {\n    callback = ctx;\n    ctx = null;\n    options = {};\n  }\n  options = options || {};\n\n  // expand all documents\n  var expanded = [];\n  var error = null;\n  var count = docs.length;\n  for(var i = 0; i < docs.length; ++i) {\n    var opts = {};\n    for(var key in options) {\n      opts[key] = options[key];\n    }\n    jsonld.expand(docs[i], opts, expandComplete);\n  }\n\n  function expandComplete(err, _input) {\n    if(error) {\n      return;\n    }\n    if(err) {\n      error = err;\n      return callback(new JsonLdError(\n        'Could not expand input before flattening.',\n        'jsonld.FlattenError', {cause: err}));\n    }\n    expanded.push(_input);\n    if(--count === 0) {\n      merge(expanded);\n    }\n  }\n\n  function merge(expanded) {\n    var mergeNodes = true;\n    if('mergeNodes' in options) {\n      mergeNodes = options.mergeNodes;\n    }\n\n    var issuer = options.namer || options.issuer || new IdentifierIssuer('_:b');\n    var graphs = {'@default': {}};\n\n    var defaultGraph;\n    try {\n      for(var i = 0; i < expanded.length; ++i) {\n        // uniquely relabel blank nodes\n        var doc = expanded[i];\n        doc = jsonld.relabelBlankNodes(doc, {\n          issuer: new IdentifierIssuer('_:b' + i + '-')\n        });\n\n        // add nodes to the shared node map graphs if merging nodes, to a\n        // separate graph set if not\n        var _graphs = (mergeNodes || i === 0) ? graphs : {'@default': {}};\n        _createNodeMap(doc, _graphs, '@default', issuer);\n\n        if(_graphs !== graphs) {\n          // merge document graphs but don't merge existing nodes\n          for(var graphName in _graphs) {\n            var _nodeMap = _graphs[graphName];\n            if(!(graphName in graphs)) {\n              graphs[graphName] = _nodeMap;\n              continue;\n            }\n            var nodeMap = graphs[graphName];\n            for(var key in _nodeMap) {\n              if(!(key in nodeMap)) {\n                nodeMap[key] = _nodeMap[key];\n              }\n            }\n          }\n        }\n      }\n\n      // add all non-default graphs to default graph\n      defaultGraph = _mergeNodeMaps(graphs);\n    } catch(ex) {\n      return callback(ex);\n    }\n\n    // produce flattened output\n    var flattened = [];\n    var keys = Object.keys(defaultGraph).sort();\n    for(var ki = 0; ki < keys.length; ++ki) {\n      var node = defaultGraph[keys[ki]];\n      // only add full subjects to top-level\n      if(!_isSubjectReference(node)) {\n        flattened.push(node);\n      }\n    }\n\n    if(ctx === null) {\n      return callback(null, flattened);\n    }\n\n    // compact result (force @graph option to true, skip expansion)\n    options.graph = true;\n    options.skipExpansion = true;\n    jsonld.compact(flattened, ctx, options, function(err, compacted) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not compact merged output.',\n          'jsonld.MergeError', {cause: err}));\n      }\n      callback(null, compacted);\n    });\n  }\n};\n\n/**\n * Relabels all blank nodes in the given JSON-LD input.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [namer] (deprecated).\n */\njsonld.relabelBlankNodes = function(input, options) {\n  options = options || {};\n  var issuer = options.namer || options.issuer || new IdentifierIssuer('_:b');\n  return _labelBlankNodes(issuer, input);\n};\n\n/**\n * Prepends a base IRI to the given relative IRI.\n *\n * @param base the base IRI.\n * @param iri the relative IRI.\n *\n * @return the absolute IRI.\n */\njsonld.prependBase = function(base, iri) {\n  return _prependBase(base, iri);\n};\n\n/**\n * The default document loader for external documents. If the environment\n * is node.js, a callback-continuation-style document loader is used; otherwise,\n * a promises-style document loader is used.\n *\n * @param url the URL to load.\n * @param callback(err, remoteDoc) called once the operation completes,\n *          if using a non-promises API.\n *\n * @return a promise, if using a promises API.\n */\njsonld.documentLoader = function(url, callback) {\n  var err = new JsonLdError(\n    'Could not retrieve a JSON-LD document from the URL. URL ' +\n    'dereferencing not implemented.', 'jsonld.LoadDocumentError',\n    {code: 'loading document failed'});\n  if(_nodejs) {\n    return callback(err, {contextUrl: null, documentUrl: url, document: null});\n  }\n  return jsonld.promisify(function(callback) {\n    callback(err);\n  });\n};\n\n/**\n * Deprecated default document loader. Use or override jsonld.documentLoader\n * instead.\n */\njsonld.loadDocument = function(url, callback) {\n  var promise = jsonld.documentLoader(url, callback);\n  if(promise && 'then' in promise) {\n    promise.then(callback.bind(null, null), callback);\n  }\n};\n\n/* Promises API */\n\n/**\n * Creates a new promises API object.\n *\n * @param [options] the options to use:\n *          [api] an object to attach the API to.\n *          [version] 'json-ld-1.0' to output a standard JSON-LD 1.0 promises\n *            API, 'jsonld.js' to output the same with augmented proprietary\n *            methods (default: 'jsonld.js')\n *\n * @return the promises API object.\n */\njsonld.promises = function(options) {\n  options = options || {};\n  var slice = Array.prototype.slice;\n  var promisify = jsonld.promisify;\n\n  // handle 'api' option as version, set defaults\n  var api = options.api || {};\n  var version = options.version || 'jsonld.js';\n  if(typeof options.api === 'string') {\n    if(!options.version) {\n      version = options.api;\n    }\n    api = {};\n  }\n\n  api.expand = function(input) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not expand, too few arguments.');\n    }\n    return promisify.apply(null, [jsonld.expand].concat(slice.call(arguments)));\n  };\n  api.compact = function(input, ctx) {\n    if(arguments.length < 2) {\n      throw new TypeError('Could not compact, too few arguments.');\n    }\n    var compact = function(input, ctx, options, callback) {\n      // ensure only one value is returned in callback\n      jsonld.compact(input, ctx, options, function(err, compacted) {\n        callback(err, compacted);\n      });\n    };\n    return promisify.apply(null, [compact].concat(slice.call(arguments)));\n  };\n  api.flatten = function(input) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not flatten, too few arguments.');\n    }\n    return promisify.apply(\n      null, [jsonld.flatten].concat(slice.call(arguments)));\n  };\n  api.frame = function(input, frame) {\n    if(arguments.length < 2) {\n      throw new TypeError('Could not frame, too few arguments.');\n    }\n    return promisify.apply(null, [jsonld.frame].concat(slice.call(arguments)));\n  };\n  api.fromRDF = function(dataset) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not convert from RDF, too few arguments.');\n    }\n    return promisify.apply(\n      null, [jsonld.fromRDF].concat(slice.call(arguments)));\n  };\n  api.toRDF = function(input) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not convert to RDF, too few arguments.');\n    }\n    return promisify.apply(null, [jsonld.toRDF].concat(slice.call(arguments)));\n  };\n  api.normalize = function(input) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not normalize, too few arguments.');\n    }\n    return promisify.apply(\n      null, [jsonld.normalize].concat(slice.call(arguments)));\n  };\n\n  if(version === 'jsonld.js') {\n    api.link = function(input, ctx) {\n      if(arguments.length < 2) {\n        throw new TypeError('Could not link, too few arguments.');\n      }\n      return promisify.apply(\n        null, [jsonld.link].concat(slice.call(arguments)));\n    };\n    api.objectify = function(input) {\n      return promisify.apply(\n        null, [jsonld.objectify].concat(slice.call(arguments)));\n    };\n    api.createNodeMap = function(input) {\n      return promisify.apply(\n        null, [jsonld.createNodeMap].concat(slice.call(arguments)));\n    };\n    api.merge = function(input) {\n      return promisify.apply(\n        null, [jsonld.merge].concat(slice.call(arguments)));\n    };\n  }\n\n  try {\n    jsonld.Promise = global.Promise || require('es6-promise').Promise;\n  } catch(e) {\n    var f = function() {\n      throw new Error('Unable to find a Promise implementation.');\n    };\n    for(var method in api) {\n      api[method] = f;\n    }\n  }\n\n  return api;\n};\n\n/**\n * Converts a node.js async op into a promise w/boxed resolved value(s).\n *\n * @param op the operation to convert.\n *\n * @return the promise.\n */\njsonld.promisify = function(op) {\n  if(!jsonld.Promise) {\n    try {\n      jsonld.Promise = global.Promise || require('es6-promise').Promise;\n    } catch(e) {\n      throw new Error('Unable to find a Promise implementation.');\n    }\n  }\n  var args = Array.prototype.slice.call(arguments, 1);\n  return new jsonld.Promise(function(resolve, reject) {\n    op.apply(null, args.concat(function(err, value) {\n      if(!err) {\n        resolve(value);\n      } else {\n        reject(err);\n      }\n    }));\n  });\n};\n\n// extend jsonld.promises w/jsonld.js methods\njsonld.promises({api: jsonld.promises});\n\n/* WebIDL API */\n\nfunction JsonLdProcessor() {}\nJsonLdProcessor.prototype = jsonld.promises({version: 'json-ld-1.0'});\nJsonLdProcessor.prototype.toString = function() {\n  if(this instanceof JsonLdProcessor) {\n    return '[object JsonLdProcessor]';\n  }\n  return '[object JsonLdProcessorPrototype]';\n};\njsonld.JsonLdProcessor = JsonLdProcessor;\n\n// IE8 has Object.defineProperty but it only\n// works on DOM nodes -- so feature detection\n// requires try/catch :-(\nvar canDefineProperty = !!Object.defineProperty;\nif(canDefineProperty) {\n  try {\n    Object.defineProperty({}, 'x', {});\n  } catch(e) {\n    canDefineProperty = false;\n  }\n}\n\nif(canDefineProperty) {\n  Object.defineProperty(JsonLdProcessor, 'prototype', {\n    writable: false,\n    enumerable: false\n  });\n  Object.defineProperty(JsonLdProcessor.prototype, 'constructor', {\n    writable: true,\n    enumerable: false,\n    configurable: true,\n    value: JsonLdProcessor\n  });\n}\n\n// setup browser global JsonLdProcessor\nif(_browser && typeof global.JsonLdProcessor === 'undefined') {\n  if(canDefineProperty) {\n    Object.defineProperty(global, 'JsonLdProcessor', {\n      writable: true,\n      enumerable: false,\n      configurable: true,\n      value: JsonLdProcessor\n    });\n  } else {\n    global.JsonLdProcessor = JsonLdProcessor;\n  }\n}\n\n/* Utility API */\n\n// define setImmediate and nextTick\n//// nextTick implementation with browser-compatible fallback ////\n// from https://github.com/caolan/async/blob/master/lib/async.js\n\n// capture the global reference to guard against fakeTimer mocks\nvar _setImmediate = typeof setImmediate === 'function' && setImmediate;\n\nvar _delay = _setImmediate ? function(fn) {\n  // not a direct alias (for IE10 compatibility)\n  _setImmediate(fn);\n} : function(fn) {\n  setTimeout(fn, 0);\n};\n\nif(typeof process === 'object' && typeof process.nextTick === 'function') {\n  jsonld.nextTick = process.nextTick;\n} else {\n  jsonld.nextTick = _delay;\n}\njsonld.setImmediate = _setImmediate ? _delay : jsonld.nextTick;\n\n/**\n * Parses a link header. The results will be key'd by the value of \"rel\".\n *\n * Link: <http://json-ld.org/contexts/person.jsonld>; rel=\"http://www.w3.org/ns/json-ld#context\"; type=\"application/ld+json\"\n *\n * Parses as: {\n *   'http://www.w3.org/ns/json-ld#context': {\n *     target: http://json-ld.org/contexts/person.jsonld,\n *     type: 'application/ld+json'\n *   }\n * }\n *\n * If there is more than one \"rel\" with the same IRI, then entries in the\n * resulting map for that \"rel\" will be arrays.\n *\n * @param header the link header to parse.\n */\njsonld.parseLinkHeader = function(header) {\n  var rval = {};\n  // split on unbracketed/unquoted commas\n  var entries = header.match(/(?:<[^>]*?>|\"[^\"]*?\"|[^,])+/g);\n  var rLinkHeader = /\\s*<([^>]*?)>\\s*(?:;\\s*(.*))?/;\n  for(var i = 0; i < entries.length; ++i) {\n    var match = entries[i].match(rLinkHeader);\n    if(!match) {\n      continue;\n    }\n    var result = {target: match[1]};\n    var params = match[2];\n    var rParams = /(.*?)=(?:(?:\"([^\"]*?)\")|([^\"]*?))\\s*(?:(?:;\\s*)|$)/g;\n    while(match = rParams.exec(params)) {\n      result[match[1]] = (match[2] === undefined) ? match[3] : match[2];\n    }\n    var rel = result['rel'] || '';\n    if(_isArray(rval[rel])) {\n      rval[rel].push(result);\n    } else if(rel in rval) {\n      rval[rel] = [rval[rel], result];\n    } else {\n      rval[rel] = result;\n    }\n  }\n  return rval;\n};\n\n/**\n * Creates a simple queue for requesting documents.\n */\njsonld.RequestQueue = function() {\n  this._requests = {};\n};\njsonld.RequestQueue.prototype.wrapLoader = function(loader) {\n  this._loader = loader;\n  this._usePromise = (loader.length === 1);\n  return this.add.bind(this);\n};\njsonld.RequestQueue.prototype.add = function(url, callback) {\n  var self = this;\n\n  // callback must be given if not using promises\n  if(!callback && !self._usePromise) {\n    throw new Error('callback must be specified.');\n  }\n\n  // Promise-based API\n  if(self._usePromise) {\n    return new jsonld.Promise(function(resolve, reject) {\n      var load = self._requests[url];\n      if(!load) {\n        // load URL then remove from queue\n        load = self._requests[url] = self._loader(url)\n          .then(function(remoteDoc) {\n            delete self._requests[url];\n            return remoteDoc;\n          }).catch(function(err) {\n            delete self._requests[url];\n            throw err;\n          });\n      }\n      // resolve/reject promise once URL has been loaded\n      load.then(function(remoteDoc) {\n        resolve(remoteDoc);\n      }).catch(function(err) {\n        reject(err);\n      });\n    });\n  }\n\n  // callback-based API\n  if(url in self._requests) {\n    self._requests[url].push(callback);\n  } else {\n    self._requests[url] = [callback];\n    self._loader(url, function(err, remoteDoc) {\n      var callbacks = self._requests[url];\n      delete self._requests[url];\n      for(var i = 0; i < callbacks.length; ++i) {\n        callbacks[i](err, remoteDoc);\n      }\n    });\n  }\n};\n\n/**\n * Creates a simple document cache that retains documents for a short\n * period of time.\n *\n * FIXME: Implement simple HTTP caching instead.\n *\n * @param size the maximum size of the cache.\n */\njsonld.DocumentCache = function(size) {\n  this.order = [];\n  this.cache = {};\n  this.size = size || 50;\n  this.expires = 30 * 1000;\n};\njsonld.DocumentCache.prototype.get = function(url) {\n  if(url in this.cache) {\n    var entry = this.cache[url];\n    if(entry.expires >= +new Date()) {\n      return entry.ctx;\n    }\n    delete this.cache[url];\n    this.order.splice(this.order.indexOf(url), 1);\n  }\n  return null;\n};\njsonld.DocumentCache.prototype.set = function(url, ctx) {\n  if(this.order.length === this.size) {\n    delete this.cache[this.order.shift()];\n  }\n  this.order.push(url);\n  this.cache[url] = {ctx: ctx, expires: (+new Date() + this.expires)};\n};\n\n/**\n * Creates an active context cache.\n *\n * @param size the maximum size of the cache.\n */\njsonld.ActiveContextCache = function(size) {\n  this.order = [];\n  this.cache = {};\n  this.size = size || 100;\n};\njsonld.ActiveContextCache.prototype.get = function(activeCtx, localCtx) {\n  var key1 = JSON.stringify(activeCtx);\n  var key2 = JSON.stringify(localCtx);\n  var level1 = this.cache[key1];\n  if(level1 && key2 in level1) {\n    return level1[key2];\n  }\n  return null;\n};\njsonld.ActiveContextCache.prototype.set = function(\n  activeCtx, localCtx, result) {\n  if(this.order.length === this.size) {\n    var entry = this.order.shift();\n    delete this.cache[entry.activeCtx][entry.localCtx];\n  }\n  var key1 = JSON.stringify(activeCtx);\n  var key2 = JSON.stringify(localCtx);\n  this.order.push({activeCtx: key1, localCtx: key2});\n  if(!(key1 in this.cache)) {\n    this.cache[key1] = {};\n  }\n  this.cache[key1][key2] = _clone(result);\n};\n\n/**\n * Default JSON-LD cache.\n */\njsonld.cache = {\n  activeCtx: new jsonld.ActiveContextCache()\n};\n\n/**\n * Document loaders.\n */\njsonld.documentLoaders = {};\n\n/**\n * Creates a built-in jquery document loader.\n *\n * @param $ the jquery instance to use.\n * @param options the options to use:\n *          secure: require all URLs to use HTTPS.\n *          usePromise: true to use a promises API, false for a\n *            callback-continuation-style API; defaults to true if Promise\n *            is globally defined, false if not.\n *\n * @return the jquery document loader.\n */\njsonld.documentLoaders.jquery = function($, options) {\n  options = options || {};\n  var queue = new jsonld.RequestQueue();\n\n  // use option or, by default, use Promise when its defined\n  var usePromise = ('usePromise' in options ?\n    options.usePromise : (typeof Promise !== 'undefined'));\n  if(usePromise) {\n    return queue.wrapLoader(function(url) {\n      return jsonld.promisify(loader, url);\n    });\n  }\n  return queue.wrapLoader(loader);\n\n  function loader(url, callback) {\n    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; only \"http\" and \"https\" URLs are ' +\n        'supported.',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    if(options.secure && url.indexOf('https') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; secure mode is enabled and ' +\n        'the URL\\'s scheme is not \"https\".',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    $.ajax({\n      url: url,\n      accepts: {\n        json: 'application/ld+json, application/json'\n      },\n      // ensure Accept header is very specific for JSON-LD/JSON\n      headers: {\n        'Accept': 'application/ld+json, application/json'\n      },\n      dataType: 'json',\n      crossDomain: true,\n      success: function(data, textStatus, jqXHR) {\n        var doc = {contextUrl: null, documentUrl: url, document: data};\n\n        // handle Link Header\n        var contentType = jqXHR.getResponseHeader('Content-Type');\n        var linkHeader = jqXHR.getResponseHeader('Link');\n        if(linkHeader && contentType !== 'application/ld+json') {\n          // only 1 related link header permitted\n          linkHeader = jsonld.parseLinkHeader(linkHeader)[LINK_HEADER_REL];\n          if(_isArray(linkHeader)) {\n            return callback(new JsonLdError(\n              'URL could not be dereferenced, it has more than one ' +\n              'associated HTTP Link Header.',\n              'jsonld.InvalidUrl',\n              {code: 'multiple context link headers', url: url}), doc);\n          }\n          if(linkHeader) {\n            doc.contextUrl = linkHeader.target;\n          }\n        }\n\n        callback(null, doc);\n      },\n      error: function(jqXHR, textStatus, err) {\n        callback(new JsonLdError(\n          'URL could not be dereferenced, an error occurred.',\n          'jsonld.LoadDocumentError',\n          {code: 'loading document failed', url: url, cause: err}),\n          {contextUrl: null, documentUrl: url, document: null});\n      }\n    });\n  }\n};\n\n/**\n * Creates a built-in node document loader.\n *\n * @param options the options to use:\n *          secure: require all URLs to use HTTPS.\n *          strictSSL: true to require SSL certificates to be valid,\n *            false not to (default: true).\n *          maxRedirects: the maximum number of redirects to permit, none by\n *            default.\n *          request: the object which will make the request, default is\n *            provided by `https://www.npmjs.com/package/request`.\n *          headers: an array of headers which will be passed as request\n *            headers for the requested document. Accept is not allowed.\n *          usePromise: true to use a promises API, false for a\n *            callback-continuation-style API; false by default.\n *\n * @return the node document loader.\n */\njsonld.documentLoaders.node = function(options) {\n  options = options || {};\n  var strictSSL = ('strictSSL' in options) ? options.strictSSL : true;\n  var maxRedirects = ('maxRedirects' in options) ? options.maxRedirects : -1;\n  var request = ('request' in options) ? options.request : require('request');\n  var acceptHeader = 'application/ld+json, application/json';\n  var http = require('http');\n  // TODO: disable cache until HTTP caching implemented\n  //var cache = new jsonld.DocumentCache();\n\n  var queue = new jsonld.RequestQueue();\n  if(options.usePromise) {\n    return queue.wrapLoader(function(url) {\n      return jsonld.promisify(loadDocument, url, []);\n    });\n  }\n  var headers = options.headers || {};\n  if('Accept' in headers || 'accept' in headers) {\n    throw new RangeError(\n      'Accept header may not be specified as an option; only \"' +\n      acceptHeader + '\" is supported.');\n  }\n  return queue.wrapLoader(function(url, callback) {\n    loadDocument(url, [], callback);\n  });\n\n  function loadDocument(url, redirects, callback) {\n    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; only \"http\" and \"https\" URLs are ' +\n        'supported.',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    if(options.secure && url.indexOf('https') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; secure mode is enabled and ' +\n        'the URL\\'s scheme is not \"https\".',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    // TODO: disable cache until HTTP caching implemented\n    var doc = null;//cache.get(url);\n    if(doc !== null) {\n      return callback(null, doc);\n    }\n    var headers = {'Accept': acceptHeader};\n    for(var k in options.headers) { headers[k] = options.headers[k]; }\n    request({\n      url: url,\n      headers: headers,\n      strictSSL: strictSSL,\n      followRedirect: false\n    }, handleResponse);\n\n    function handleResponse(err, res, body) {\n      doc = {contextUrl: null, documentUrl: url, document: body || null};\n\n      // handle error\n      if(err) {\n        return callback(new JsonLdError(\n          'URL could not be dereferenced, an error occurred.',\n          'jsonld.LoadDocumentError',\n          {code: 'loading document failed', url: url, cause: err}), doc);\n      }\n      var statusText = http.STATUS_CODES[res.statusCode];\n      if(res.statusCode >= 400) {\n        return callback(new JsonLdError(\n          'URL could not be dereferenced: ' + statusText,\n          'jsonld.InvalidUrl', {\n            code: 'loading document failed',\n            url: url,\n            httpStatusCode: res.statusCode\n          }), doc);\n      }\n\n      // handle Link Header\n      if(res.headers.link &&\n        res.headers['content-type'] !== 'application/ld+json') {\n        // only 1 related link header permitted\n        var linkHeader = jsonld.parseLinkHeader(\n          res.headers.link)[LINK_HEADER_REL];\n        if(_isArray(linkHeader)) {\n          return callback(new JsonLdError(\n            'URL could not be dereferenced, it has more than one associated ' +\n            'HTTP Link Header.',\n            'jsonld.InvalidUrl',\n            {code: 'multiple context link headers', url: url}), doc);\n        }\n        if(linkHeader) {\n          doc.contextUrl = linkHeader.target;\n        }\n      }\n\n      // handle redirect\n      if(res.statusCode >= 300 && res.statusCode < 400 &&\n        res.headers.location) {\n        if(redirects.length === maxRedirects) {\n          return callback(new JsonLdError(\n            'URL could not be dereferenced; there were too many redirects.',\n            'jsonld.TooManyRedirects', {\n              code: 'loading document failed',\n              url: url,\n              httpStatusCode: res.statusCode,\n              redirects: redirects\n            }), doc);\n        }\n        if(redirects.indexOf(url) !== -1) {\n          return callback(new JsonLdError(\n            'URL could not be dereferenced; infinite redirection was detected.',\n            'jsonld.InfiniteRedirectDetected', {\n              code: 'recursive context inclusion',\n              url: url,\n              httpStatusCode: res.statusCode,\n              redirects: redirects\n            }), doc);\n        }\n        redirects.push(url);\n        return loadDocument(res.headers.location, redirects, callback);\n      }\n      // cache for each redirected URL\n      redirects.push(url);\n      // TODO: disable cache until HTTP caching implemented\n      /*for(var i = 0; i < redirects.length; ++i) {\n        cache.set(\n          redirects[i],\n          {contextUrl: null, documentUrl: redirects[i], document: body});\n      }*/\n      callback(err, doc);\n    }\n  }\n};\n\n/**\n * Creates a built-in XMLHttpRequest document loader.\n *\n * @param options the options to use:\n *          secure: require all URLs to use HTTPS.\n *          usePromise: true to use a promises API, false for a\n *            callback-continuation-style API; defaults to true if Promise\n *            is globally defined, false if not.\n *          [xhr]: the XMLHttpRequest API to use.\n *\n * @return the XMLHttpRequest document loader.\n */\njsonld.documentLoaders.xhr = function(options) {\n  options = options || {};\n  var rlink = /(^|(\\r\\n))link:/i;\n  var queue = new jsonld.RequestQueue();\n\n  // use option or, by default, use Promise when its defined\n  var usePromise = ('usePromise' in options ?\n    options.usePromise : (typeof Promise !== 'undefined'));\n  if(usePromise) {\n    return queue.wrapLoader(function(url) {\n      return jsonld.promisify(loader, url);\n    });\n  }\n  return queue.wrapLoader(loader);\n\n  function loader(url, callback) {\n    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; only \"http\" and \"https\" URLs are ' +\n        'supported.',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    if(options.secure && url.indexOf('https') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; secure mode is enabled and ' +\n        'the URL\\'s scheme is not \"https\".',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    var xhr = options.xhr || XMLHttpRequest;\n    var req = new xhr();\n    req.onload = function() {\n      if(req.status >= 400) {\n        return callback(new JsonLdError(\n          'URL could not be dereferenced: ' + req.statusText,\n          'jsonld.LoadDocumentError', {\n            code: 'loading document failed',\n            url: url,\n            httpStatusCode: req.status\n          }), {contextUrl: null, documentUrl: url, document: null});\n      }\n\n      var doc = {contextUrl: null, documentUrl: url, document: req.response};\n\n      // handle Link Header (avoid unsafe header warning by existence testing)\n      var contentType = req.getResponseHeader('Content-Type');\n      var linkHeader;\n      if(rlink.test(req.getAllResponseHeaders())) {\n        linkHeader = req.getResponseHeader('Link');\n      }\n      if(linkHeader && contentType !== 'application/ld+json') {\n        // only 1 related link header permitted\n        linkHeader = jsonld.parseLinkHeader(linkHeader)[LINK_HEADER_REL];\n        if(_isArray(linkHeader)) {\n          return callback(new JsonLdError(\n            'URL could not be dereferenced, it has more than one ' +\n            'associated HTTP Link Header.',\n            'jsonld.InvalidUrl',\n            {code: 'multiple context link headers', url: url}), doc);\n        }\n        if(linkHeader) {\n          doc.contextUrl = linkHeader.target;\n        }\n      }\n\n      callback(null, doc);\n    };\n    req.onerror = function() {\n      callback(new JsonLdError(\n        'URL could not be dereferenced, an error occurred.',\n        'jsonld.LoadDocumentError',\n        {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    };\n    req.open('GET', url, true);\n    req.setRequestHeader('Accept', 'application/ld+json, application/json');\n    req.send();\n  }\n};\n\n/**\n * Assigns the default document loader for external document URLs to a built-in\n * default. Supported types currently include: 'jquery' and 'node'.\n *\n * To use the jquery document loader, the first parameter must be a reference\n * to the main jquery object.\n *\n * @param type the type to set.\n * @param [params] the parameters required to use the document loader.\n */\njsonld.useDocumentLoader = function(type) {\n  if(!(type in jsonld.documentLoaders)) {\n    throw new JsonLdError(\n      'Unknown document loader type: \"' + type + '\"',\n      'jsonld.UnknownDocumentLoader',\n      {type: type});\n  }\n\n  // set document loader\n  jsonld.documentLoader = jsonld.documentLoaders[type].apply(\n    jsonld, Array.prototype.slice.call(arguments, 1));\n};\n\n/**\n * Processes a local context, resolving any URLs as necessary, and returns a\n * new active context in its callback.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param [options] the options to use:\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, ctx) called once the operation completes.\n */\njsonld.processContext = function(activeCtx, localCtx) {\n  // get arguments\n  var options = {};\n  var callbackArg = 2;\n  if(arguments.length > 3) {\n    options = arguments[2] || {};\n    callbackArg += 1;\n  }\n  var callback = arguments[callbackArg];\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // return initial context early for null context\n  if(localCtx === null) {\n    return callback(null, _getInitialContext(options));\n  }\n\n  // retrieve URLs in localCtx\n  localCtx = _clone(localCtx);\n  if(!(_isObject(localCtx) && '@context' in localCtx)) {\n    localCtx = {'@context': localCtx};\n  }\n  _retrieveContextUrls(localCtx, options, function(err, ctx) {\n    if(err) {\n      return callback(err);\n    }\n    try {\n      // process context\n      ctx = new Processor().processContext(activeCtx, ctx, options);\n    } catch(ex) {\n      return callback(ex);\n    }\n    callback(null, ctx);\n  });\n};\n\n/**\n * Returns true if the given subject has the given property.\n *\n * @param subject the subject to check.\n * @param property the property to look for.\n *\n * @return true if the subject has the given property, false if not.\n */\njsonld.hasProperty = function(subject, property) {\n  var rval = false;\n  if(property in subject) {\n    var value = subject[property];\n    rval = (!_isArray(value) || value.length > 0);\n  }\n  return rval;\n};\n\n/**\n * Determines if the given value is a property of the given subject.\n *\n * @param subject the subject to check.\n * @param property the property to check.\n * @param value the value to check.\n *\n * @return true if the value exists, false if not.\n */\njsonld.hasValue = function(subject, property, value) {\n  var rval = false;\n  if(jsonld.hasProperty(subject, property)) {\n    var val = subject[property];\n    var isList = _isList(val);\n    if(_isArray(val) || isList) {\n      if(isList) {\n        val = val['@list'];\n      }\n      for(var i = 0; i < val.length; ++i) {\n        if(jsonld.compareValues(value, val[i])) {\n          rval = true;\n          break;\n        }\n      }\n    } else if(!_isArray(value)) {\n      // avoid matching the set of values with an array value parameter\n      rval = jsonld.compareValues(value, val);\n    }\n  }\n  return rval;\n};\n\n/**\n * Adds a value to a subject. If the value is an array, all values in the\n * array will be added.\n *\n * @param subject the subject to add the value to.\n * @param property the property that relates the value to the subject.\n * @param value the value to add.\n * @param [options] the options to use:\n *        [propertyIsArray] true if the property is always an array, false\n *          if not (default: false).\n *        [allowDuplicate] true to allow duplicates, false not to (uses a\n *          simple shallow comparison of subject ID or value) (default: true).\n */\njsonld.addValue = function(subject, property, value, options) {\n  options = options || {};\n  if(!('propertyIsArray' in options)) {\n    options.propertyIsArray = false;\n  }\n  if(!('allowDuplicate' in options)) {\n    options.allowDuplicate = true;\n  }\n\n  if(_isArray(value)) {\n    if(value.length === 0 && options.propertyIsArray &&\n      !(property in subject)) {\n      subject[property] = [];\n    }\n    for(var i = 0; i < value.length; ++i) {\n      jsonld.addValue(subject, property, value[i], options);\n    }\n  } else if(property in subject) {\n    // check if subject already has value if duplicates not allowed\n    var hasValue = (!options.allowDuplicate &&\n      jsonld.hasValue(subject, property, value));\n\n    // make property an array if value not present or always an array\n    if(!_isArray(subject[property]) &&\n      (!hasValue || options.propertyIsArray)) {\n      subject[property] = [subject[property]];\n    }\n\n    // add new value\n    if(!hasValue) {\n      subject[property].push(value);\n    }\n  } else {\n    // add new value as set or single value\n    subject[property] = options.propertyIsArray ? [value] : value;\n  }\n};\n\n/**\n * Gets all of the values for a subject's property as an array.\n *\n * @param subject the subject.\n * @param property the property.\n *\n * @return all of the values for a subject's property as an array.\n */\njsonld.getValues = function(subject, property) {\n  var rval = subject[property] || [];\n  if(!_isArray(rval)) {\n    rval = [rval];\n  }\n  return rval;\n};\n\n/**\n * Removes a property from a subject.\n *\n * @param subject the subject.\n * @param property the property.\n */\njsonld.removeProperty = function(subject, property) {\n  delete subject[property];\n};\n\n/**\n * Removes a value from a subject.\n *\n * @param subject the subject.\n * @param property the property that relates the value to the subject.\n * @param value the value to remove.\n * @param [options] the options to use:\n *          [propertyIsArray] true if the property is always an array, false\n *            if not (default: false).\n */\njsonld.removeValue = function(subject, property, value, options) {\n  options = options || {};\n  if(!('propertyIsArray' in options)) {\n    options.propertyIsArray = false;\n  }\n\n  // filter out value\n  var values = jsonld.getValues(subject, property).filter(function(e) {\n    return !jsonld.compareValues(e, value);\n  });\n\n  if(values.length === 0) {\n    jsonld.removeProperty(subject, property);\n  } else if(values.length === 1 && !options.propertyIsArray) {\n    subject[property] = values[0];\n  } else {\n    subject[property] = values;\n  }\n};\n\n/**\n * Compares two JSON-LD values for equality. Two JSON-LD values will be\n * considered equal if:\n *\n * 1. They are both primitives of the same type and value.\n * 2. They are both @values with the same @value, @type, @language,\n *   and @index, OR\n * 3. They both have @ids they are the same.\n *\n * @param v1 the first value.\n * @param v2 the second value.\n *\n * @return true if v1 and v2 are considered equal, false if not.\n */\njsonld.compareValues = function(v1, v2) {\n  // 1. equal primitives\n  if(v1 === v2) {\n    return true;\n  }\n\n  // 2. equal @values\n  if(_isValue(v1) && _isValue(v2) &&\n    v1['@value'] === v2['@value'] &&\n    v1['@type'] === v2['@type'] &&\n    v1['@language'] === v2['@language'] &&\n    v1['@index'] === v2['@index']) {\n    return true;\n  }\n\n  // 3. equal @ids\n  if(_isObject(v1) && ('@id' in v1) && _isObject(v2) && ('@id' in v2)) {\n    return v1['@id'] === v2['@id'];\n  }\n\n  return false;\n};\n\n/**\n * Gets the value for the given active context key and type, null if none is\n * set.\n *\n * @param ctx the active context.\n * @param key the context key.\n * @param [type] the type of value to get (eg: '@id', '@type'), if not\n *          specified gets the entire entry for a key, null if not found.\n *\n * @return the value.\n */\njsonld.getContextValue = function(ctx, key, type) {\n  var rval = null;\n\n  // return null for invalid key\n  if(key === null) {\n    return rval;\n  }\n\n  // get default language\n  if(type === '@language' && (type in ctx)) {\n    rval = ctx[type];\n  }\n\n  // get specific entry information\n  if(ctx.mappings[key]) {\n    var entry = ctx.mappings[key];\n\n    if(_isUndefined(type)) {\n      // return whole entry\n      rval = entry;\n    } else if(type in entry) {\n      // return entry value for type\n      rval = entry[type];\n    }\n  }\n\n  return rval;\n};\n\n/** Registered RDF dataset parsers hashed by content-type. */\nvar _rdfParsers = {};\n\n/**\n * Registers an RDF dataset parser by content-type, for use with\n * jsonld.fromRDF. An RDF dataset parser will always be given two parameters,\n * a string of input and a callback. An RDF dataset parser can be synchronous\n * or asynchronous.\n *\n * If the parser function returns undefined or null then it will be assumed to\n * be asynchronous w/a continuation-passing style and the callback parameter\n * given to the parser MUST be invoked.\n *\n * If it returns a Promise, then it will be assumed to be asynchronous, but the\n * callback parameter MUST NOT be invoked. It should instead be ignored.\n *\n * If it returns an RDF dataset, it will be assumed to be synchronous and the\n * callback parameter MUST NOT be invoked. It should instead be ignored.\n *\n * @param contentType the content-type for the parser.\n * @param parser(input, callback(err, dataset)) the parser function (takes a\n *          string as a parameter and either returns null/undefined and uses\n *          the given callback, returns a Promise, or returns an RDF dataset).\n */\njsonld.registerRDFParser = function(contentType, parser) {\n  _rdfParsers[contentType] = parser;\n};\n\n/**\n * Unregisters an RDF dataset parser by content-type.\n *\n * @param contentType the content-type for the parser.\n */\njsonld.unregisterRDFParser = function(contentType) {\n  delete _rdfParsers[contentType];\n};\n\nif(_nodejs) {\n  // needed for serialization of XML literals\n  if(typeof XMLSerializer === 'undefined') {\n    var XMLSerializer = null;\n  }\n  if(typeof Node === 'undefined') {\n    var Node = {\n      ELEMENT_NODE: 1,\n      ATTRIBUTE_NODE: 2,\n      TEXT_NODE: 3,\n      CDATA_SECTION_NODE: 4,\n      ENTITY_REFERENCE_NODE: 5,\n      ENTITY_NODE: 6,\n      PROCESSING_INSTRUCTION_NODE: 7,\n      COMMENT_NODE: 8,\n      DOCUMENT_NODE: 9,\n      DOCUMENT_TYPE_NODE: 10,\n      DOCUMENT_FRAGMENT_NODE: 11,\n      NOTATION_NODE:12\n    };\n  }\n}\n\n// constants\nvar XSD_BOOLEAN = 'http://www.w3.org/2001/XMLSchema#boolean';\nvar XSD_DOUBLE = 'http://www.w3.org/2001/XMLSchema#double';\nvar XSD_INTEGER = 'http://www.w3.org/2001/XMLSchema#integer';\nvar XSD_STRING = 'http://www.w3.org/2001/XMLSchema#string';\n\nvar RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nvar RDF_LIST = RDF + 'List';\nvar RDF_FIRST = RDF + 'first';\nvar RDF_REST = RDF + 'rest';\nvar RDF_NIL = RDF + 'nil';\nvar RDF_TYPE = RDF + 'type';\nvar RDF_PLAIN_LITERAL = RDF + 'PlainLiteral';\nvar RDF_XML_LITERAL = RDF + 'XMLLiteral';\nvar RDF_OBJECT = RDF + 'object';\nvar RDF_LANGSTRING = RDF + 'langString';\n\nvar LINK_HEADER_REL = 'http://www.w3.org/ns/json-ld#context';\nvar MAX_CONTEXT_URLS = 10;\n\n/**\n * A JSON-LD Error.\n *\n * @param msg the error message.\n * @param type the error type.\n * @param details the error details.\n */\nvar JsonLdError = function(msg, type, details) {\n  if(_nodejs) {\n    Error.call(this);\n    Error.captureStackTrace(this, this.constructor);\n  } else if(typeof Error !== 'undefined') {\n    this.stack = (new Error()).stack;\n  }\n  this.name = type || 'jsonld.Error';\n  this.message = msg || 'An unspecified JSON-LD error occurred.';\n  this.details = details || {};\n};\nif(_nodejs) {\n  require('util').inherits(JsonLdError, Error);\n} else if(typeof Error !== 'undefined') {\n  JsonLdError.prototype = new Error();\n}\n\n/**\n * Constructs a new JSON-LD Processor.\n */\nvar Processor = function() {};\n\n/**\n * Recursively compacts an element using the given active context. All values\n * must be in expanded form before this method is called.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the compacted property associated with the element\n *          to compact, null for none.\n * @param element the element to compact.\n * @param options the compaction options.\n *\n * @return the compacted value.\n */\nProcessor.prototype.compact = function(\n  activeCtx, activeProperty, element, options) {\n  // recursively compact array\n  if(_isArray(element)) {\n    var rval = [];\n    for(var i = 0; i < element.length; ++i) {\n      // compact, dropping any null values\n      var compacted = this.compact(\n        activeCtx, activeProperty, element[i], options);\n      if(compacted !== null) {\n        rval.push(compacted);\n      }\n    }\n    if(options.compactArrays && rval.length === 1) {\n      // use single element if no container is specified\n      var container = jsonld.getContextValue(\n        activeCtx, activeProperty, '@container');\n      if(container === null) {\n        rval = rval[0];\n      }\n    }\n    return rval;\n  }\n\n  // recursively compact object\n  if(_isObject(element)) {\n    if(options.link && '@id' in element && element['@id'] in options.link) {\n      // check for a linked element to reuse\n      var linked = options.link[element['@id']];\n      for(var i = 0; i < linked.length; ++i) {\n        if(linked[i].expanded === element) {\n          return linked[i].compacted;\n        }\n      }\n    }\n\n    // do value compaction on @values and subject references\n    if(_isValue(element) || _isSubjectReference(element)) {\n      var rval = _compactValue(activeCtx, activeProperty, element);\n      if(options.link && _isSubjectReference(element)) {\n        // store linked element\n        if(!(element['@id'] in options.link)) {\n          options.link[element['@id']] = [];\n        }\n        options.link[element['@id']].push({expanded: element, compacted: rval});\n      }\n      return rval;\n    }\n\n    // FIXME: avoid misuse of active property as an expanded property?\n    var insideReverse = (activeProperty === '@reverse');\n\n    var rval = {};\n\n    if(options.link && '@id' in element) {\n      // store linked element\n      if(!(element['@id'] in options.link)) {\n        options.link[element['@id']] = [];\n      }\n      options.link[element['@id']].push({expanded: element, compacted: rval});\n    }\n\n    // process element keys in order\n    var keys = Object.keys(element).sort();\n    for(var ki = 0; ki < keys.length; ++ki) {\n      var expandedProperty = keys[ki];\n      var expandedValue = element[expandedProperty];\n\n      // compact @id and @type(s)\n      if(expandedProperty === '@id' || expandedProperty === '@type') {\n        var compactedValue;\n\n        // compact single @id\n        if(_isString(expandedValue)) {\n          compactedValue = _compactIri(\n            activeCtx, expandedValue, null,\n            {vocab: (expandedProperty === '@type')});\n        } else {\n          // expanded value must be a @type array\n          compactedValue = [];\n          for(var vi = 0; vi < expandedValue.length; ++vi) {\n            compactedValue.push(_compactIri(\n              activeCtx, expandedValue[vi], null, {vocab: true}));\n          }\n        }\n\n        // use keyword alias and add value\n        var alias = _compactIri(activeCtx, expandedProperty);\n        var isArray = (_isArray(compactedValue) && expandedValue.length === 0);\n        jsonld.addValue(\n          rval, alias, compactedValue, {propertyIsArray: isArray});\n        continue;\n      }\n\n      // handle @reverse\n      if(expandedProperty === '@reverse') {\n        // recursively compact expanded value\n        var compactedValue = this.compact(\n          activeCtx, '@reverse', expandedValue, options);\n\n        // handle double-reversed properties\n        for(var compactedProperty in compactedValue) {\n          if(activeCtx.mappings[compactedProperty] &&\n            activeCtx.mappings[compactedProperty].reverse) {\n            var value = compactedValue[compactedProperty];\n            var container = jsonld.getContextValue(\n              activeCtx, compactedProperty, '@container');\n            var useArray = (container === '@set' || !options.compactArrays);\n            jsonld.addValue(\n              rval, compactedProperty, value, {propertyIsArray: useArray});\n            delete compactedValue[compactedProperty];\n          }\n        }\n\n        if(Object.keys(compactedValue).length > 0) {\n          // use keyword alias and add value\n          var alias = _compactIri(activeCtx, expandedProperty);\n          jsonld.addValue(rval, alias, compactedValue);\n        }\n\n        continue;\n      }\n\n      // handle @index property\n      if(expandedProperty === '@index') {\n        // drop @index if inside an @index container\n        var container = jsonld.getContextValue(\n          activeCtx, activeProperty, '@container');\n        if(container === '@index') {\n          continue;\n        }\n\n        // use keyword alias and add value\n        var alias = _compactIri(activeCtx, expandedProperty);\n        jsonld.addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // skip array processing for keywords that aren't @graph or @list\n      if(expandedProperty !== '@graph' && expandedProperty !== '@list' &&\n        _isKeyword(expandedProperty)) {\n        // use keyword alias and add value as is\n        var alias = _compactIri(activeCtx, expandedProperty);\n        jsonld.addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // Note: expanded value must be an array due to expansion algorithm.\n\n      // preserve empty arrays\n      if(expandedValue.length === 0) {\n        var itemActiveProperty = _compactIri(\n          activeCtx, expandedProperty, expandedValue, {vocab: true},\n          insideReverse);\n        jsonld.addValue(\n          rval, itemActiveProperty, expandedValue, {propertyIsArray: true});\n      }\n\n      // recusively process array values\n      for(var vi = 0; vi < expandedValue.length; ++vi) {\n        var expandedItem = expandedValue[vi];\n\n        // compact property and get container type\n        var itemActiveProperty = _compactIri(\n          activeCtx, expandedProperty, expandedItem, {vocab: true},\n          insideReverse);\n        var container = jsonld.getContextValue(\n          activeCtx, itemActiveProperty, '@container');\n\n        // get @list value if appropriate\n        var isList = _isList(expandedItem);\n        var list = null;\n        if(isList) {\n          list = expandedItem['@list'];\n        }\n\n        // recursively compact expanded item\n        var compactedItem = this.compact(\n          activeCtx, itemActiveProperty, isList ? list : expandedItem, options);\n\n        // handle @list\n        if(isList) {\n          // ensure @list value is an array\n          if(!_isArray(compactedItem)) {\n            compactedItem = [compactedItem];\n          }\n\n          if(container !== '@list') {\n            // wrap using @list alias\n            var wrapper = {};\n            wrapper[_compactIri(activeCtx, '@list')] = compactedItem;\n            compactedItem = wrapper;\n\n            // include @index from expanded @list, if any\n            if('@index' in expandedItem) {\n              compactedItem[_compactIri(activeCtx, '@index')] =\n                expandedItem['@index'];\n            }\n          } else if(itemActiveProperty in rval) {\n            // can't use @list container for more than 1 list\n            throw new JsonLdError(\n              'JSON-LD compact error; property has a \"@list\" @container ' +\n              'rule but there is more than a single @list that matches ' +\n              'the compacted term in the document. Compaction might mix ' +\n              'unwanted items into the list.',\n              'jsonld.SyntaxError', {code: 'compaction to list of lists'});\n          }\n        }\n\n        // handle language and index maps\n        if(container === '@language' || container === '@index') {\n          // get or create the map object\n          var mapObject;\n          if(itemActiveProperty in rval) {\n            mapObject = rval[itemActiveProperty];\n          } else {\n            rval[itemActiveProperty] = mapObject = {};\n          }\n\n          // if container is a language map, simplify compacted value to\n          // a simple string\n          if(container === '@language' && _isValue(compactedItem)) {\n            compactedItem = compactedItem['@value'];\n          }\n\n          // add compact value to map object using key from expanded value\n          // based on the container type\n          jsonld.addValue(mapObject, expandedItem[container], compactedItem);\n        } else {\n          // use an array if: compactArrays flag is false,\n          // @container is @set or @list , value is an empty\n          // array, or key is @graph\n          var isArray = (!options.compactArrays || container === '@set' ||\n            container === '@list' ||\n            (_isArray(compactedItem) && compactedItem.length === 0) ||\n            expandedProperty === '@list' || expandedProperty === '@graph');\n\n          // add compact value\n          jsonld.addValue(\n            rval, itemActiveProperty, compactedItem,\n            {propertyIsArray: isArray});\n        }\n      }\n    }\n\n    return rval;\n  }\n\n  // only primitives remain which are already compact\n  return element;\n};\n\n/**\n * Recursively expands an element using the given context. Any context in\n * the element will be removed. All context URLs must have been retrieved\n * before calling this method.\n *\n * @param activeCtx the context to use.\n * @param activeProperty the property for the element, null for none.\n * @param element the element to expand.\n * @param options the expansion options.\n * @param insideList true if the element is a list, false if not.\n *\n * @return the expanded value.\n */\nProcessor.prototype.expand = function(\n  activeCtx, activeProperty, element, options, insideList) {\n  var self = this;\n\n  // nothing to expand\n  if(element === null || element === undefined) {\n    return null;\n  }\n\n  if(!_isArray(element) && !_isObject(element)) {\n    // drop free-floating scalars that are not in lists\n    if(!insideList && (activeProperty === null ||\n      _expandIri(activeCtx, activeProperty, {vocab: true}) === '@graph')) {\n      return null;\n    }\n\n    // expand element according to value expansion rules\n    return _expandValue(activeCtx, activeProperty, element);\n  }\n\n  // recursively expand array\n  if(_isArray(element)) {\n    var rval = [];\n    var container = jsonld.getContextValue(\n      activeCtx, activeProperty, '@container');\n    insideList = insideList || container === '@list';\n    for(var i = 0; i < element.length; ++i) {\n      // expand element\n      var e = self.expand(activeCtx, activeProperty, element[i], options);\n      if(insideList && (_isArray(e) || _isList(e))) {\n        // lists of lists are illegal\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; lists of lists are not permitted.',\n          'jsonld.SyntaxError', {code: 'list of lists'});\n      }\n      // drop null values\n      if(e !== null) {\n        if(_isArray(e)) {\n          rval = rval.concat(e);\n        } else {\n          rval.push(e);\n        }\n      }\n    }\n    return rval;\n  }\n\n  // recursively expand object:\n\n  // if element has a context, process it\n  if('@context' in element) {\n    activeCtx = self.processContext(activeCtx, element['@context'], options);\n  }\n\n  // expand the active property\n  var expandedActiveProperty = _expandIri(\n    activeCtx, activeProperty, {vocab: true});\n\n  var rval = {};\n  var keys = Object.keys(element).sort();\n  for(var ki = 0; ki < keys.length; ++ki) {\n    var key = keys[ki];\n    var value = element[key];\n    var expandedValue;\n\n    // skip @context\n    if(key === '@context') {\n      continue;\n    }\n\n    // expand property\n    var expandedProperty = _expandIri(activeCtx, key, {vocab: true});\n\n    // drop non-absolute IRI keys that aren't keywords\n    if(expandedProperty === null ||\n      !(_isAbsoluteIri(expandedProperty) || _isKeyword(expandedProperty))) {\n      continue;\n    }\n\n    if(_isKeyword(expandedProperty)) {\n      if(expandedActiveProperty === '@reverse') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a keyword cannot be used as a @reverse ' +\n          'property.', 'jsonld.SyntaxError',\n          {code: 'invalid reverse property map', value: value});\n      }\n      if(expandedProperty in rval) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; colliding keywords detected.',\n          'jsonld.SyntaxError',\n          {code: 'colliding keywords', keyword: expandedProperty});\n      }\n    }\n\n    // syntax error if @id is not a string\n    if(expandedProperty === '@id' && !_isString(value)) {\n      if(!options.isFrame) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@id\" value must a string.',\n          'jsonld.SyntaxError', {code: 'invalid @id value', value: value});\n      }\n      if(!_isObject(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@id\" value must be a string or an ' +\n          'object.', 'jsonld.SyntaxError',\n          {code: 'invalid @id value', value: value});\n      }\n    }\n\n    if(expandedProperty === '@type') {\n      _validateTypeValue(value);\n    }\n\n    // @graph must be an array or an object\n    if(expandedProperty === '@graph' &&\n      !(_isObject(value) || _isArray(value))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; \"@graph\" value must not be an ' +\n        'object or an array.',\n        'jsonld.SyntaxError', {code: 'invalid @graph value', value: value});\n    }\n\n    // @value must not be an object or an array\n    if(expandedProperty === '@value' &&\n      (_isObject(value) || _isArray(value))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; \"@value\" value must not be an ' +\n        'object or an array.',\n        'jsonld.SyntaxError',\n        {code: 'invalid value object value', value: value});\n    }\n\n    // @language must be a string\n    if(expandedProperty === '@language') {\n      if(value === null) {\n        // drop null @language values, they expand as if they didn't exist\n        continue;\n      }\n      if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@language\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid language-tagged string', value: value});\n      }\n      // ensure language value is lowercase\n      value = value.toLowerCase();\n    }\n\n    // @index must be a string\n    if(expandedProperty === '@index') {\n      if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@index\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @index value', value: value});\n      }\n    }\n\n    // @reverse must be an object\n    if(expandedProperty === '@reverse') {\n      if(!_isObject(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@reverse\" value must be an object.',\n          'jsonld.SyntaxError', {code: 'invalid @reverse value', value: value});\n      }\n\n      expandedValue = self.expand(activeCtx, '@reverse', value, options);\n\n      // properties double-reversed\n      if('@reverse' in expandedValue) {\n        for(var property in expandedValue['@reverse']) {\n          jsonld.addValue(\n            rval, property, expandedValue['@reverse'][property],\n            {propertyIsArray: true});\n        }\n      }\n\n      // FIXME: can this be merged with code below to simplify?\n      // merge in all reversed properties\n      var reverseMap = rval['@reverse'] || null;\n      for(var property in expandedValue) {\n        if(property === '@reverse') {\n          continue;\n        }\n        if(reverseMap === null) {\n          reverseMap = rval['@reverse'] = {};\n        }\n        jsonld.addValue(reverseMap, property, [], {propertyIsArray: true});\n        var items = expandedValue[property];\n        for(var ii = 0; ii < items.length; ++ii) {\n          var item = items[ii];\n          if(_isValue(item) || _isList(item)) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; \"@reverse\" value must not be a ' +\n              '@value or an @list.', 'jsonld.SyntaxError',\n              {code: 'invalid reverse property value', value: expandedValue});\n          }\n          jsonld.addValue(\n            reverseMap, property, item, {propertyIsArray: true});\n        }\n      }\n\n      continue;\n    }\n\n    var container = jsonld.getContextValue(activeCtx, key, '@container');\n\n    if(container === '@language' && _isObject(value)) {\n      // handle language map container (skip if value is not an object)\n      expandedValue = _expandLanguageMap(value);\n    } else if(container === '@index' && _isObject(value)) {\n      // handle index container (skip if value is not an object)\n      expandedValue = (function _expandIndexMap(activeProperty) {\n        var rval = [];\n        var keys = Object.keys(value).sort();\n        for(var ki = 0; ki < keys.length; ++ki) {\n          var key = keys[ki];\n          var val = value[key];\n          if(!_isArray(val)) {\n            val = [val];\n          }\n          val = self.expand(activeCtx, activeProperty, val, options, false);\n          for(var vi = 0; vi < val.length; ++vi) {\n            var item = val[vi];\n            if(!('@index' in item)) {\n              item['@index'] = key;\n            }\n            rval.push(item);\n          }\n        }\n        return rval;\n      })(key);\n    } else {\n      // recurse into @list or @set\n      var isList = (expandedProperty === '@list');\n      if(isList || expandedProperty === '@set') {\n        var nextActiveProperty = activeProperty;\n        if(isList && expandedActiveProperty === '@graph') {\n          nextActiveProperty = null;\n        }\n        expandedValue = self.expand(\n          activeCtx, nextActiveProperty, value, options, isList);\n        if(isList && _isList(expandedValue)) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; lists of lists are not permitted.',\n            'jsonld.SyntaxError', {code: 'list of lists'});\n        }\n      } else {\n        // recursively expand value with key as new active property\n        expandedValue = self.expand(activeCtx, key, value, options, false);\n      }\n    }\n\n    // drop null values if property is not @value\n    if(expandedValue === null && expandedProperty !== '@value') {\n      continue;\n    }\n\n    // convert expanded value to @list if container specifies it\n    if(expandedProperty !== '@list' && !_isList(expandedValue) &&\n      container === '@list') {\n      // ensure expanded value is an array\n      expandedValue = (_isArray(expandedValue) ?\n        expandedValue : [expandedValue]);\n      expandedValue = {'@list': expandedValue};\n    }\n\n    // FIXME: can this be merged with code above to simplify?\n    // merge in reverse properties\n    if(activeCtx.mappings[key] && activeCtx.mappings[key].reverse) {\n      var reverseMap = rval['@reverse'] = rval['@reverse'] || {};\n      if(!_isArray(expandedValue)) {\n        expandedValue = [expandedValue];\n      }\n      for(var ii = 0; ii < expandedValue.length; ++ii) {\n        var item = expandedValue[ii];\n        if(_isValue(item) || _isList(item)) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@reverse\" value must not be a ' +\n            '@value or an @list.', 'jsonld.SyntaxError',\n            {code: 'invalid reverse property value', value: expandedValue});\n        }\n        jsonld.addValue(\n          reverseMap, expandedProperty, item, {propertyIsArray: true});\n      }\n      continue;\n    }\n\n    // add value for property\n    // use an array except for certain keywords\n    var useArray =\n      ['@index', '@id', '@type', '@value', '@language'].indexOf(\n        expandedProperty) === -1;\n    jsonld.addValue(\n      rval, expandedProperty, expandedValue, {propertyIsArray: useArray});\n  }\n\n  // get property count on expanded output\n  keys = Object.keys(rval);\n  var count = keys.length;\n\n  if('@value' in rval) {\n    // @value must only have @language or @type\n    if('@type' in rval && '@language' in rval) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" may not ' +\n        'contain both \"@type\" and \"@language\".',\n        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});\n    }\n    var validCount = count - 1;\n    if('@type' in rval) {\n      validCount -= 1;\n    }\n    if('@index' in rval) {\n      validCount -= 1;\n    }\n    if('@language' in rval) {\n      validCount -= 1;\n    }\n    if(validCount !== 0) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" may only ' +\n        'have an \"@index\" property and at most one other property ' +\n        'which can be \"@type\" or \"@language\".',\n        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});\n    }\n    // drop null @values\n    if(rval['@value'] === null) {\n      rval = null;\n    } else if('@language' in rval && !_isString(rval['@value'])) {\n      // if @language is present, @value must be a string\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; only strings may be language-tagged.',\n        'jsonld.SyntaxError',\n        {code: 'invalid language-tagged value', element: rval});\n    } else if('@type' in rval && (!_isAbsoluteIri(rval['@type']) ||\n      rval['@type'].indexOf('_:') === 0)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" and \"@type\" ' +\n        'must have an absolute IRI for the value of \"@type\".',\n        'jsonld.SyntaxError', {code: 'invalid typed value', element: rval});\n    }\n  } else if('@type' in rval && !_isArray(rval['@type'])) {\n    // convert @type to an array\n    rval['@type'] = [rval['@type']];\n  } else if('@set' in rval || '@list' in rval) {\n    // handle @set and @list\n    if(count > 1 && !(count === 2 && '@index' in rval)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; if an element has the property \"@set\" ' +\n        'or \"@list\", then it can have at most one other property that is ' +\n        '\"@index\".', 'jsonld.SyntaxError',\n        {code: 'invalid set or list object', element: rval});\n    }\n    // optimize away @set\n    if('@set' in rval) {\n      rval = rval['@set'];\n      keys = Object.keys(rval);\n      count = keys.length;\n    }\n  } else if(count === 1 && '@language' in rval) {\n    // drop objects with only @language\n    rval = null;\n  }\n\n  // drop certain top-level objects that do not occur in lists\n  if(_isObject(rval) &&\n    !options.keepFreeFloatingNodes && !insideList &&\n    (activeProperty === null || expandedActiveProperty === '@graph')) {\n    // drop empty object, top-level @value/@list, or object with only @id\n    if(count === 0 || '@value' in rval || '@list' in rval ||\n      (count === 1 && '@id' in rval)) {\n      rval = null;\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Creates a JSON-LD node map (node ID => node).\n *\n * @param input the expanded JSON-LD to create a node map of.\n * @param [options] the options to use:\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [namer] (deprecated).\n *\n * @return the node map.\n */\nProcessor.prototype.createNodeMap = function(input, options) {\n  options = options || {};\n\n  // produce a map of all subjects and name each bnode\n  var issuer = options.namer || options.issuer || new IdentifierIssuer('_:b');\n  var graphs = {'@default': {}};\n  _createNodeMap(input, graphs, '@default', issuer);\n\n  // add all non-default graphs to default graph\n  return _mergeNodeMaps(graphs);\n};\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the expanded JSON-LD to flatten.\n *\n * @return the flattened output.\n */\nProcessor.prototype.flatten = function(input) {\n  var defaultGraph = this.createNodeMap(input);\n\n  // produce flattened output\n  var flattened = [];\n  var keys = Object.keys(defaultGraph).sort();\n  for(var ki = 0; ki < keys.length; ++ki) {\n    var node = defaultGraph[keys[ki]];\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      flattened.push(node);\n    }\n  }\n  return flattened;\n};\n\n/**\n * Performs JSON-LD framing.\n *\n * @param input the expanded JSON-LD to frame.\n * @param frame the expanded JSON-LD frame to use.\n * @param options the framing options.\n *\n * @return the framed output.\n */\nProcessor.prototype.frame = function(input, frame, options) {\n  // create framing state\n  var state = {\n    options: options,\n    graphs: {'@default': {}, '@merged': {}},\n    subjectStack: [],\n    link: {}\n  };\n\n  // produce a map of all graphs and name each bnode\n  // FIXME: currently uses subjects from @merged graph only\n  var issuer = new IdentifierIssuer('_:b');\n  _createNodeMap(input, state.graphs, '@merged', issuer);\n  state.subjects = state.graphs['@merged'];\n\n  // frame the subjects\n  var framed = [];\n  _frame(state, Object.keys(state.subjects).sort(), frame, framed, null);\n  return framed;\n};\n\n/**\n * Performs normalization on the given RDF dataset.\n *\n * @param dataset the RDF dataset to normalize.\n * @param options the normalization options.\n * @param callback(err, normalized) called once the operation completes.\n */\nProcessor.prototype.normalize = function(dataset, options, callback) {\n  if(options.algorithm === 'URDNA2015') {\n    return new URDNA2015(options).main(dataset, callback);\n  }\n  if(options.algorithm === 'URGNA2012') {\n    return new URGNA2012(options).main(dataset, callback);\n  }\n  callback(new Error(\n    'Invalid RDF Dataset Normalization algorithm: ' + options.algorithm));\n};\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset the RDF dataset.\n * @param options the RDF serialization options.\n * @param callback(err, output) called once the operation completes.\n */\nProcessor.prototype.fromRDF = function(dataset, options, callback) {\n  var defaultGraph = {};\n  var graphMap = {'@default': defaultGraph};\n  var referencedOnce = {};\n\n  for(var name in dataset) {\n    var graph = dataset[name];\n    if(!(name in graphMap)) {\n      graphMap[name] = {};\n    }\n    if(name !== '@default' && !(name in defaultGraph)) {\n      defaultGraph[name] = {'@id': name};\n    }\n    var nodeMap = graphMap[name];\n    for(var ti = 0; ti < graph.length; ++ti) {\n      var triple = graph[ti];\n\n      // get subject, predicate, object\n      var s = triple.subject.value;\n      var p = triple.predicate.value;\n      var o = triple.object;\n\n      if(!(s in nodeMap)) {\n        nodeMap[s] = {'@id': s};\n      }\n      var node = nodeMap[s];\n\n      var objectIsId = (o.type === 'IRI' || o.type === 'blank node');\n      if(objectIsId && !(o.value in nodeMap)) {\n        nodeMap[o.value] = {'@id': o.value};\n      }\n\n      if(p === RDF_TYPE && !options.useRdfType && objectIsId) {\n        jsonld.addValue(node, '@type', o.value, {propertyIsArray: true});\n        continue;\n      }\n\n      var value = _RDFToObject(o, options.useNativeTypes);\n      jsonld.addValue(node, p, value, {propertyIsArray: true});\n\n      // object may be an RDF list/partial list node but we can't know easily\n      // until all triples are read\n      if(objectIsId) {\n        if(o.value === RDF_NIL) {\n          // track rdf:nil uniquely per graph\n          var object = nodeMap[o.value];\n          if(!('usages' in object)) {\n            object.usages = [];\n          }\n          object.usages.push({\n            node: node,\n            property: p,\n            value: value\n          });\n        } else if(o.value in referencedOnce) {\n          // object referenced more than once\n          referencedOnce[o.value] = false;\n        } else {\n          // keep track of single reference\n          referencedOnce[o.value] = {\n            node: node,\n            property: p,\n            value: value\n          };\n        }\n      }\n    }\n  }\n\n  // convert linked lists to @list arrays\n  for(var name in graphMap) {\n    var graphObject = graphMap[name];\n\n    // no @lists to be converted, continue\n    if(!(RDF_NIL in graphObject)) {\n      continue;\n    }\n\n    // iterate backwards through each RDF list\n    var nil = graphObject[RDF_NIL];\n    for(var i = 0; i < nil.usages.length; ++i) {\n      var usage = nil.usages[i];\n      var node = usage.node;\n      var property = usage.property;\n      var head = usage.value;\n      var list = [];\n      var listNodes = [];\n\n      // ensure node is a well-formed list node; it must:\n      // 1. Be referenced only once.\n      // 2. Have an array for rdf:first that has 1 item.\n      // 3. Have an array for rdf:rest that has 1 item.\n      // 4. Have no keys other than: @id, rdf:first, rdf:rest, and,\n      //   optionally, @type where the value is rdf:List.\n      var nodeKeyCount = Object.keys(node).length;\n      while(property === RDF_REST &&\n        _isObject(referencedOnce[node['@id']]) &&\n        _isArray(node[RDF_FIRST]) && node[RDF_FIRST].length === 1 &&\n        _isArray(node[RDF_REST]) && node[RDF_REST].length === 1 &&\n        (nodeKeyCount === 3 || (nodeKeyCount === 4 && _isArray(node['@type']) &&\n          node['@type'].length === 1 && node['@type'][0] === RDF_LIST))) {\n        list.push(node[RDF_FIRST][0]);\n        listNodes.push(node['@id']);\n\n        // get next node, moving backwards through list\n        usage = referencedOnce[node['@id']];\n        node = usage.node;\n        property = usage.property;\n        head = usage.value;\n        nodeKeyCount = Object.keys(node).length;\n\n        // if node is not a blank node, then list head found\n        if(node['@id'].indexOf('_:') !== 0) {\n          break;\n        }\n      }\n\n      // the list is nested in another list\n      if(property === RDF_FIRST) {\n        // empty list\n        if(node['@id'] === RDF_NIL) {\n          // can't convert rdf:nil to a @list object because it would\n          // result in a list of lists which isn't supported\n          continue;\n        }\n\n        // preserve list head\n        head = graphObject[head['@id']][RDF_REST][0];\n        list.pop();\n        listNodes.pop();\n      }\n\n      // transform list into @list object\n      delete head['@id'];\n      head['@list'] = list.reverse();\n      for(var j = 0; j < listNodes.length; ++j) {\n        delete graphObject[listNodes[j]];\n      }\n    }\n\n    delete nil.usages;\n  }\n\n  var result = [];\n  var subjects = Object.keys(defaultGraph).sort();\n  for(var i = 0; i < subjects.length; ++i) {\n    var subject = subjects[i];\n    var node = defaultGraph[subject];\n    if(subject in graphMap) {\n      var graph = node['@graph'] = [];\n      var graphObject = graphMap[subject];\n      var subjects_ = Object.keys(graphObject).sort();\n      for(var si = 0; si < subjects_.length; ++si) {\n        var node_ = graphObject[subjects_[si]];\n        // only add full subjects to top-level\n        if(!_isSubjectReference(node_)) {\n          graph.push(node_);\n        }\n      }\n    }\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      result.push(node);\n    }\n  }\n\n  callback(null, result);\n};\n\n/**\n * Outputs an RDF dataset for the expanded JSON-LD input.\n *\n * @param input the expanded JSON-LD input.\n * @param options the RDF serialization options.\n *\n * @return the RDF dataset.\n */\nProcessor.prototype.toRDF = function(input, options) {\n  // create node map for default graph (and any named graphs)\n  var issuer = new IdentifierIssuer('_:b');\n  var nodeMap = {'@default': {}};\n  _createNodeMap(input, nodeMap, '@default', issuer);\n\n  var dataset = {};\n  var graphNames = Object.keys(nodeMap).sort();\n  for(var i = 0; i < graphNames.length; ++i) {\n    var graphName = graphNames[i];\n    // skip relative IRIs\n    if(graphName === '@default' || _isAbsoluteIri(graphName)) {\n      dataset[graphName] = _graphToRDF(nodeMap[graphName], issuer, options);\n    }\n  }\n  return dataset;\n};\n\n/**\n * Processes a local context and returns a new active context.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param options the context processing options.\n *\n * @return the new active context.\n */\nProcessor.prototype.processContext = function(activeCtx, localCtx, options) {\n  // normalize local context to an array of @context objects\n  if(_isObject(localCtx) && '@context' in localCtx &&\n    _isArray(localCtx['@context'])) {\n    localCtx = localCtx['@context'];\n  }\n  var ctxs = _isArray(localCtx) ? localCtx : [localCtx];\n\n  // no contexts in array, clone existing context\n  if(ctxs.length === 0) {\n    return activeCtx.clone();\n  }\n\n  // process each context in order, update active context\n  // on each iteration to ensure proper caching\n  var rval = activeCtx;\n  for(var i = 0; i < ctxs.length; ++i) {\n    var ctx = ctxs[i];\n\n    // reset to initial context\n    if(ctx === null) {\n      rval = activeCtx = _getInitialContext(options);\n      continue;\n    }\n\n    // dereference @context key if present\n    if(_isObject(ctx) && '@context' in ctx) {\n      ctx = ctx['@context'];\n    }\n\n    // context must be an object by now, all URLs retrieved before this call\n    if(!_isObject(ctx)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context must be an object.',\n        'jsonld.SyntaxError', {code: 'invalid local context', context: ctx});\n    }\n\n    // get context from cache if available\n    if(jsonld.cache.activeCtx) {\n      var cached = jsonld.cache.activeCtx.get(activeCtx, ctx);\n      if(cached) {\n        rval = activeCtx = cached;\n        continue;\n      }\n    }\n\n    // update active context and clone new one before updating\n    activeCtx = rval;\n    rval = rval.clone();\n\n    // define context mappings for keys in local context\n    var defined = {};\n\n    // handle @base\n    if('@base' in ctx) {\n      var base = ctx['@base'];\n\n      // clear base\n      if(base === null) {\n        base = null;\n      } else if(!_isString(base)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@base\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});\n      } else if(base !== '' && !_isAbsoluteIri(base)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@base\" in a ' +\n          '@context must be an absolute IRI or the empty string.',\n          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});\n      }\n\n      if(base !== null) {\n        base = jsonld.url.parse(base || '');\n      }\n      rval['@base'] = base;\n      defined['@base'] = true;\n    }\n\n    // handle @vocab\n    if('@vocab' in ctx) {\n      var value = ctx['@vocab'];\n      if(value === null) {\n        delete rval['@vocab'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else if(!_isAbsoluteIri(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be an absolute IRI.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else {\n        rval['@vocab'] = value;\n      }\n      defined['@vocab'] = true;\n    }\n\n    // handle @language\n    if('@language' in ctx) {\n      var value = ctx['@language'];\n      if(value === null) {\n        delete rval['@language'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@language\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError',\n          {code: 'invalid default language', context: ctx});\n      } else {\n        rval['@language'] = value.toLowerCase();\n      }\n      defined['@language'] = true;\n    }\n\n    // process all other keys\n    for(var key in ctx) {\n      _createTermDefinition(rval, ctx, key, defined);\n    }\n\n    // cache result\n    if(jsonld.cache.activeCtx) {\n      jsonld.cache.activeCtx.set(activeCtx, ctx, rval);\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Expands a language map.\n *\n * @param languageMap the language map to expand.\n *\n * @return the expanded language map.\n */\nfunction _expandLanguageMap(languageMap) {\n  var rval = [];\n  var keys = Object.keys(languageMap).sort();\n  for(var ki = 0; ki < keys.length; ++ki) {\n    var key = keys[ki];\n    var val = languageMap[key];\n    if(!_isArray(val)) {\n      val = [val];\n    }\n    for(var vi = 0; vi < val.length; ++vi) {\n      var item = val[vi];\n      if(item === null) {\n          // null values are allowed (8.5) but ignored (3.1)\n          continue;\n      }\n      if(!_isString(item)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; language map values must be strings.',\n          'jsonld.SyntaxError',\n          {code: 'invalid language map value', languageMap: languageMap});\n      }\n      rval.push({\n        '@value': item,\n        '@language': key.toLowerCase()\n      });\n    }\n  }\n  return rval;\n}\n\n/**\n * Labels the blank nodes in the given value using the given IdentifierIssuer.\n *\n * @param issuer the IdentifierIssuer to use.\n * @param element the element with blank nodes to rename.\n *\n * @return the element.\n */\nfunction _labelBlankNodes(issuer, element) {\n  if(_isArray(element)) {\n    for(var i = 0; i < element.length; ++i) {\n      element[i] = _labelBlankNodes(issuer, element[i]);\n    }\n  } else if(_isList(element)) {\n    element['@list'] = _labelBlankNodes(issuer, element['@list']);\n  } else if(_isObject(element)) {\n    // relabel blank node\n    if(_isBlankNode(element)) {\n      element['@id'] = issuer.getId(element['@id']);\n    }\n\n    // recursively apply to all keys\n    var keys = Object.keys(element).sort();\n    for(var ki = 0; ki < keys.length; ++ki) {\n      var key = keys[ki];\n      if(key !== '@id') {\n        element[key] = _labelBlankNodes(issuer, element[key]);\n      }\n    }\n  }\n\n  return element;\n}\n\n/**\n * Expands the given value by using the coercion and keyword rules in the\n * given context.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the active property the value is associated with.\n * @param value the value to expand.\n *\n * @return the expanded value.\n */\nfunction _expandValue(activeCtx, activeProperty, value) {\n  // nothing to expand\n  if(value === null || value === undefined) {\n    return null;\n  }\n\n  // special-case expand @id and @type (skips '@id' expansion)\n  var expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true});\n  if(expandedProperty === '@id') {\n    return _expandIri(activeCtx, value, {base: true});\n  } else if(expandedProperty === '@type') {\n    return _expandIri(activeCtx, value, {vocab: true, base: true});\n  }\n\n  // get type definition from context\n  var type = jsonld.getContextValue(activeCtx, activeProperty, '@type');\n\n  // do @id expansion (automatic for @graph)\n  if(type === '@id' || (expandedProperty === '@graph' && _isString(value))) {\n    return {'@id': _expandIri(activeCtx, value, {base: true})};\n  }\n  // do @id expansion w/vocab\n  if(type === '@vocab') {\n    return {'@id': _expandIri(activeCtx, value, {vocab: true, base: true})};\n  }\n\n  // do not expand keyword values\n  if(_isKeyword(expandedProperty)) {\n    return value;\n  }\n\n  var rval = {};\n\n  if(type !== null) {\n    // other type\n    rval['@type'] = type;\n  } else if(_isString(value)) {\n    // check for language tagging for strings\n    var language = jsonld.getContextValue(\n      activeCtx, activeProperty, '@language');\n    if(language !== null) {\n      rval['@language'] = language;\n    }\n  }\n  // do conversion of values that aren't basic JSON types to strings\n  if(['boolean', 'number', 'string'].indexOf(typeof value) === -1) {\n    value = value.toString();\n  }\n  rval['@value'] = value;\n\n  return rval;\n}\n\n/**\n * Creates an array of RDF triples for the given graph.\n *\n * @param graph the graph to create RDF triples for.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param options the RDF serialization options.\n *\n * @return the array of RDF triples for the given graph.\n */\nfunction _graphToRDF(graph, issuer, options) {\n  var rval = [];\n\n  var ids = Object.keys(graph).sort();\n  for(var i = 0; i < ids.length; ++i) {\n    var id = ids[i];\n    var node = graph[id];\n    var properties = Object.keys(node).sort();\n    for(var pi = 0; pi < properties.length; ++pi) {\n      var property = properties[pi];\n      var items = node[property];\n      if(property === '@type') {\n        property = RDF_TYPE;\n      } else if(_isKeyword(property)) {\n        continue;\n      }\n\n      for(var ii = 0; ii < items.length; ++ii) {\n        var item = items[ii];\n\n        // RDF subject\n        var subject = {};\n        subject.type = (id.indexOf('_:') === 0) ? 'blank node' : 'IRI';\n        subject.value = id;\n\n        // skip relative IRI subjects\n        if(!_isAbsoluteIri(id)) {\n          continue;\n        }\n\n        // RDF predicate\n        var predicate = {};\n        predicate.type = (property.indexOf('_:') === 0) ? 'blank node' : 'IRI';\n        predicate.value = property;\n\n        // skip relative IRI predicates\n        if(!_isAbsoluteIri(property)) {\n          continue;\n        }\n\n        // skip blank node predicates unless producing generalized RDF\n        if(predicate.type === 'blank node' && !options.produceGeneralizedRdf) {\n          continue;\n        }\n\n        // convert @list to triples\n        if(_isList(item)) {\n          _listToRDF(item['@list'], issuer, subject, predicate, rval);\n        } else {\n          // convert value or node object to triple\n          var object = _objectToRDF(item);\n          // skip null objects (they are relative IRIs)\n          if(object) {\n            rval.push({subject: subject, predicate: predicate, object: object});\n          }\n        }\n      }\n    }\n  }\n\n  return rval;\n}\n\n/**\n * Converts a @list value into linked list of blank node RDF triples\n * (an RDF collection).\n *\n * @param list the @list value.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param subject the subject for the head of the list.\n * @param predicate the predicate for the head of the list.\n * @param triples the array of triples to append to.\n */\nfunction _listToRDF(list, issuer, subject, predicate, triples) {\n  var first = {type: 'IRI', value: RDF_FIRST};\n  var rest = {type: 'IRI', value: RDF_REST};\n  var nil = {type: 'IRI', value: RDF_NIL};\n\n  for(var i = 0; i < list.length; ++i) {\n    var item = list[i];\n\n    var blankNode = {type: 'blank node', value: issuer.getId()};\n    triples.push({subject: subject, predicate: predicate, object: blankNode});\n\n    subject = blankNode;\n    predicate = first;\n    var object = _objectToRDF(item);\n\n    // skip null objects (they are relative IRIs)\n    if(object) {\n      triples.push({subject: subject, predicate: predicate, object: object});\n    }\n\n    predicate = rest;\n  }\n\n  triples.push({subject: subject, predicate: predicate, object: nil});\n}\n\n/**\n * Converts a JSON-LD value object to an RDF literal or a JSON-LD string or\n * node object to an RDF resource.\n *\n * @param item the JSON-LD value or node object.\n *\n * @return the RDF literal or RDF resource.\n */\nfunction _objectToRDF(item) {\n  var object = {};\n\n  // convert value object to RDF\n  if(_isValue(item)) {\n    object.type = 'literal';\n    var value = item['@value'];\n    var datatype = item['@type'] || null;\n\n    // convert to XSD datatypes as appropriate\n    if(_isBoolean(value)) {\n      object.value = value.toString();\n      object.datatype = datatype || XSD_BOOLEAN;\n    } else if(_isDouble(value) || datatype === XSD_DOUBLE) {\n      if(!_isDouble(value)) {\n        value = parseFloat(value);\n      }\n      // canonical double representation\n      object.value = value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n      object.datatype = datatype || XSD_DOUBLE;\n    } else if(_isNumber(value)) {\n      object.value = value.toFixed(0);\n      object.datatype = datatype || XSD_INTEGER;\n    } else if('@language' in item) {\n      object.value = value;\n      object.datatype = datatype || RDF_LANGSTRING;\n      object.language = item['@language'];\n    } else {\n      object.value = value;\n      object.datatype = datatype || XSD_STRING;\n    }\n  } else {\n    // convert string/node object to RDF\n    var id = _isObject(item) ? item['@id'] : item;\n    object.type = (id.indexOf('_:') === 0) ? 'blank node' : 'IRI';\n    object.value = id;\n  }\n\n  // skip relative IRIs\n  if(object.type === 'IRI' && !_isAbsoluteIri(object.value)) {\n    return null;\n  }\n\n  return object;\n}\n\n/**\n * Converts an RDF triple object to a JSON-LD object.\n *\n * @param o the RDF triple object to convert.\n * @param useNativeTypes true to output native types, false not to.\n *\n * @return the JSON-LD object.\n */\nfunction _RDFToObject(o, useNativeTypes) {\n  // convert IRI/blank node object to JSON-LD\n  if(o.type === 'IRI' || o.type === 'blank node') {\n    return {'@id': o.value};\n  }\n\n  // convert literal to JSON-LD\n  var rval = {'@value': o.value};\n\n  // add language\n  if(o.language) {\n    rval['@language'] = o.language;\n  } else {\n    var type = o.datatype;\n    if(!type) {\n      type = XSD_STRING;\n    }\n    // use native types for certain xsd types\n    if(useNativeTypes) {\n      if(type === XSD_BOOLEAN) {\n        if(rval['@value'] === 'true') {\n          rval['@value'] = true;\n        } else if(rval['@value'] === 'false') {\n          rval['@value'] = false;\n        }\n      } else if(_isNumeric(rval['@value'])) {\n        if(type === XSD_INTEGER) {\n          var i = parseInt(rval['@value'], 10);\n          if(i.toFixed(0) === rval['@value']) {\n            rval['@value'] = i;\n          }\n        } else if(type === XSD_DOUBLE) {\n          rval['@value'] = parseFloat(rval['@value']);\n        }\n      }\n      // do not add native type\n      if([XSD_BOOLEAN, XSD_INTEGER, XSD_DOUBLE, XSD_STRING]\n        .indexOf(type) === -1) {\n        rval['@type'] = type;\n      }\n    } else if(type !== XSD_STRING) {\n      rval['@type'] = type;\n    }\n  }\n\n  return rval;\n}\n\n/**\n * Compares two RDF triples for equality.\n *\n * @param t1 the first triple.\n * @param t2 the second triple.\n *\n * @return true if the triples are the same, false if not.\n */\nfunction _compareRDFTriples(t1, t2) {\n  var attrs = ['subject', 'predicate', 'object'];\n  for(var i = 0; i < attrs.length; ++i) {\n    var attr = attrs[i];\n    if(t1[attr].type !== t2[attr].type || t1[attr].value !== t2[attr].value) {\n      return false;\n    }\n  }\n  if(t1.object.language !== t2.object.language) {\n    return false;\n  }\n  if(t1.object.datatype !== t2.object.datatype) {\n    return false;\n  }\n  return true;\n}\n\n/////////////////////////////// DEFINE URDNA2015 //////////////////////////////\n\nvar URDNA2015 = (function() {\n\nvar POSITIONS = {'subject': 's', 'object': 'o', 'name': 'g'};\n\nvar Normalize = function(options) {\n  options = options || {};\n  this.name = 'URDNA2015';\n  this.options = options;\n  this.blankNodeInfo = {};\n  this.hashToBlankNodes = {};\n  this.canonicalIssuer = new IdentifierIssuer('_:c14n');\n  this.quads = [];\n  this.schedule = {};\n  if('maxCallStackDepth' in options) {\n    this.schedule.MAX_DEPTH = options.maxCallStackDepth;\n  } else {\n    this.schedule.MAX_DEPTH = 500;\n  }\n  if('maxTotalCallStackDepth' in options) {\n    this.schedule.MAX_TOTAL_DEPTH = options.maxCallStackDepth;\n  } else {\n    this.schedule.MAX_TOTAL_DEPTH = 0xFFFFFFFF;\n  }\n  this.schedule.depth = 0;\n  this.schedule.totalDepth = 0;\n  if('timeSlice' in options) {\n    this.schedule.timeSlice = options.timeSlice;\n  } else {\n    // milliseconds\n    this.schedule.timeSlice = 10;\n  }\n};\n\n// do some work in a time slice, but in serial\nNormalize.prototype.doWork = function(fn, callback) {\n  var schedule = this.schedule;\n\n  if(schedule.totalDepth >= schedule.MAX_TOTAL_DEPTH) {\n    return callback(new Error(\n      'Maximum total call stack depth exceeded; normalization aborting.'));\n  }\n\n  (function work() {\n    if(schedule.depth === schedule.MAX_DEPTH) {\n      // stack too deep, run on next tick\n      schedule.depth = 0;\n      schedule.running = false;\n      return jsonld.nextTick(work);\n    }\n\n    // if not yet running, force run\n    var now = new Date().getTime();\n    if(!schedule.running) {\n      schedule.start = new Date().getTime();\n      schedule.deadline = schedule.start + schedule.timeSlice;\n    }\n\n    // TODO: should also include an estimate of expectedWorkTime\n    if(now < schedule.deadline) {\n      schedule.running = true;\n      schedule.depth++;\n      schedule.totalDepth++;\n      return fn(function(err, result) {\n        schedule.depth--;\n        schedule.totalDepth--;\n        callback(err, result);\n      });\n    }\n\n    // not enough time left in this slice, run after letting browser\n    // do some other things\n    schedule.depth = 0;\n    schedule.running = false;\n    jsonld.setImmediate(work);\n  })();\n};\n\n// asynchronously loop\nNormalize.prototype.forEach = function(iterable, fn, callback) {\n  var self = this;\n  var iterator;\n  var idx = 0;\n  var length;\n  if(_isArray(iterable)) {\n    length = iterable.length;\n    iterator = function() {\n      if(idx === length) {\n        return false;\n      }\n      iterator.value = iterable[idx++];\n      iterator.key = idx;\n      return true;\n    };\n  } else {\n    var keys = Object.keys(iterable);\n    length = keys.length;\n    iterator = function() {\n      if(idx === length) {\n        return false;\n      }\n      iterator.key = keys[idx++];\n      iterator.value = iterable[iterator.key];\n      return true;\n    };\n  }\n\n  (function iterate(err, result) {\n    if(err) {\n      return callback(err);\n    }\n    if(iterator()) {\n      return self.doWork(function() {\n        fn(iterator.value, iterator.key, iterate);\n      });\n    }\n    callback();\n  })();\n};\n\n// asynchronous waterfall\nNormalize.prototype.waterfall = function(fns, callback) {\n  var self = this;\n  self.forEach(fns, function(fn, idx, callback) {\n    self.doWork(fn, callback);\n  }, callback);\n};\n\n// asynchronous while\nNormalize.prototype.whilst = function(condition, fn, callback) {\n  var self = this;\n  (function loop(err) {\n    if(err) {\n      return callback(err);\n    }\n    if(!condition()) {\n      return callback();\n    }\n    self.doWork(fn, loop);\n  })();\n};\n\n// 4.4) Normalization Algorithm\nNormalize.prototype.main = function(dataset, callback) {\n  var self = this;\n  self.schedule.start = new Date().getTime();\n  var result;\n\n  // handle invalid output format\n  if(self.options.format) {\n    if(self.options.format !== 'application/nquads') {\n      return callback(new JsonLdError(\n        'Unknown output format.',\n        'jsonld.UnknownFormat', {format: self.options.format}));\n    }\n  }\n\n  // 1) Create the normalization state.\n\n  // Note: Optimize by generating non-normalized blank node map concurrently.\n  var nonNormalized = {};\n\n  self.waterfall([\n    function(callback) {\n      // 2) For every quad in input dataset:\n      self.forEach(dataset, function(triples, graphName, callback) {\n        if(graphName === '@default') {\n          graphName = null;\n        }\n        self.forEach(triples, function(quad, idx, callback) {\n          if(graphName !== null) {\n            if(graphName.indexOf('_:') === 0) {\n              quad.name = {type: 'blank node', value: graphName};\n            } else {\n              quad.name = {type: 'IRI', value: graphName};\n            }\n          }\n          self.quads.push(quad);\n\n          // 2.1) For each blank node that occurs in the quad, add a reference\n          // to the quad using the blank node identifier in the blank node to\n          // quads map, creating a new entry if necessary.\n          self.forEachComponent(quad, function(component) {\n            if(component.type !== 'blank node') {\n              return;\n            }\n            var id = component.value;\n            if(id in self.blankNodeInfo) {\n              self.blankNodeInfo[id].quads.push(quad);\n            } else {\n              nonNormalized[id] = true;\n              self.blankNodeInfo[id] = {quads: [quad]};\n            }\n          });\n          callback();\n        }, callback);\n      }, callback);\n    },\n    function(callback) {\n      // 3) Create a list of non-normalized blank node identifiers\n      // non-normalized identifiers and populate it using the keys from the\n      // blank node to quads map.\n      // Note: We use a map here and it was generated during step 2.\n\n      // 4) Initialize simple, a boolean flag, to true.\n      var simple = true;\n\n      // 5) While simple is true, issue canonical identifiers for blank nodes:\n      self.whilst(function() { return simple; }, function(callback) {\n        // 5.1) Set simple to false.\n        simple = false;\n\n        // 5.2) Clear hash to blank nodes map.\n        self.hashToBlankNodes = {};\n\n        self.waterfall([\n          function(callback) {\n            // 5.3) For each blank node identifier identifier in non-normalized\n            // identifiers:\n            self.forEach(nonNormalized, function(value, id, callback) {\n              // 5.3.1) Create a hash, hash, according to the Hash First Degree\n              // Quads algorithm.\n              self.hashFirstDegreeQuads(id, function(err, hash) {\n                if(err) {\n                  return callback(err);\n                }\n                // 5.3.2) Add hash and identifier to hash to blank nodes map,\n                // creating a new entry if necessary.\n                if(hash in self.hashToBlankNodes) {\n                  self.hashToBlankNodes[hash].push(id);\n                } else {\n                  self.hashToBlankNodes[hash] = [id];\n                }\n                callback();\n              });\n            }, callback);\n          },\n          function(callback) {\n            // 5.4) For each hash to identifier list mapping in hash to blank\n            // nodes map, lexicographically-sorted by hash:\n            var hashes = Object.keys(self.hashToBlankNodes).sort();\n            self.forEach(hashes, function(hash, i, callback) {\n              // 5.4.1) If the length of identifier list is greater than 1,\n              // continue to the next mapping.\n              var idList = self.hashToBlankNodes[hash];\n              if(idList.length > 1) {\n                return callback();\n              }\n\n              // 5.4.2) Use the Issue Identifier algorithm, passing canonical\n              // issuer and the single blank node identifier in identifier\n              // list, identifier, to issue a canonical replacement identifier\n              // for identifier.\n              // TODO: consider changing `getId` to `issue`\n              var id = idList[0];\n              self.canonicalIssuer.getId(id);\n\n              // 5.4.3) Remove identifier from non-normalized identifiers.\n              delete nonNormalized[id];\n\n              // 5.4.4) Remove hash from the hash to blank nodes map.\n              delete self.hashToBlankNodes[hash];\n\n              // 5.4.5) Set simple to true.\n              simple = true;\n              callback();\n            }, callback);\n          }\n        ], callback);\n      }, callback);\n    },\n    function(callback) {\n      // 6) For each hash to identifier list mapping in hash to blank nodes map,\n      // lexicographically-sorted by hash:\n      var hashes = Object.keys(self.hashToBlankNodes).sort();\n      self.forEach(hashes, function(hash, idx, callback) {\n        // 6.1) Create hash path list where each item will be a result of\n        // running the Hash N-Degree Quads algorithm.\n        var hashPathList = [];\n\n        // 6.2) For each blank node identifier identifier in identifier list:\n        var idList = self.hashToBlankNodes[hash];\n        self.waterfall([\n          function(callback) {\n            self.forEach(idList, function(id, idx, callback) {\n              // 6.2.1) If a canonical identifier has already been issued for\n              // identifier, continue to the next identifier.\n              if(self.canonicalIssuer.hasId(id)) {\n                return callback();\n              }\n\n              // 6.2.2) Create temporary issuer, an identifier issuer\n              // initialized with the prefix _:b.\n              var issuer = new IdentifierIssuer('_:b');\n\n              // 6.2.3) Use the Issue Identifier algorithm, passing temporary\n              // issuer and identifier, to issue a new temporary blank node\n              // identifier for identifier.\n              issuer.getId(id);\n\n              // 6.2.4) Run the Hash N-Degree Quads algorithm, passing\n              // temporary issuer, and append the result to the hash path list.\n              self.hashNDegreeQuads(id, issuer, function(err, result) {\n                if(err) {\n                  return callback(err);\n                }\n                hashPathList.push(result);\n                callback();\n              });\n            }, callback);\n          },\n          function(callback) {\n            // 6.3) For each result in the hash path list,\n            // lexicographically-sorted by the hash in result:\n            hashPathList.sort(function(a, b) {\n              return (a.hash < b.hash) ? -1 : ((a.hash > b.hash) ? 1 : 0);\n            });\n            self.forEach(hashPathList, function(result, idx, callback) {\n              // 6.3.1) For each blank node identifier, existing identifier,\n              // that was issued a temporary identifier by identifier issuer\n              // in result, issue a canonical identifier, in the same order,\n              // using the Issue Identifier algorithm, passing canonical\n              // issuer and existing identifier.\n              for(var existing in result.issuer.existing) {\n                self.canonicalIssuer.getId(existing);\n              }\n              callback();\n            }, callback);\n          }\n        ], callback);\n      }, callback);\n    }, function(callback) {\n      /* Note: At this point all blank nodes in the set of RDF quads have been\n      assigned canonical identifiers, which have been stored in the canonical\n      issuer. Here each quad is updated by assigning each of its blank nodes\n      its new identifier. */\n\n      // 7) For each quad, quad, in input dataset:\n      var normalized = [];\n      self.waterfall([\n        function(callback) {\n          self.forEach(self.quads, function(quad, idx, callback) {\n            // 7.1) Create a copy, quad copy, of quad and replace any existing\n            // blank node identifiers using the canonical identifiers\n            // previously issued by canonical issuer.\n            // Note: We optimize away the copy here.\n            self.forEachComponent(quad, function(component) {\n              if(component.type === 'blank node' &&\n                component.value.indexOf(self.canonicalIssuer.prefix) !== 0) {\n                component.value = self.canonicalIssuer.getId(component.value);\n              }\n            });\n            // 7.2) Add quad copy to the normalized dataset.\n            normalized.push(_toNQuad(quad));\n            callback();\n          }, callback);\n        },\n        function(callback) {\n          // sort normalized output\n          normalized.sort();\n\n          // 8) Return the normalized dataset.\n          if(self.options.format === 'application/nquads') {\n            result = normalized.join('');\n            return callback();\n          }\n\n          result = _parseNQuads(normalized.join(''));\n          callback();\n        }\n      ], callback);\n    }\n  ], function(err) {\n    callback(err, result);\n  });\n};\n\n// 4.6) Hash First Degree Quads\nNormalize.prototype.hashFirstDegreeQuads = function(id, callback) {\n  var self = this;\n\n  // return cached hash\n  var info = self.blankNodeInfo[id];\n  if('hash' in info) {\n    return callback(null, info.hash);\n  }\n\n  // 1) Initialize nquads to an empty list. It will be used to store quads in\n  // N-Quads format.\n  var nquads = [];\n\n  // 2) Get the list of quads quads associated with the reference blank node\n  // identifier in the blank node to quads map.\n  var quads = info.quads;\n\n  // 3) For each quad quad in quads:\n  self.forEach(quads, function(quad, idx, callback) {\n    // 3.1) Serialize the quad in N-Quads format with the following special\n    // rule:\n\n    // 3.1.1) If any component in quad is an blank node, then serialize it\n    // using a special identifier as follows:\n    var copy = {predicate: quad.predicate};\n    self.forEachComponent(quad, function(component, key) {\n      // 3.1.2) If the blank node's existing blank node identifier matches the\n      // reference blank node identifier then use the blank node identifier _:a,\n      // otherwise, use the blank node identifier _:z.\n      copy[key] = self.modifyFirstDegreeComponent(id, component, key);\n    });\n    nquads.push(_toNQuad(copy));\n    callback();\n  }, function(err) {\n    if(err) {\n      return callback(err);\n    }\n    // 4) Sort nquads in lexicographical order.\n    nquads.sort();\n\n    // 5) Return the hash that results from passing the sorted, joined nquads\n    // through the hash algorithm.\n    info.hash = NormalizeHash.hashNQuads(self.name, nquads);\n    callback(null, info.hash);\n  });\n};\n\n// helper for modifying component during Hash First Degree Quads\nNormalize.prototype.modifyFirstDegreeComponent = function(id, component) {\n  if(component.type !== 'blank node') {\n    return component;\n  }\n  component = _clone(component);\n  component.value = (component.value === id ? '_:a' : '_:z');\n  return component;\n};\n\n// 4.7) Hash Related Blank Node\nNormalize.prototype.hashRelatedBlankNode = function(\n  related, quad, issuer, position, callback) {\n  var self = this;\n\n  // 1) Set the identifier to use for related, preferring first the canonical\n  // identifier for related if issued, second the identifier issued by issuer\n  // if issued, and last, if necessary, the result of the Hash First Degree\n  // Quads algorithm, passing related.\n  var id;\n  self.waterfall([\n    function(callback) {\n      if(self.canonicalIssuer.hasId(related)) {\n        id = self.canonicalIssuer.getId(related);\n        return callback();\n      }\n      if(issuer.hasId(related)) {\n        id = issuer.getId(related);\n        return callback();\n      }\n      self.hashFirstDegreeQuads(related, function(err, hash) {\n        if(err) {\n          return callback(err);\n        }\n        id = hash;\n        callback();\n      });\n    }\n  ], function(err) {\n    if(err) {\n      return callback(err);\n    }\n\n    // 2) Initialize a string input to the value of position.\n    // Note: We use a hash object instead.\n    var md = new NormalizeHash(self.name);\n    md.update(position);\n\n    // 3) If position is not g, append <, the value of the predicate in quad,\n    // and > to input.\n    if(position !== 'g') {\n      md.update(self.getRelatedPredicate(quad));\n    }\n\n    // 4) Append identifier to input.\n    md.update(id);\n\n    // 5) Return the hash that results from passing input through the hash\n    // algorithm.\n    return callback(null, md.digest());\n  });\n};\n\n// helper for getting a related predicate\nNormalize.prototype.getRelatedPredicate = function(quad) {\n  return '<' + quad.predicate.value + '>';\n};\n\n// 4.8) Hash N-Degree Quads\nNormalize.prototype.hashNDegreeQuads = function(id, issuer, callback) {\n  var self = this;\n\n  // 1) Create a hash to related blank nodes map for storing hashes that\n  // identify related blank nodes.\n  // Note: 2) and 3) handled within `createHashToRelated`\n  var hashToRelated;\n  var md = new NormalizeHash(self.name);\n  self.waterfall([\n    function(callback) {\n      self.createHashToRelated(id, issuer, function(err, result) {\n        if(err) {\n          return callback(err);\n        }\n        hashToRelated = result;\n        callback();\n      });\n    },\n    function(callback) {\n      // 4) Create an empty string, data to hash.\n      // Note: We created a hash object `md` above instead.\n\n      // 5) For each related hash to blank node list mapping in hash to related\n      // blank nodes map, sorted lexicographically by related hash:\n      var hashes = Object.keys(hashToRelated).sort();\n      self.forEach(hashes, function(hash, idx, callback) {\n        // 5.1) Append the related hash to the data to hash.\n        md.update(hash);\n\n        // 5.2) Create a string chosen path.\n        var chosenPath = '';\n\n        // 5.3) Create an unset chosen issuer variable.\n        var chosenIssuer;\n\n        // 5.4) For each permutation of blank node list:\n        var permutator = new Permutator(hashToRelated[hash]);\n        self.whilst(\n          function() { return permutator.hasNext(); },\n          function(nextPermutation) {\n          var permutation = permutator.next();\n\n          // 5.4.1) Create a copy of issuer, issuer copy.\n          var issuerCopy = issuer.clone();\n\n          // 5.4.2) Create a string path.\n          var path = '';\n\n          // 5.4.3) Create a recursion list, to store blank node identifiers\n          // that must be recursively processed by this algorithm.\n          var recursionList = [];\n\n          self.waterfall([\n            function(callback) {\n              // 5.4.4) For each related in permutation:\n              self.forEach(permutation, function(related, idx, callback) {\n                // 5.4.4.1) If a canonical identifier has been issued for\n                // related, append it to path.\n                if(self.canonicalIssuer.hasId(related)) {\n                  path += self.canonicalIssuer.getId(related);\n                } else {\n                  // 5.4.4.2) Otherwise:\n                  // 5.4.4.2.1) If issuer copy has not issued an identifier for\n                  // related, append related to recursion list.\n                  if(!issuerCopy.hasId(related)) {\n                    recursionList.push(related);\n                  }\n                  // 5.4.4.2.2) Use the Issue Identifier algorithm, passing\n                  // issuer copy and related and append the result to path.\n                  path += issuerCopy.getId(related);\n                }\n\n                // 5.4.4.3) If chosen path is not empty and the length of path\n                // is greater than or equal to the length of chosen path and\n                // path is lexicographically greater than chosen path, then\n                // skip to the next permutation.\n                if(chosenPath.length !== 0 &&\n                  path.length >= chosenPath.length && path > chosenPath) {\n                  // FIXME: may cause inaccurate total depth calculation\n                  return nextPermutation();\n                }\n                callback();\n              }, callback);\n            },\n            function(callback) {\n              // 5.4.5) For each related in recursion list:\n              self.forEach(recursionList, function(related, idx, callback) {\n                // 5.4.5.1) Set result to the result of recursively executing\n                // the Hash N-Degree Quads algorithm, passing related for\n                // identifier and issuer copy for path identifier issuer.\n                self.hashNDegreeQuads(\n                  related, issuerCopy, function(err, result) {\n                  if(err) {\n                    return callback(err);\n                  }\n\n                  // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer\n                  // copy and related and append the result to path.\n                  path += issuerCopy.getId(related);\n\n                  // 5.4.5.3) Append <, the hash in result, and > to path.\n                  path += '<' + result.hash + '>';\n\n                  // 5.4.5.4) Set issuer copy to the identifier issuer in\n                  // result.\n                  issuerCopy = result.issuer;\n\n                  // 5.4.5.5) If chosen path is not empty and the length of path\n                  // is greater than or equal to the length of chosen path and\n                  // path is lexicographically greater than chosen path, then\n                  // skip to the next permutation.\n                  if(chosenPath.length !== 0 &&\n                    path.length >= chosenPath.length && path > chosenPath) {\n                    // FIXME: may cause inaccurate total depth calculation\n                    return nextPermutation();\n                  }\n                  callback();\n                });\n              }, callback);\n            },\n            function(callback) {\n              // 5.4.6) If chosen path is empty or path is lexicographically\n              // less than chosen path, set chosen path to path and chosen\n              // issuer to issuer copy.\n              if(chosenPath.length === 0 || path < chosenPath) {\n                chosenPath = path;\n                chosenIssuer = issuerCopy;\n              }\n              callback();\n            }\n          ], nextPermutation);\n        }, function(err) {\n          if(err) {\n            return callback(err);\n          }\n\n          // 5.5) Append chosen path to data to hash.\n          md.update(chosenPath);\n\n          // 5.6) Replace issuer, by reference, with chosen issuer.\n          issuer = chosenIssuer;\n          callback();\n        });\n      }, callback);\n    }\n  ], function(err) {\n    // 6) Return issuer and the hash that results from passing data to hash\n    // through the hash algorithm.\n    callback(err, {hash: md.digest(), issuer: issuer});\n  });\n};\n\n// helper for creating hash to related blank nodes map\nNormalize.prototype.createHashToRelated = function(id, issuer, callback) {\n  var self = this;\n\n  // 1) Create a hash to related blank nodes map for storing hashes that\n  // identify related blank nodes.\n  var hashToRelated = {};\n\n  // 2) Get a reference, quads, to the list of quads in the blank node to\n  // quads map for the key identifier.\n  var quads = self.blankNodeInfo[id].quads;\n\n  // 3) For each quad in quads:\n  self.forEach(quads, function(quad, idx, callback) {\n    // 3.1) For each component in quad, if component is the subject, object,\n    // and graph name and it is a blank node that is not identified by\n    // identifier:\n    self.forEach(quad, function(component, key, callback) {\n      if(key === 'predicate' ||\n        !(component.type === 'blank node' && component.value !== id)) {\n        return callback();\n      }\n      // 3.1.1) Set hash to the result of the Hash Related Blank Node\n      // algorithm, passing the blank node identifier for component as\n      // related, quad, path identifier issuer as issuer, and position as\n      // either s, o, or g based on whether component is a subject, object,\n      // graph name, respectively.\n      var related = component.value;\n      var position = POSITIONS[key];\n      self.hashRelatedBlankNode(\n        related, quad, issuer, position, function(err, hash) {\n        if(err) {\n          return callback(err);\n        }\n        // 3.1.2) Add a mapping of hash to the blank node identifier for\n        // component to hash to related blank nodes map, adding an entry as\n        // necessary.\n        if(hash in hashToRelated) {\n          hashToRelated[hash].push(related);\n        } else {\n          hashToRelated[hash] = [related];\n        }\n        callback();\n      });\n    }, callback);\n  }, function(err) {\n    callback(err, hashToRelated);\n  });\n};\n\n// helper that iterates over quad components (skips predicate)\nNormalize.prototype.forEachComponent = function(quad, op) {\n  for(var key in quad) {\n    // skip `predicate`\n    if(key === 'predicate') {\n      continue;\n    }\n    op(quad[key], key, quad);\n  }\n};\n\nreturn Normalize;\n\n})(); // end of define URDNA2015\n\n/////////////////////////////// DEFINE URGNA2012 //////////////////////////////\n\nvar URGNA2012 = (function() {\n\nvar Normalize = function(options) {\n  URDNA2015.call(this, options);\n  this.name = 'URGNA2012';\n};\nNormalize.prototype = new URDNA2015();\n\n// helper for modifying component during Hash First Degree Quads\nNormalize.prototype.modifyFirstDegreeComponent = function(id, component, key) {\n  if(component.type !== 'blank node') {\n    return component;\n  }\n  component = _clone(component);\n  if(key === 'name') {\n    component.value = '_:g';\n  } else {\n    component.value = (component.value === id ? '_:a' : '_:z');\n  }\n  return component;\n};\n\n// helper for getting a related predicate\nNormalize.prototype.getRelatedPredicate = function(quad) {\n  return quad.predicate.value;\n};\n\n// helper for creating hash to related blank nodes map\nNormalize.prototype.createHashToRelated = function(id, issuer, callback) {\n  var self = this;\n\n  // 1) Create a hash to related blank nodes map for storing hashes that\n  // identify related blank nodes.\n  var hashToRelated = {};\n\n  // 2) Get a reference, quads, to the list of quads in the blank node to\n  // quads map for the key identifier.\n  var quads = self.blankNodeInfo[id].quads;\n\n  // 3) For each quad in quads:\n  self.forEach(quads, function(quad, idx, callback) {\n    // 3.1) If the quad's subject is a blank node that does not match\n    // identifier, set hash to the result of the Hash Related Blank Node\n    // algorithm, passing the blank node identifier for subject as related,\n    // quad, path identifier issuer as issuer, and p as position.\n    var position;\n    var related;\n    if(quad.subject.type === 'blank node' && quad.subject.value !== id) {\n      related = quad.subject.value;\n      position = 'p';\n    } else if(quad.object.type === 'blank node' && quad.object.value !== id) {\n      // 3.2) Otherwise, if quad's object is a blank node that does not match\n      // identifier, to the result of the Hash Related Blank Node algorithm,\n      // passing the blank node identifier for object as related, quad, path\n      // identifier issuer as issuer, and r as position.\n      related = quad.object.value;\n      position = 'r';\n    } else {\n      // 3.3) Otherwise, continue to the next quad.\n      return callback();\n    }\n    // 3.4) Add a mapping of hash to the blank node identifier for the\n    // component that matched (subject or object) to hash to related blank\n    // nodes map, adding an entry as necessary.\n    self.hashRelatedBlankNode(\n      related, quad, issuer, position, function(err, hash) {\n      if(hash in hashToRelated) {\n        hashToRelated[hash].push(related);\n      } else {\n        hashToRelated[hash] = [related];\n      }\n      callback();\n    });\n  }, function(err) {\n    callback(err, hashToRelated);\n  });\n};\n\nreturn Normalize;\n\n})(); // end of define URGNA2012\n\n/**\n * Recursively flattens the subjects in the given JSON-LD expanded input\n * into a node map.\n *\n * @param input the JSON-LD expanded input.\n * @param graphs a map of graph name to subject map.\n * @param graph the name of the current graph.\n * @param issuer the blank node identifier issuer.\n * @param name the name assigned to the current input if it is a bnode.\n * @param list the list to append to, null for none.\n */\nfunction _createNodeMap(input, graphs, graph, issuer, name, list) {\n  // recurse through array\n  if(_isArray(input)) {\n    for(var i = 0; i < input.length; ++i) {\n      _createNodeMap(input[i], graphs, graph, issuer, undefined, list);\n    }\n    return;\n  }\n\n  // add non-object to list\n  if(!_isObject(input)) {\n    if(list) {\n      list.push(input);\n    }\n    return;\n  }\n\n  // add values to list\n  if(_isValue(input)) {\n    if('@type' in input) {\n      var type = input['@type'];\n      // rename @type blank node\n      if(type.indexOf('_:') === 0) {\n        input['@type'] = type = issuer.getId(type);\n      }\n    }\n    if(list) {\n      list.push(input);\n    }\n    return;\n  }\n\n  // Note: At this point, input must be a subject.\n\n  // spec requires @type to be named first, so assign names early\n  if('@type' in input) {\n    var types = input['@type'];\n    for(var i = 0; i < types.length; ++i) {\n      var type = types[i];\n      if(type.indexOf('_:') === 0) {\n        issuer.getId(type);\n      }\n    }\n  }\n\n  // get name for subject\n  if(_isUndefined(name)) {\n    name = _isBlankNode(input) ? issuer.getId(input['@id']) : input['@id'];\n  }\n\n  // add subject reference to list\n  if(list) {\n    list.push({'@id': name});\n  }\n\n  // create new subject or merge into existing one\n  var subjects = graphs[graph];\n  var subject = subjects[name] = subjects[name] || {};\n  subject['@id'] = name;\n  var properties = Object.keys(input).sort();\n  for(var pi = 0; pi < properties.length; ++pi) {\n    var property = properties[pi];\n\n    // skip @id\n    if(property === '@id') {\n      continue;\n    }\n\n    // handle reverse properties\n    if(property === '@reverse') {\n      var referencedNode = {'@id': name};\n      var reverseMap = input['@reverse'];\n      for(var reverseProperty in reverseMap) {\n        var items = reverseMap[reverseProperty];\n        for(var ii = 0; ii < items.length; ++ii) {\n          var item = items[ii];\n          var itemName = item['@id'];\n          if(_isBlankNode(item)) {\n            itemName = issuer.getId(itemName);\n          }\n          _createNodeMap(item, graphs, graph, issuer, itemName);\n          jsonld.addValue(\n            subjects[itemName], reverseProperty, referencedNode,\n            {propertyIsArray: true, allowDuplicate: false});\n        }\n      }\n      continue;\n    }\n\n    // recurse into graph\n    if(property === '@graph') {\n      // add graph subjects map entry\n      if(!(name in graphs)) {\n        graphs[name] = {};\n      }\n      var g = (graph === '@merged') ? graph : name;\n      _createNodeMap(input[property], graphs, g, issuer);\n      continue;\n    }\n\n    // copy non-@type keywords\n    if(property !== '@type' && _isKeyword(property)) {\n      if(property === '@index' && property in subject &&\n        (input[property] !== subject[property] ||\n        input[property]['@id'] !== subject[property]['@id'])) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; conflicting @index property detected.',\n          'jsonld.SyntaxError',\n          {code: 'conflicting indexes', subject: subject});\n      }\n      subject[property] = input[property];\n      continue;\n    }\n\n    // iterate over objects\n    var objects = input[property];\n\n    // if property is a bnode, assign it a new id\n    if(property.indexOf('_:') === 0) {\n      property = issuer.getId(property);\n    }\n\n    // ensure property is added for empty arrays\n    if(objects.length === 0) {\n      jsonld.addValue(subject, property, [], {propertyIsArray: true});\n      continue;\n    }\n    for(var oi = 0; oi < objects.length; ++oi) {\n      var o = objects[oi];\n\n      if(property === '@type') {\n        // rename @type blank nodes\n        o = (o.indexOf('_:') === 0) ? issuer.getId(o) : o;\n      }\n\n      // handle embedded subject or subject reference\n      if(_isSubject(o) || _isSubjectReference(o)) {\n        // relabel blank node @id\n        var id = _isBlankNode(o) ? issuer.getId(o['@id']) : o['@id'];\n\n        // add reference and recurse\n        jsonld.addValue(\n          subject, property, {'@id': id},\n          {propertyIsArray: true, allowDuplicate: false});\n        _createNodeMap(o, graphs, graph, issuer, id);\n      } else if(_isList(o)) {\n        // handle @list\n        var _list = [];\n        _createNodeMap(o['@list'], graphs, graph, issuer, name, _list);\n        o = {'@list': _list};\n        jsonld.addValue(\n          subject, property, o,\n          {propertyIsArray: true, allowDuplicate: false});\n      } else {\n        // handle @value\n        _createNodeMap(o, graphs, graph, issuer, name);\n        jsonld.addValue(\n          subject, property, o, {propertyIsArray: true, allowDuplicate: false});\n      }\n    }\n  }\n}\n\nfunction _mergeNodeMaps(graphs) {\n  // add all non-default graphs to default graph\n  var defaultGraph = graphs['@default'];\n  var graphNames = Object.keys(graphs).sort();\n  for(var i = 0; i < graphNames.length; ++i) {\n    var graphName = graphNames[i];\n    if(graphName === '@default') {\n      continue;\n    }\n    var nodeMap = graphs[graphName];\n    var subject = defaultGraph[graphName];\n    if(!subject) {\n      defaultGraph[graphName] = subject = {\n        '@id': graphName,\n        '@graph': []\n      };\n    } else if(!('@graph' in subject)) {\n      subject['@graph'] = [];\n    }\n    var graph = subject['@graph'];\n    var ids = Object.keys(nodeMap).sort();\n    for(var ii = 0; ii < ids.length; ++ii) {\n      var node = nodeMap[ids[ii]];\n      // only add full subjects\n      if(!_isSubjectReference(node)) {\n        graph.push(node);\n      }\n    }\n  }\n  return defaultGraph;\n}\n\n/**\n * Frames subjects according to the given frame.\n *\n * @param state the current framing state.\n * @param subjects the subjects to filter.\n * @param frame the frame.\n * @param parent the parent subject or top-level array.\n * @param property the parent property, initialized to null.\n */\nfunction _frame(state, subjects, frame, parent, property) {\n  // validate the frame\n  _validateFrame(frame);\n  frame = frame[0];\n\n  // get flags for current frame\n  var options = state.options;\n  var flags = {\n    embed: _getFrameFlag(frame, options, 'embed'),\n    explicit: _getFrameFlag(frame, options, 'explicit'),\n    requireAll: _getFrameFlag(frame, options, 'requireAll')\n  };\n\n  // filter out subjects that match the frame\n  var matches = _filterSubjects(state, subjects, frame, flags);\n\n  // add matches to output\n  var ids = Object.keys(matches).sort();\n  for(var idx = 0; idx < ids.length; ++idx) {\n    var id = ids[idx];\n    var subject = matches[id];\n\n    if(flags.embed === '@link' && id in state.link) {\n      // TODO: may want to also match an existing linked subject against\n      // the current frame ... so different frames could produce different\n      // subjects that are only shared in-memory when the frames are the same\n\n      // add existing linked subject\n      _addFrameOutput(parent, property, state.link[id]);\n      continue;\n    }\n\n    /* Note: In order to treat each top-level match as a compartmentalized\n    result, clear the unique embedded subjects map when the property is null,\n    which only occurs at the top-level. */\n    if(property === null) {\n      state.uniqueEmbeds = {};\n    }\n\n    // start output for subject\n    var output = {};\n    output['@id'] = id;\n    state.link[id] = output;\n\n    // if embed is @never or if a circular reference would be created by an\n    // embed, the subject cannot be embedded, just add the reference;\n    // note that a circular reference won't occur when the embed flag is\n    // `@link` as the above check will short-circuit before reaching this point\n    if(flags.embed === '@never' ||\n      _createsCircularReference(subject, state.subjectStack)) {\n      _addFrameOutput(parent, property, output);\n      continue;\n    }\n\n    // if only the last match should be embedded\n    if(flags.embed === '@last') {\n      // remove any existing embed\n      if(id in state.uniqueEmbeds) {\n        _removeEmbed(state, id);\n      }\n      state.uniqueEmbeds[id] = {parent: parent, property: property};\n    }\n\n    // push matching subject onto stack to enable circular embed checks\n    state.subjectStack.push(subject);\n\n    // iterate over subject properties\n    var props = Object.keys(subject).sort();\n    for(var i = 0; i < props.length; i++) {\n      var prop = props[i];\n\n      // copy keywords to output\n      if(_isKeyword(prop)) {\n        output[prop] = _clone(subject[prop]);\n        continue;\n      }\n\n      // explicit is on and property isn't in the frame, skip processing\n      if(flags.explicit && !(prop in frame)) {\n        continue;\n      }\n\n      // add objects\n      var objects = subject[prop];\n      for(var oi = 0; oi < objects.length; ++oi) {\n        var o = objects[oi];\n\n        // recurse into list\n        if(_isList(o)) {\n          // add empty list\n          var list = {'@list': []};\n          _addFrameOutput(output, prop, list);\n\n          // add list objects\n          var src = o['@list'];\n          for(var n in src) {\n            o = src[n];\n            if(_isSubjectReference(o)) {\n              var subframe = (prop in frame ?\n                frame[prop][0]['@list'] : _createImplicitFrame(flags));\n              // recurse into subject reference\n              _frame(state, [o['@id']], subframe, list, '@list');\n            } else {\n              // include other values automatically\n              _addFrameOutput(list, '@list', _clone(o));\n            }\n          }\n          continue;\n        }\n\n        if(_isSubjectReference(o)) {\n          // recurse into subject reference\n          var subframe = (prop in frame ?\n            frame[prop] : _createImplicitFrame(flags));\n          _frame(state, [o['@id']], subframe, output, prop);\n        } else {\n          // include other values automatically\n          _addFrameOutput(output, prop, _clone(o));\n        }\n      }\n    }\n\n    // handle defaults\n    var props = Object.keys(frame).sort();\n    for(var i = 0; i < props.length; ++i) {\n      var prop = props[i];\n\n      // skip keywords\n      if(_isKeyword(prop)) {\n        continue;\n      }\n\n      // if omit default is off, then include default values for properties\n      // that appear in the next frame but are not in the matching subject\n      var next = frame[prop][0];\n      var omitDefaultOn = _getFrameFlag(next, options, 'omitDefault');\n      if(!omitDefaultOn && !(prop in output)) {\n        var preserve = '@null';\n        if('@default' in next) {\n          preserve = _clone(next['@default']);\n        }\n        if(!_isArray(preserve)) {\n          preserve = [preserve];\n        }\n        output[prop] = [{'@preserve': preserve}];\n      }\n    }\n\n    // add output to parent\n    _addFrameOutput(parent, property, output);\n\n    // pop matching subject from circular ref-checking stack\n    state.subjectStack.pop();\n  }\n}\n\n/**\n * Creates an implicit frame when recursing through subject matches. If\n * a frame doesn't have an explicit frame for a particular property, then\n * a wildcard child frame will be created that uses the same flags that the\n * parent frame used.\n *\n * @param flags the current framing flags.\n *\n * @return the implicit frame.\n */\nfunction _createImplicitFrame(flags) {\n  var frame = {};\n  for(var key in flags) {\n    if(flags[key] !== undefined) {\n      frame['@' + key] = [flags[key]];\n    }\n  }\n  return [frame];\n}\n\n/**\n * Checks the current subject stack to see if embedding the given subject\n * would cause a circular reference.\n *\n * @param subjectToEmbed the subject to embed.\n * @param subjectStack the current stack of subjects.\n *\n * @return true if a circular reference would be created, false if not.\n */\nfunction _createsCircularReference(subjectToEmbed, subjectStack) {\n  for(var i = subjectStack.length - 1; i >= 0; --i) {\n    if(subjectStack[i]['@id'] === subjectToEmbed['@id']) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Gets the frame flag value for the given flag name.\n *\n * @param frame the frame.\n * @param options the framing options.\n * @param name the flag name.\n *\n * @return the flag value.\n */\nfunction _getFrameFlag(frame, options, name) {\n  var flag = '@' + name;\n  var rval = (flag in frame ? frame[flag][0] : options[name]);\n  if(name === 'embed') {\n    // default is \"@last\"\n    // backwards-compatibility support for \"embed\" maps:\n    // true => \"@last\"\n    // false => \"@never\"\n    if(rval === true) {\n      rval = '@last';\n    } else if(rval === false) {\n      rval = '@never';\n    } else if(rval !== '@always' && rval !== '@never' && rval !== '@link') {\n      rval = '@last';\n    }\n  }\n  return rval;\n}\n\n/**\n * Validates a JSON-LD frame, throwing an exception if the frame is invalid.\n *\n * @param frame the frame to validate.\n */\nfunction _validateFrame(frame) {\n  if(!_isArray(frame) || frame.length !== 1 || !_isObject(frame[0])) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a JSON-LD frame must be a single object.',\n      'jsonld.SyntaxError', {frame: frame});\n  }\n}\n\n/**\n * Returns a map of all of the subjects that match a parsed frame.\n *\n * @param state the current framing state.\n * @param subjects the set of subjects to filter.\n * @param frame the parsed frame.\n * @param flags the frame flags.\n *\n * @return all of the matched subjects.\n */\nfunction _filterSubjects(state, subjects, frame, flags) {\n  // filter subjects in @id order\n  var rval = {};\n  for(var i = 0; i < subjects.length; ++i) {\n    var id = subjects[i];\n    var subject = state.subjects[id];\n    if(_filterSubject(subject, frame, flags)) {\n      rval[id] = subject;\n    }\n  }\n  return rval;\n}\n\n/**\n * Returns true if the given subject matches the given frame.\n *\n * @param subject the subject to check.\n * @param frame the frame to check.\n * @param flags the frame flags.\n *\n * @return true if the subject matches, false if not.\n */\nfunction _filterSubject(subject, frame, flags) {\n  // check @type (object value means 'any' type, fall through to ducktyping)\n  if('@type' in frame &&\n    !(frame['@type'].length === 1 && _isObject(frame['@type'][0]))) {\n    var types = frame['@type'];\n    for(var i = 0; i < types.length; ++i) {\n      // any matching @type is a match\n      if(jsonld.hasValue(subject, '@type', types[i])) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  // check ducktype\n  var wildcard = true;\n  var matchesSome = false;\n  for(var key in frame) {\n    if(_isKeyword(key)) {\n      // skip non-@id and non-@type\n      if(key !== '@id' && key !== '@type') {\n        continue;\n      }\n      wildcard = false;\n\n      // check @id for a specific @id value\n      if(key === '@id' && _isString(frame[key])) {\n        if(subject[key] !== frame[key]) {\n          return false;\n        }\n        matchesSome = true;\n        continue;\n      }\n    }\n\n    wildcard = false;\n\n    if(key in subject) {\n      // frame[key] === [] means do not match if property is present\n      if(_isArray(frame[key]) && frame[key].length === 0 &&\n        subject[key] !== undefined) {\n        return false;\n      }\n      matchesSome = true;\n      continue;\n    }\n\n    // all properties must match to be a duck unless a @default is specified\n    var hasDefault = (_isArray(frame[key]) && _isObject(frame[key][0]) &&\n      '@default' in frame[key][0]);\n    if(flags.requireAll && !hasDefault) {\n      return false;\n    }\n  }\n\n  // return true if wildcard or subject matches some properties\n  return wildcard || matchesSome;\n}\n\n/**\n * Removes an existing embed.\n *\n * @param state the current framing state.\n * @param id the @id of the embed to remove.\n */\nfunction _removeEmbed(state, id) {\n  // get existing embed\n  var embeds = state.uniqueEmbeds;\n  var embed = embeds[id];\n  var parent = embed.parent;\n  var property = embed.property;\n\n  // create reference to replace embed\n  var subject = {'@id': id};\n\n  // remove existing embed\n  if(_isArray(parent)) {\n    // replace subject with reference\n    for(var i = 0; i < parent.length; ++i) {\n      if(jsonld.compareValues(parent[i], subject)) {\n        parent[i] = subject;\n        break;\n      }\n    }\n  } else {\n    // replace subject with reference\n    var useArray = _isArray(parent[property]);\n    jsonld.removeValue(parent, property, subject, {propertyIsArray: useArray});\n    jsonld.addValue(parent, property, subject, {propertyIsArray: useArray});\n  }\n\n  // recursively remove dependent dangling embeds\n  var removeDependents = function(id) {\n    // get embed keys as a separate array to enable deleting keys in map\n    var ids = Object.keys(embeds);\n    for(var i = 0; i < ids.length; ++i) {\n      var next = ids[i];\n      if(next in embeds && _isObject(embeds[next].parent) &&\n        embeds[next].parent['@id'] === id) {\n        delete embeds[next];\n        removeDependents(next);\n      }\n    }\n  };\n  removeDependents(id);\n}\n\n/**\n * Adds framing output to the given parent.\n *\n * @param parent the parent to add to.\n * @param property the parent property.\n * @param output the output to add.\n */\nfunction _addFrameOutput(parent, property, output) {\n  if(_isObject(parent)) {\n    jsonld.addValue(parent, property, output, {propertyIsArray: true});\n  } else {\n    parent.push(output);\n  }\n}\n\n/**\n * Removes the @preserve keywords as the last step of the framing algorithm.\n *\n * @param ctx the active context used to compact the input.\n * @param input the framed, compacted output.\n * @param options the compaction options used.\n *\n * @return the resulting output.\n */\nfunction _removePreserve(ctx, input, options) {\n  // recurse through arrays\n  if(_isArray(input)) {\n    var output = [];\n    for(var i = 0; i < input.length; ++i) {\n      var result = _removePreserve(ctx, input[i], options);\n      // drop nulls from arrays\n      if(result !== null) {\n        output.push(result);\n      }\n    }\n    input = output;\n  } else if(_isObject(input)) {\n    // remove @preserve\n    if('@preserve' in input) {\n      if(input['@preserve'] === '@null') {\n        return null;\n      }\n      return input['@preserve'];\n    }\n\n    // skip @values\n    if(_isValue(input)) {\n      return input;\n    }\n\n    // recurse through @lists\n    if(_isList(input)) {\n      input['@list'] = _removePreserve(ctx, input['@list'], options);\n      return input;\n    }\n\n    // handle in-memory linked nodes\n    var idAlias = _compactIri(ctx, '@id');\n    if(idAlias in input) {\n      var id = input[idAlias];\n      if(id in options.link) {\n        var idx = options.link[id].indexOf(input);\n        if(idx === -1) {\n          // prevent circular visitation\n          options.link[id].push(input);\n        } else {\n          // already visited\n          return options.link[id][idx];\n        }\n      } else {\n        // prevent circular visitation\n        options.link[id] = [input];\n      }\n    }\n\n    // recurse through properties\n    for(var prop in input) {\n      var result = _removePreserve(ctx, input[prop], options);\n      var container = jsonld.getContextValue(ctx, prop, '@container');\n      if(options.compactArrays && _isArray(result) && result.length === 1 &&\n        container === null) {\n        result = result[0];\n      }\n      input[prop] = result;\n    }\n  }\n  return input;\n}\n\n/**\n * Compares two strings first based on length and then lexicographically.\n *\n * @param a the first string.\n * @param b the second string.\n *\n * @return -1 if a < b, 1 if a > b, 0 if a == b.\n */\nfunction _compareShortestLeast(a, b) {\n  if(a.length < b.length) {\n    return -1;\n  }\n  if(b.length < a.length) {\n    return 1;\n  }\n  if(a === b) {\n    return 0;\n  }\n  return (a < b) ? -1 : 1;\n}\n\n/**\n * Picks the preferred compaction term from the given inverse context entry.\n *\n * @param activeCtx the active context.\n * @param iri the IRI to pick the term for.\n * @param value the value to pick the term for.\n * @param containers the preferred containers.\n * @param typeOrLanguage either '@type' or '@language'.\n * @param typeOrLanguageValue the preferred value for '@type' or '@language'.\n *\n * @return the preferred term.\n */\nfunction _selectTerm(\n  activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue) {\n  if(typeOrLanguageValue === null) {\n    typeOrLanguageValue = '@null';\n  }\n\n  // preferences for the value of @type or @language\n  var prefs = [];\n\n  // determine prefs for @id based on whether or not value compacts to a term\n  if((typeOrLanguageValue === '@id' || typeOrLanguageValue === '@reverse') &&\n    _isSubjectReference(value)) {\n    // prefer @reverse first\n    if(typeOrLanguageValue === '@reverse') {\n      prefs.push('@reverse');\n    }\n    // try to compact value to a term\n    var term = _compactIri(activeCtx, value['@id'], null, {vocab: true});\n    if(term in activeCtx.mappings &&\n      activeCtx.mappings[term] &&\n      activeCtx.mappings[term]['@id'] === value['@id']) {\n      // prefer @vocab\n      prefs.push.apply(prefs, ['@vocab', '@id']);\n    } else {\n      // prefer @id\n      prefs.push.apply(prefs, ['@id', '@vocab']);\n    }\n  } else {\n    prefs.push(typeOrLanguageValue);\n  }\n  prefs.push('@none');\n\n  var containerMap = activeCtx.inverse[iri];\n  for(var ci = 0; ci < containers.length; ++ci) {\n    // if container not available in the map, continue\n    var container = containers[ci];\n    if(!(container in containerMap)) {\n      continue;\n    }\n\n    var typeOrLanguageValueMap = containerMap[container][typeOrLanguage];\n    for(var pi = 0; pi < prefs.length; ++pi) {\n      // if type/language option not available in the map, continue\n      var pref = prefs[pi];\n      if(!(pref in typeOrLanguageValueMap)) {\n        continue;\n      }\n\n      // select term\n      return typeOrLanguageValueMap[pref];\n    }\n  }\n\n  return null;\n}\n\n/**\n * Compacts an IRI or keyword into a term or prefix if it can be. If the\n * IRI has an associated value it may be passed.\n *\n * @param activeCtx the active context to use.\n * @param iri the IRI to compact.\n * @param value the value to check or null.\n * @param relativeTo options for how to compact IRIs:\n *          vocab: true to split after @vocab, false not to.\n * @param reverse true if a reverse property is being compacted, false if not.\n *\n * @return the compacted term, prefix, keyword alias, or the original IRI.\n */\nfunction _compactIri(activeCtx, iri, value, relativeTo, reverse) {\n  // can't compact null\n  if(iri === null) {\n    return iri;\n  }\n\n  // default value and parent to null\n  if(_isUndefined(value)) {\n    value = null;\n  }\n  // default reverse to false\n  if(_isUndefined(reverse)) {\n    reverse = false;\n  }\n  relativeTo = relativeTo || {};\n\n  var inverseCtx = activeCtx.getInverse();\n\n  // if term is a keyword, it can only be compacted to a simple alias\n  if(_isKeyword(iri)) {\n    if(iri in inverseCtx) {\n      return inverseCtx[iri]['@none']['@type']['@none'];\n    }\n    return iri;\n  }\n\n  // use inverse context to pick a term if iri is relative to vocab\n  if(relativeTo.vocab && iri in inverseCtx) {\n    var defaultLanguage = activeCtx['@language'] || '@none';\n\n    // prefer @index if available in value\n    var containers = [];\n    if(_isObject(value) && '@index' in value) {\n      containers.push('@index');\n    }\n\n    // defaults for term selection based on type/language\n    var typeOrLanguage = '@language';\n    var typeOrLanguageValue = '@null';\n\n    if(reverse) {\n      typeOrLanguage = '@type';\n      typeOrLanguageValue = '@reverse';\n      containers.push('@set');\n    } else if(_isList(value)) {\n      // choose the most specific term that works for all elements in @list\n      // only select @list containers if @index is NOT in value\n      if(!('@index' in value)) {\n        containers.push('@list');\n      }\n      var list = value['@list'];\n      var commonLanguage = (list.length === 0) ? defaultLanguage : null;\n      var commonType = null;\n      for(var i = 0; i < list.length; ++i) {\n        var item = list[i];\n        var itemLanguage = '@none';\n        var itemType = '@none';\n        if(_isValue(item)) {\n          if('@language' in item) {\n            itemLanguage = item['@language'];\n          } else if('@type' in item) {\n            itemType = item['@type'];\n          } else {\n            // plain literal\n            itemLanguage = '@null';\n          }\n        } else {\n          itemType = '@id';\n        }\n        if(commonLanguage === null) {\n          commonLanguage = itemLanguage;\n        } else if(itemLanguage !== commonLanguage && _isValue(item)) {\n          commonLanguage = '@none';\n        }\n        if(commonType === null) {\n          commonType = itemType;\n        } else if(itemType !== commonType) {\n          commonType = '@none';\n        }\n        // there are different languages and types in the list, so choose\n        // the most generic term, no need to keep iterating the list\n        if(commonLanguage === '@none' && commonType === '@none') {\n          break;\n        }\n      }\n      commonLanguage = commonLanguage || '@none';\n      commonType = commonType || '@none';\n      if(commonType !== '@none') {\n        typeOrLanguage = '@type';\n        typeOrLanguageValue = commonType;\n      } else {\n        typeOrLanguageValue = commonLanguage;\n      }\n    } else {\n      if(_isValue(value)) {\n        if('@language' in value && !('@index' in value)) {\n          containers.push('@language');\n          typeOrLanguageValue = value['@language'];\n        } else if('@type' in value) {\n          typeOrLanguage = '@type';\n          typeOrLanguageValue = value['@type'];\n        }\n      } else {\n        typeOrLanguage = '@type';\n        typeOrLanguageValue = '@id';\n      }\n      containers.push('@set');\n    }\n\n    // do term selection\n    containers.push('@none');\n    var term = _selectTerm(\n      activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue);\n    if(term !== null) {\n      return term;\n    }\n  }\n\n  // no term match, use @vocab if available\n  if(relativeTo.vocab) {\n    if('@vocab' in activeCtx) {\n      // determine if vocab is a prefix of the iri\n      var vocab = activeCtx['@vocab'];\n      if(iri.indexOf(vocab) === 0 && iri !== vocab) {\n        // use suffix as relative iri if it is not a term in the active context\n        var suffix = iri.substr(vocab.length);\n        if(!(suffix in activeCtx.mappings)) {\n          return suffix;\n        }\n      }\n    }\n  }\n\n  // no term or @vocab match, check for possible CURIEs\n  var choice = null;\n  var idx = 0;\n  var partialMatches = [];\n  var iriMap = activeCtx.fastCurieMap;\n  // check for partial matches of against `iri`, which means look until\n  // iri.length - 1, not full length\n  var maxPartialLength = iri.length - 1;\n  for(; idx < maxPartialLength && iri[idx] in iriMap; ++idx) {\n    iriMap = iriMap[iri[idx]];\n    if('' in iriMap) {\n      partialMatches.push(iriMap[''][0]);\n    }\n  }\n  // check partial matches in reverse order to prefer longest ones first\n  for(var i = partialMatches.length - 1; i >= 0; --i) {\n    var entry = partialMatches[i];\n    var terms = entry.terms;\n    for(var ti = 0; ti < terms.length; ++ti) {\n      // a CURIE is usable if:\n      // 1. it has no mapping, OR\n      // 2. value is null, which means we're not compacting an @value, AND\n      //   the mapping matches the IRI\n      var curie = terms[ti] + ':' + iri.substr(entry.iri.length);\n      var isUsableCurie = (!(curie in activeCtx.mappings) ||\n        (value === null && activeCtx.mappings[curie]['@id'] === iri));\n\n      // select curie if it is shorter or the same length but lexicographically\n      // less than the current choice\n      if(isUsableCurie && (choice === null ||\n        _compareShortestLeast(curie, choice) < 0)) {\n        choice = curie;\n      }\n    }\n  }\n\n  // return chosen curie\n  if(choice !== null) {\n    return choice;\n  }\n\n  // compact IRI relative to base\n  if(!relativeTo.vocab) {\n    return _removeBase(activeCtx['@base'], iri);\n  }\n\n  // return IRI as is\n  return iri;\n}\n\n/**\n * Performs value compaction on an object with '@value' or '@id' as the only\n * property.\n *\n * @param activeCtx the active context.\n * @param activeProperty the active property that points to the value.\n * @param value the value to compact.\n *\n * @return the compaction result.\n */\nfunction _compactValue(activeCtx, activeProperty, value) {\n  // value is a @value\n  if(_isValue(value)) {\n    // get context rules\n    var type = jsonld.getContextValue(activeCtx, activeProperty, '@type');\n    var language = jsonld.getContextValue(\n      activeCtx, activeProperty, '@language');\n    var container = jsonld.getContextValue(\n      activeCtx, activeProperty, '@container');\n\n    // whether or not the value has an @index that must be preserved\n    var preserveIndex = (('@index' in value) &&\n      container !== '@index');\n\n    // if there's no @index to preserve ...\n    if(!preserveIndex) {\n      // matching @type or @language specified in context, compact value\n      if(value['@type'] === type || value['@language'] === language) {\n        return value['@value'];\n      }\n    }\n\n    // return just the value of @value if all are true:\n    // 1. @value is the only key or @index isn't being preserved\n    // 2. there is no default language or @value is not a string or\n    //   the key has a mapping with a null @language\n    var keyCount = Object.keys(value).length;\n    var isValueOnlyKey = (keyCount === 1 ||\n      (keyCount === 2 && ('@index' in value) && !preserveIndex));\n    var hasDefaultLanguage = ('@language' in activeCtx);\n    var isValueString = _isString(value['@value']);\n    var hasNullMapping = (activeCtx.mappings[activeProperty] &&\n      activeCtx.mappings[activeProperty]['@language'] === null);\n    if(isValueOnlyKey &&\n      (!hasDefaultLanguage || !isValueString || hasNullMapping)) {\n      return value['@value'];\n    }\n\n    var rval = {};\n\n    // preserve @index\n    if(preserveIndex) {\n      rval[_compactIri(activeCtx, '@index')] = value['@index'];\n    }\n\n    if('@type' in value) {\n      // compact @type IRI\n      rval[_compactIri(activeCtx, '@type')] = _compactIri(\n        activeCtx, value['@type'], null, {vocab: true});\n    } else if('@language' in value) {\n      // alias @language\n      rval[_compactIri(activeCtx, '@language')] = value['@language'];\n    }\n\n    // alias @value\n    rval[_compactIri(activeCtx, '@value')] = value['@value'];\n\n    return rval;\n  }\n\n  // value is a subject reference\n  var expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true});\n  var type = jsonld.getContextValue(activeCtx, activeProperty, '@type');\n  var compacted = _compactIri(\n    activeCtx, value['@id'], null, {vocab: type === '@vocab'});\n\n  // compact to scalar\n  if(type === '@id' || type === '@vocab' || expandedProperty === '@graph') {\n    return compacted;\n  }\n\n  var rval = {};\n  rval[_compactIri(activeCtx, '@id')] = compacted;\n  return rval;\n}\n\n/**\n * Creates a term definition during context processing.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context being processed.\n * @param term the term in the local context to define the mapping for.\n * @param defined a map of defining/defined keys to detect cycles and prevent\n *          double definitions.\n */\nfunction _createTermDefinition(activeCtx, localCtx, term, defined) {\n  if(term in defined) {\n    // term already defined\n    if(defined[term]) {\n      return;\n    }\n    // cycle detected\n    throw new JsonLdError(\n      'Cyclical context definition detected.',\n      'jsonld.CyclicalContext',\n      {code: 'cyclic IRI mapping', context: localCtx, term: term});\n  }\n\n  // now defining term\n  defined[term] = false;\n\n  if(_isKeyword(term)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; keywords cannot be overridden.',\n      'jsonld.SyntaxError',\n      {code: 'keyword redefinition', context: localCtx, term: term});\n  }\n\n  if(term === '') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a term cannot be an empty string.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // remove old mapping\n  if(activeCtx.mappings[term]) {\n    delete activeCtx.mappings[term];\n  }\n\n  // get context term value\n  var value = localCtx[term];\n\n  // clear context entry\n  if(value === null || (_isObject(value) && value['@id'] === null)) {\n    activeCtx.mappings[term] = null;\n    defined[term] = true;\n    return;\n  }\n\n  // convert short-hand value to object w/@id\n  if(_isString(value)) {\n    value = {'@id': value};\n  }\n\n  if(!_isObject(value)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context property values must be ' +\n      'strings or objects.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // create new mapping\n  var mapping = activeCtx.mappings[term] = {};\n  mapping.reverse = false;\n\n  if('@reverse' in value) {\n    if('@id' in value) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @reverse term definition must not ' +\n        'contain @id.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n    var reverse = value['@reverse'];\n    if(!_isString(reverse)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n\n    // expand and add @id mapping\n    var id = _expandIri(\n      activeCtx, reverse, {vocab: true, base: false}, localCtx, defined);\n    if(!_isAbsoluteIri(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be an ' +\n        'absolute IRI or a blank node identifier.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n    mapping['@id'] = id;\n    mapping.reverse = true;\n  } else if('@id' in value) {\n    var id = value['@id'];\n    if(!_isString(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @id value must be an array ' +\n        'of strings or a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n    if(id !== term) {\n      // expand and add @id mapping\n      id = _expandIri(\n        activeCtx, id, {vocab: true, base: false}, localCtx, defined);\n      if(!_isAbsoluteIri(id) && !_isKeyword(id)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a @context @id value must be an ' +\n          'absolute IRI, a blank node identifier, or a keyword.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx});\n      }\n      mapping['@id'] = id;\n    }\n  }\n\n  // always compute whether term has a colon as an optimization for\n  // _compactIri\n  var colon = term.indexOf(':');\n  mapping._termHasColon = (colon !== -1);\n\n  if(!('@id' in mapping)) {\n    // see if the term has a prefix\n    if(mapping._termHasColon) {\n      var prefix = term.substr(0, colon);\n      if(prefix in localCtx) {\n        // define parent prefix\n        _createTermDefinition(activeCtx, localCtx, prefix, defined);\n      }\n\n      if(activeCtx.mappings[prefix]) {\n        // set @id based on prefix parent\n        var suffix = term.substr(colon + 1);\n        mapping['@id'] = activeCtx.mappings[prefix]['@id'] + suffix;\n      } else {\n        // term is an absolute IRI\n        mapping['@id'] = term;\n      }\n    } else {\n      // non-IRIs *must* define @ids if @vocab is not available\n      if(!('@vocab' in activeCtx)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @context terms must define an @id.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx, term: term});\n      }\n      // prepend vocab to term\n      mapping['@id'] = activeCtx['@vocab'] + term;\n    }\n  }\n\n  // IRI mapping now defined\n  defined[term] = true;\n\n  if('@type' in value) {\n    var type = value['@type'];\n    if(!_isString(type)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an @context @type values must be a string.',\n        'jsonld.SyntaxError',\n        {code: 'invalid type mapping', context: localCtx});\n    }\n\n    if(type !== '@id' && type !== '@vocab') {\n      // expand @type to full IRI\n      type = _expandIri(\n        activeCtx, type, {vocab: true, base: false}, localCtx, defined);\n      if(!_isAbsoluteIri(type)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must be an ' +\n          'absolute IRI.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n      if(type.indexOf('_:') === 0) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type values must be an IRI, ' +\n          'not a blank node identifier.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n    }\n\n    // add @type to mapping\n    mapping['@type'] = type;\n  }\n\n  if('@container' in value) {\n    var container = value['@container'];\n    if(container !== '@list' && container !== '@set' &&\n      container !== '@index' && container !== '@language') {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value must be ' +\n        'one of the following: @list, @set, @index, or @language.',\n        'jsonld.SyntaxError',\n        {code: 'invalid container mapping', context: localCtx});\n    }\n    if(mapping.reverse && container !== '@index' && container !== '@set' &&\n      container !== null) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value for a @reverse ' +\n        'type definition must be @index or @set.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n\n    // add @container to mapping\n    mapping['@container'] = container;\n  }\n\n  if('@language' in value && !('@type' in value)) {\n    var language = value['@language'];\n    if(language !== null && !_isString(language)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @language value must be ' +\n        'a string or null.', 'jsonld.SyntaxError',\n        {code: 'invalid language mapping', context: localCtx});\n    }\n\n    // add @language to mapping\n    if(language !== null) {\n      language = language.toLowerCase();\n    }\n    mapping['@language'] = language;\n  }\n\n  // disallow aliasing @context and @preserve\n  var id = mapping['@id'];\n  if(id === '@context' || id === '@preserve') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context and @preserve cannot be aliased.',\n      'jsonld.SyntaxError', {code: 'invalid keyword alias', context: localCtx});\n  }\n}\n\n/**\n * Expands a string to a full IRI. The string may be a term, a prefix, a\n * relative IRI, or an absolute IRI. The associated absolute IRI will be\n * returned.\n *\n * @param activeCtx the current active context.\n * @param value the string to expand.\n * @param relativeTo options for how to resolve relative IRIs:\n *          base: true to resolve against the base IRI, false not to.\n *          vocab: true to concatenate after @vocab, false not to.\n * @param localCtx the local context being processed (only given if called\n *          during context processing).\n * @param defined a map for tracking cycles in context definitions (only given\n *          if called during context processing).\n *\n * @return the expanded value.\n */\nfunction _expandIri(activeCtx, value, relativeTo, localCtx, defined) {\n  // already expanded\n  if(value === null || _isKeyword(value)) {\n    return value;\n  }\n\n  // ensure value is interpreted as a string\n  value = String(value);\n\n  // define term dependency if not defined\n  if(localCtx && value in localCtx && defined[value] !== true) {\n    _createTermDefinition(activeCtx, localCtx, value, defined);\n  }\n\n  relativeTo = relativeTo || {};\n  if(relativeTo.vocab) {\n    var mapping = activeCtx.mappings[value];\n\n    // value is explicitly ignored with a null mapping\n    if(mapping === null) {\n      return null;\n    }\n\n    if(mapping) {\n      // value is a term\n      return mapping['@id'];\n    }\n  }\n\n  // split value into prefix:suffix\n  var colon = value.indexOf(':');\n  if(colon !== -1) {\n    var prefix = value.substr(0, colon);\n    var suffix = value.substr(colon + 1);\n\n    // do not expand blank nodes (prefix of '_') or already-absolute\n    // IRIs (suffix of '//')\n    if(prefix === '_' || suffix.indexOf('//') === 0) {\n      return value;\n    }\n\n    // prefix dependency not defined, define it\n    if(localCtx && prefix in localCtx) {\n      _createTermDefinition(activeCtx, localCtx, prefix, defined);\n    }\n\n    // use mapping if prefix is defined\n    var mapping = activeCtx.mappings[prefix];\n    if(mapping) {\n      return mapping['@id'] + suffix;\n    }\n\n    // already absolute IRI\n    return value;\n  }\n\n  // prepend vocab\n  if(relativeTo.vocab && '@vocab' in activeCtx) {\n    return activeCtx['@vocab'] + value;\n  }\n\n  // prepend base\n  var rval = value;\n  if(relativeTo.base) {\n    rval = jsonld.prependBase(activeCtx['@base'], rval);\n  }\n\n  return rval;\n}\n\nfunction _prependBase(base, iri) {\n  // skip IRI processing\n  if(base === null) {\n    return iri;\n  }\n  // already an absolute IRI\n  if(iri.indexOf(':') !== -1) {\n    return iri;\n  }\n\n  // parse base if it is a string\n  if(_isString(base)) {\n    base = jsonld.url.parse(base || '');\n  }\n\n  // parse given IRI\n  var rel = jsonld.url.parse(iri);\n\n  // per RFC3986 5.2.2\n  var transform = {\n    protocol: base.protocol || ''\n  };\n\n  if(rel.authority !== null) {\n    transform.authority = rel.authority;\n    transform.path = rel.path;\n    transform.query = rel.query;\n  } else {\n    transform.authority = base.authority;\n\n    if(rel.path === '') {\n      transform.path = base.path;\n      if(rel.query !== null) {\n        transform.query = rel.query;\n      } else {\n        transform.query = base.query;\n      }\n    } else {\n      if(rel.path.indexOf('/') === 0) {\n        // IRI represents an absolute path\n        transform.path = rel.path;\n      } else {\n        // merge paths\n        var path = base.path;\n\n        // append relative path to the end of the last directory from base\n        if(rel.path !== '') {\n          path = path.substr(0, path.lastIndexOf('/') + 1);\n          if(path.length > 0 && path.substr(-1) !== '/') {\n            path += '/';\n          }\n          path += rel.path;\n        }\n\n        transform.path = path;\n      }\n      transform.query = rel.query;\n    }\n  }\n\n  // remove slashes and dots in path\n  transform.path = _removeDotSegments(transform.path, !!transform.authority);\n\n  // construct URL\n  var rval = transform.protocol;\n  if(transform.authority !== null) {\n    rval += '//' + transform.authority;\n  }\n  rval += transform.path;\n  if(transform.query !== null) {\n    rval += '?' + transform.query;\n  }\n  if(rel.fragment !== null) {\n    rval += '#' + rel.fragment;\n  }\n\n  // handle empty base\n  if(rval === '') {\n    rval = './';\n  }\n\n  return rval;\n}\n\n/**\n * Removes a base IRI from the given absolute IRI.\n *\n * @param base the base IRI.\n * @param iri the absolute IRI.\n *\n * @return the relative IRI if relative to base, otherwise the absolute IRI.\n */\nfunction _removeBase(base, iri) {\n  // skip IRI processing\n  if(base === null) {\n    return iri;\n  }\n\n  if(_isString(base)) {\n    base = jsonld.url.parse(base || '');\n  }\n\n  // establish base root\n  var root = '';\n  if(base.href !== '') {\n    root += (base.protocol || '') + '//' + (base.authority || '');\n  } else if(iri.indexOf('//')) {\n    // support network-path reference with empty base\n    root += '//';\n  }\n\n  // IRI not relative to base\n  if(iri.indexOf(root) !== 0) {\n    return iri;\n  }\n\n  // remove root from IRI and parse remainder\n  var rel = jsonld.url.parse(iri.substr(root.length));\n\n  // remove path segments that match (do not remove last segment unless there\n  // is a hash or query)\n  var baseSegments = base.normalizedPath.split('/');\n  var iriSegments = rel.normalizedPath.split('/');\n  var last = (rel.fragment || rel.query) ? 0 : 1;\n  while(baseSegments.length > 0 && iriSegments.length > last) {\n    if(baseSegments[0] !== iriSegments[0]) {\n      break;\n    }\n    baseSegments.shift();\n    iriSegments.shift();\n  }\n\n  // use '../' for each non-matching base segment\n  var rval = '';\n  if(baseSegments.length > 0) {\n    // don't count the last segment (if it ends with '/' last path doesn't\n    // count and if it doesn't end with '/' it isn't a path)\n    baseSegments.pop();\n    for(var i = 0; i < baseSegments.length; ++i) {\n      rval += '../';\n    }\n  }\n\n  // prepend remaining segments\n  rval += iriSegments.join('/');\n\n  // add query and hash\n  if(rel.query !== null) {\n    rval += '?' + rel.query;\n  }\n  if(rel.fragment !== null) {\n    rval += '#' + rel.fragment;\n  }\n\n  // handle empty base\n  if(rval === '') {\n    rval = './';\n  }\n\n  return rval;\n}\n\n/**\n * Gets the initial context.\n *\n * @param options the options to use:\n *          [base] the document base IRI.\n *\n * @return the initial context.\n */\nfunction _getInitialContext(options) {\n  var base = jsonld.url.parse(options.base || '');\n  return {\n    '@base': base,\n    mappings: {},\n    inverse: null,\n    getInverse: _createInverseContext,\n    clone: _cloneActiveContext\n  };\n\n  /**\n   * Generates an inverse context for use in the compaction algorithm, if\n   * not already generated for the given active context.\n   *\n   * @return the inverse context.\n   */\n  function _createInverseContext() {\n    var activeCtx = this;\n\n    // lazily create inverse\n    if(activeCtx.inverse) {\n      return activeCtx.inverse;\n    }\n    var inverse = activeCtx.inverse = {};\n\n    // variables for building fast CURIE map\n    var fastCurieMap = activeCtx.fastCurieMap = {};\n    var irisToTerms = {};\n\n    // handle default language\n    var defaultLanguage = activeCtx['@language'] || '@none';\n\n    // create term selections for each mapping in the context, ordered by\n    // shortest and then lexicographically least\n    var mappings = activeCtx.mappings;\n    var terms = Object.keys(mappings).sort(_compareShortestLeast);\n    for(var i = 0; i < terms.length; ++i) {\n      var term = terms[i];\n      var mapping = mappings[term];\n      if(mapping === null) {\n        continue;\n      }\n\n      var container = mapping['@container'] || '@none';\n\n      // iterate over every IRI in the mapping\n      var ids = mapping['@id'];\n      if(!_isArray(ids)) {\n        ids = [ids];\n      }\n      for(var ii = 0; ii < ids.length; ++ii) {\n        var iri = ids[ii];\n        var entry = inverse[iri];\n        var isKeyword = _isKeyword(iri);\n\n        if(!entry) {\n          // initialize entry\n          inverse[iri] = entry = {};\n\n          if(!isKeyword && !mapping._termHasColon) {\n            // init IRI to term map and fast CURIE prefixes\n            irisToTerms[iri] = [term];\n            var fastCurieEntry = {iri: iri, terms: irisToTerms[iri]};\n            if(iri[0] in fastCurieMap) {\n              fastCurieMap[iri[0]].push(fastCurieEntry);\n            } else {\n              fastCurieMap[iri[0]] = [fastCurieEntry];\n            }\n          }\n        } else if(!isKeyword && !mapping._termHasColon) {\n          // add IRI to term match\n          irisToTerms[iri].push(term);\n        }\n\n        // add new entry\n        if(!entry[container]) {\n          entry[container] = {\n            '@language': {},\n            '@type': {}\n          };\n        }\n        entry = entry[container];\n\n        if(mapping.reverse) {\n          // term is preferred for values using @reverse\n          _addPreferredTerm(mapping, term, entry['@type'], '@reverse');\n        } else if('@type' in mapping) {\n          // term is preferred for values using specific type\n          _addPreferredTerm(mapping, term, entry['@type'], mapping['@type']);\n        } else if('@language' in mapping) {\n          // term is preferred for values using specific language\n          var language = mapping['@language'] || '@null';\n          _addPreferredTerm(mapping, term, entry['@language'], language);\n        } else {\n          // term is preferred for values w/default language or no type and\n          // no language\n          // add an entry for the default language\n          _addPreferredTerm(mapping, term, entry['@language'], defaultLanguage);\n\n          // add entries for no type and no language\n          _addPreferredTerm(mapping, term, entry['@type'], '@none');\n          _addPreferredTerm(mapping, term, entry['@language'], '@none');\n        }\n      }\n    }\n\n    // build fast CURIE map\n    for(var key in fastCurieMap) {\n      _buildIriMap(fastCurieMap, key, 1);\n    }\n\n    return inverse;\n  }\n\n  /**\n   * Runs a recursive algorithm to build a lookup map for quickly finding\n   * potential CURIEs.\n   *\n   * @param iriMap the map to build.\n   * @param key the current key in the map to work on.\n   * @param idx the index into the IRI to compare.\n   */\n  function _buildIriMap(iriMap, key, idx) {\n    var entries = iriMap[key];\n    var next = iriMap[key] = {};\n\n    var iri;\n    var letter;\n    for(var i = 0; i < entries.length; ++i) {\n      iri = entries[i].iri;\n      if(idx >= iri.length) {\n        letter = '';\n      } else {\n        letter = iri[idx];\n      }\n      if(letter in next) {\n        next[letter].push(entries[i]);\n      } else {\n        next[letter] = [entries[i]];\n      }\n    }\n\n    for(var key in next) {\n      if(key === '') {\n        continue;\n      }\n      _buildIriMap(next, key, idx + 1);\n    }\n  }\n\n  /**\n   * Adds the term for the given entry if not already added.\n   *\n   * @param mapping the term mapping.\n   * @param term the term to add.\n   * @param entry the inverse context typeOrLanguage entry to add to.\n   * @param typeOrLanguageValue the key in the entry to add to.\n   */\n  function _addPreferredTerm(mapping, term, entry, typeOrLanguageValue) {\n    if(!(typeOrLanguageValue in entry)) {\n      entry[typeOrLanguageValue] = term;\n    }\n  }\n\n  /**\n   * Clones an active context, creating a child active context.\n   *\n   * @return a clone (child) of the active context.\n   */\n  function _cloneActiveContext() {\n    var child = {};\n    child['@base'] = this['@base'];\n    child.mappings = _clone(this.mappings);\n    child.clone = this.clone;\n    child.inverse = null;\n    child.getInverse = this.getInverse;\n    if('@language' in this) {\n      child['@language'] = this['@language'];\n    }\n    if('@vocab' in this) {\n      child['@vocab'] = this['@vocab'];\n    }\n    return child;\n  }\n}\n\n/**\n * Returns whether or not the given value is a keyword.\n *\n * @param v the value to check.\n *\n * @return true if the value is a keyword, false if not.\n */\nfunction _isKeyword(v) {\n  if(!_isString(v)) {\n    return false;\n  }\n  switch(v) {\n  case '@base':\n  case '@context':\n  case '@container':\n  case '@default':\n  case '@embed':\n  case '@explicit':\n  case '@graph':\n  case '@id':\n  case '@index':\n  case '@language':\n  case '@list':\n  case '@omitDefault':\n  case '@preserve':\n  case '@requireAll':\n  case '@reverse':\n  case '@set':\n  case '@type':\n  case '@value':\n  case '@vocab':\n    return true;\n  }\n  return false;\n}\n\n/**\n * Returns true if the given value is an Object.\n *\n * @param v the value to check.\n *\n * @return true if the value is an Object, false if not.\n */\nfunction _isObject(v) {\n  return (Object.prototype.toString.call(v) === '[object Object]');\n}\n\n/**\n * Returns true if the given value is an empty Object.\n *\n * @param v the value to check.\n *\n * @return true if the value is an empty Object, false if not.\n */\nfunction _isEmptyObject(v) {\n  return _isObject(v) && Object.keys(v).length === 0;\n}\n\n/**\n * Returns true if the given value is an Array.\n *\n * @param v the value to check.\n *\n * @return true if the value is an Array, false if not.\n */\nfunction _isArray(v) {\n  return Array.isArray(v);\n}\n\n/**\n * Throws an exception if the given value is not a valid @type value.\n *\n * @param v the value to check.\n */\nfunction _validateTypeValue(v) {\n  // can be a string or an empty object\n  if(_isString(v) || _isEmptyObject(v)) {\n    return;\n  }\n\n  // must be an array\n  var isValid = false;\n  if(_isArray(v)) {\n    // must contain only strings\n    isValid = true;\n    for(var i = 0; i < v.length; ++i) {\n      if(!(_isString(v[i]))) {\n        isValid = false;\n        break;\n      }\n    }\n  }\n\n  if(!isValid) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; \"@type\" value must a string, an array of ' +\n      'strings, or an empty object.', 'jsonld.SyntaxError',\n      {code: 'invalid type value', value: v});\n  }\n}\n\n/**\n * Returns true if the given value is a String.\n *\n * @param v the value to check.\n *\n * @return true if the value is a String, false if not.\n */\nfunction _isString(v) {\n  return (typeof v === 'string' ||\n    Object.prototype.toString.call(v) === '[object String]');\n}\n\n/**\n * Returns true if the given value is a Number.\n *\n * @param v the value to check.\n *\n * @return true if the value is a Number, false if not.\n */\nfunction _isNumber(v) {\n  return (typeof v === 'number' ||\n    Object.prototype.toString.call(v) === '[object Number]');\n}\n\n/**\n * Returns true if the given value is a double.\n *\n * @param v the value to check.\n *\n * @return true if the value is a double, false if not.\n */\nfunction _isDouble(v) {\n  return _isNumber(v) && String(v).indexOf('.') !== -1;\n}\n\n/**\n * Returns true if the given value is numeric.\n *\n * @param v the value to check.\n *\n * @return true if the value is numeric, false if not.\n */\nfunction _isNumeric(v) {\n  return !isNaN(parseFloat(v)) && isFinite(v);\n}\n\n/**\n * Returns true if the given value is a Boolean.\n *\n * @param v the value to check.\n *\n * @return true if the value is a Boolean, false if not.\n */\nfunction _isBoolean(v) {\n  return (typeof v === 'boolean' ||\n    Object.prototype.toString.call(v) === '[object Boolean]');\n}\n\n/**\n * Returns true if the given value is undefined.\n *\n * @param v the value to check.\n *\n * @return true if the value is undefined, false if not.\n */\nfunction _isUndefined(v) {\n  return (typeof v === 'undefined');\n}\n\n/**\n * Returns true if the given value is a subject with properties.\n *\n * @param v the value to check.\n *\n * @return true if the value is a subject with properties, false if not.\n */\nfunction _isSubject(v) {\n  // Note: A value is a subject if all of these hold true:\n  // 1. It is an Object.\n  // 2. It is not a @value, @set, or @list.\n  // 3. It has more than 1 key OR any existing key is not @id.\n  var rval = false;\n  if(_isObject(v) &&\n    !(('@value' in v) || ('@set' in v) || ('@list' in v))) {\n    var keyCount = Object.keys(v).length;\n    rval = (keyCount > 1 || !('@id' in v));\n  }\n  return rval;\n}\n\n/**\n * Returns true if the given value is a subject reference.\n *\n * @param v the value to check.\n *\n * @return true if the value is a subject reference, false if not.\n */\nfunction _isSubjectReference(v) {\n  // Note: A value is a subject reference if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has a single key: @id.\n  return (_isObject(v) && Object.keys(v).length === 1 && ('@id' in v));\n}\n\n/**\n * Returns true if the given value is a @value.\n *\n * @param v the value to check.\n *\n * @return true if the value is a @value, false if not.\n */\nfunction _isValue(v) {\n  // Note: A value is a @value if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has the @value property.\n  return _isObject(v) && ('@value' in v);\n}\n\n/**\n * Returns true if the given value is a @list.\n *\n * @param v the value to check.\n *\n * @return true if the value is a @list, false if not.\n */\nfunction _isList(v) {\n  // Note: A value is a @list if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has the @list property.\n  return _isObject(v) && ('@list' in v);\n}\n\n/**\n * Returns true if the given value is a blank node.\n *\n * @param v the value to check.\n *\n * @return true if the value is a blank node, false if not.\n */\nfunction _isBlankNode(v) {\n  // Note: A value is a blank node if all of these hold true:\n  // 1. It is an Object.\n  // 2. If it has an @id key its value begins with '_:'.\n  // 3. It has no keys OR is not a @value, @set, or @list.\n  var rval = false;\n  if(_isObject(v)) {\n    if('@id' in v) {\n      rval = (v['@id'].indexOf('_:') === 0);\n    } else {\n      rval = (Object.keys(v).length === 0 ||\n        !(('@value' in v) || ('@set' in v) || ('@list' in v)));\n    }\n  }\n  return rval;\n}\n\n/**\n * Returns true if the given value is an absolute IRI, false if not.\n *\n * @param v the value to check.\n *\n * @return true if the value is an absolute IRI, false if not.\n */\nfunction _isAbsoluteIri(v) {\n  return _isString(v) && v.indexOf(':') !== -1;\n}\n\n/**\n * Clones an object, array, or string/number. If a typed JavaScript object\n * is given, such as a Date, it will be converted to a string.\n *\n * @param value the value to clone.\n *\n * @return the cloned value.\n */\nfunction _clone(value) {\n  if(value && typeof value === 'object') {\n    var rval;\n    if(_isArray(value)) {\n      rval = [];\n      for(var i = 0; i < value.length; ++i) {\n        rval[i] = _clone(value[i]);\n      }\n    } else if(_isObject(value)) {\n      rval = {};\n      for(var key in value) {\n        rval[key] = _clone(value[key]);\n      }\n    } else {\n      rval = value.toString();\n    }\n    return rval;\n  }\n  return value;\n}\n\n/**\n * Finds all @context URLs in the given JSON-LD input.\n *\n * @param input the JSON-LD input.\n * @param urls a map of URLs (url => false/@contexts).\n * @param replace true to replace the URLs in the given input with the\n *           @contexts from the urls map, false not to.\n * @param base the base IRI to use to resolve relative IRIs.\n *\n * @return true if new URLs to retrieve were found, false if not.\n */\nfunction _findContextUrls(input, urls, replace, base) {\n  var count = Object.keys(urls).length;\n  if(_isArray(input)) {\n    for(var i = 0; i < input.length; ++i) {\n      _findContextUrls(input[i], urls, replace, base);\n    }\n    return (count < Object.keys(urls).length);\n  } else if(_isObject(input)) {\n    for(var key in input) {\n      if(key !== '@context') {\n        _findContextUrls(input[key], urls, replace, base);\n        continue;\n      }\n\n      // get @context\n      var ctx = input[key];\n\n      // array @context\n      if(_isArray(ctx)) {\n        var length = ctx.length;\n        for(var i = 0; i < length; ++i) {\n          var _ctx = ctx[i];\n          if(_isString(_ctx)) {\n            _ctx = jsonld.prependBase(base, _ctx);\n            // replace w/@context if requested\n            if(replace) {\n              _ctx = urls[_ctx];\n              if(_isArray(_ctx)) {\n                // add flattened context\n                Array.prototype.splice.apply(ctx, [i, 1].concat(_ctx));\n                i += _ctx.length - 1;\n                length = ctx.length;\n              } else {\n                ctx[i] = _ctx;\n              }\n            } else if(!(_ctx in urls)) {\n              // @context URL found\n              urls[_ctx] = false;\n            }\n          }\n        }\n      } else if(_isString(ctx)) {\n        // string @context\n        ctx = jsonld.prependBase(base, ctx);\n        // replace w/@context if requested\n        if(replace) {\n          input[key] = urls[ctx];\n        } else if(!(ctx in urls)) {\n          // @context URL found\n          urls[ctx] = false;\n        }\n      }\n    }\n    return (count < Object.keys(urls).length);\n  }\n  return false;\n}\n\n/**\n * Retrieves external @context URLs using the given document loader. Every\n * instance of @context in the input that refers to a URL will be replaced\n * with the JSON @context found at that URL.\n *\n * @param input the JSON-LD input with possible contexts.\n * @param options the options to use:\n *          documentLoader(url, callback(err, remoteDoc)) the document loader.\n * @param callback(err, input) called once the operation completes.\n */\nfunction _retrieveContextUrls(input, options, callback) {\n  // if any error occurs during URL resolution, quit\n  var error = null;\n\n  // recursive document loader\n  var documentLoader = options.documentLoader;\n  var retrieve = function(input, cycles, documentLoader, base, callback) {\n    if(Object.keys(cycles).length > MAX_CONTEXT_URLS) {\n      error = new JsonLdError(\n        'Maximum number of @context URLs exceeded.',\n        'jsonld.ContextUrlError',\n        {code: 'loading remote context failed', max: MAX_CONTEXT_URLS});\n      return callback(error);\n    }\n\n    // for tracking the URLs to retrieve\n    var urls = {};\n\n    // finished will be called once the URL queue is empty\n    var finished = function() {\n      // replace all URLs in the input\n      _findContextUrls(input, urls, true, base);\n      callback(null, input);\n    };\n\n    // find all URLs in the given input\n    if(!_findContextUrls(input, urls, false, base)) {\n      // no new URLs in input\n      finished();\n    }\n\n    // queue all unretrieved URLs\n    var queue = [];\n    for(var url in urls) {\n      if(urls[url] === false) {\n        queue.push(url);\n      }\n    }\n\n    // retrieve URLs in queue\n    var count = queue.length;\n    for(var i = 0; i < queue.length; ++i) {\n      (function(url) {\n        // check for context URL cycle\n        if(url in cycles) {\n          error = new JsonLdError(\n            'Cyclical @context URLs detected.',\n            'jsonld.ContextUrlError',\n            {code: 'recursive context inclusion', url: url});\n          return callback(error);\n        }\n        var _cycles = _clone(cycles);\n        _cycles[url] = true;\n        var done = function(err, remoteDoc) {\n          // short-circuit if there was an error with another URL\n          if(error) {\n            return;\n          }\n\n          var ctx = remoteDoc ? remoteDoc.document : null;\n\n          // parse string context as JSON\n          if(!err && _isString(ctx)) {\n            try {\n              ctx = JSON.parse(ctx);\n            } catch(ex) {\n              err = ex;\n            }\n          }\n\n          // ensure ctx is an object\n          if(err) {\n            err = new JsonLdError(\n              'Dereferencing a URL did not result in a valid JSON-LD object. ' +\n              'Possible causes are an inaccessible URL perhaps due to ' +\n              'a same-origin policy (ensure the server uses CORS if you are ' +\n              'using client-side JavaScript), too many redirects, a ' +\n              'non-JSON response, or more than one HTTP Link Header was ' +\n              'provided for a remote context.',\n              'jsonld.InvalidUrl',\n              {code: 'loading remote context failed', url: url, cause: err});\n          } else if(!_isObject(ctx)) {\n            err = new JsonLdError(\n              'Dereferencing a URL did not result in a JSON object. The ' +\n              'response was valid JSON, but it was not a JSON object.',\n              'jsonld.InvalidUrl',\n              {code: 'invalid remote context', url: url, cause: err});\n          }\n          if(err) {\n            error = err;\n            return callback(error);\n          }\n\n          // use empty context if no @context key is present\n          if(!('@context' in ctx)) {\n            ctx = {'@context': {}};\n          } else {\n            ctx = {'@context': ctx['@context']};\n          }\n\n          // append context URL to context if given\n          if(remoteDoc.contextUrl) {\n            if(!_isArray(ctx['@context'])) {\n              ctx['@context'] = [ctx['@context']];\n            }\n            ctx['@context'].push(remoteDoc.contextUrl);\n          }\n\n          // recurse\n          retrieve(ctx, _cycles, documentLoader, url, function(err, ctx) {\n            if(err) {\n              return callback(err);\n            }\n            urls[url] = ctx['@context'];\n            count -= 1;\n            if(count === 0) {\n              finished();\n            }\n          });\n        };\n        var promise = documentLoader(url, done);\n        if(promise && 'then' in promise) {\n          promise.then(done.bind(null, null), done);\n        }\n      }(queue[i]));\n    }\n  };\n  retrieve(input, {}, documentLoader, options.base, callback);\n}\n\n// define js 1.8.5 Object.keys method if not present\nif(!Object.keys) {\n  Object.keys = function(o) {\n    if(o !== Object(o)) {\n      throw new TypeError('Object.keys called on non-object');\n    }\n    var rval = [];\n    for(var p in o) {\n      if(Object.prototype.hasOwnProperty.call(o, p)) {\n        rval.push(p);\n      }\n    }\n    return rval;\n  };\n}\n\n/**\n * Parses RDF in the form of N-Quads.\n *\n * @param input the N-Quads input to parse.\n *\n * @return an RDF dataset.\n */\nfunction _parseNQuads(input) {\n  // define partial regexes\n  var iri = '(?:<([^:]+:[^>]*)>)';\n  var bnode = '(_:(?:[A-Za-z0-9]+))';\n  var plain = '\"([^\"\\\\\\\\]*(?:\\\\\\\\.[^\"\\\\\\\\]*)*)\"';\n  var datatype = '(?:\\\\^\\\\^' + iri + ')';\n  var language = '(?:@([a-z]+(?:-[a-z0-9]+)*))';\n  var literal = '(?:' + plain + '(?:' + datatype + '|' + language + ')?)';\n  var comment = '(?:#.*)?';\n  var ws = '[ \\\\t]+';\n  var wso = '[ \\\\t]*';\n  var eoln = /(?:\\r\\n)|(?:\\n)|(?:\\r)/g;\n  var empty = new RegExp('^' + wso + comment + '$');\n\n  // define quad part regexes\n  var subject = '(?:' + iri + '|' + bnode + ')' + ws;\n  var property = iri + ws;\n  var object = '(?:' + iri + '|' + bnode + '|' + literal + ')' + wso;\n  var graphName = '(?:\\\\.|(?:(?:' + iri + '|' + bnode + ')' + wso + '\\\\.))';\n\n  // full quad regex\n  var quad = new RegExp(\n    '^' + wso + subject + property + object + graphName + wso + comment + '$');\n\n  // build RDF dataset\n  var dataset = {};\n\n  // split N-Quad input into lines\n  var lines = input.split(eoln);\n  var lineNumber = 0;\n  for(var li = 0; li < lines.length; ++li) {\n    var line = lines[li];\n    lineNumber++;\n\n    // skip empty lines\n    if(empty.test(line)) {\n      continue;\n    }\n\n    // parse quad\n    var match = line.match(quad);\n    if(match === null) {\n      throw new JsonLdError(\n        'Error while parsing N-Quads; invalid quad.',\n        'jsonld.ParseError', {line: lineNumber});\n    }\n\n    // create RDF triple\n    var triple = {};\n\n    // get subject\n    if(!_isUndefined(match[1])) {\n      triple.subject = {type: 'IRI', value: match[1]};\n    } else {\n      triple.subject = {type: 'blank node', value: match[2]};\n    }\n\n    // get predicate\n    triple.predicate = {type: 'IRI', value: match[3]};\n\n    // get object\n    if(!_isUndefined(match[4])) {\n      triple.object = {type: 'IRI', value: match[4]};\n    } else if(!_isUndefined(match[5])) {\n      triple.object = {type: 'blank node', value: match[5]};\n    } else {\n      triple.object = {type: 'literal'};\n      if(!_isUndefined(match[7])) {\n        triple.object.datatype = match[7];\n      } else if(!_isUndefined(match[8])) {\n        triple.object.datatype = RDF_LANGSTRING;\n        triple.object.language = match[8];\n      } else {\n        triple.object.datatype = XSD_STRING;\n      }\n      var unescaped = match[6]\n        .replace(/\\\\\"/g, '\"')\n        .replace(/\\\\t/g, '\\t')\n        .replace(/\\\\n/g, '\\n')\n        .replace(/\\\\r/g, '\\r')\n        .replace(/\\\\\\\\/g, '\\\\');\n      triple.object.value = unescaped;\n    }\n\n    // get graph name ('@default' is used for the default graph)\n    var name = '@default';\n    if(!_isUndefined(match[9])) {\n      name = match[9];\n    } else if(!_isUndefined(match[10])) {\n      name = match[10];\n    }\n\n    // initialize graph in dataset\n    if(!(name in dataset)) {\n      dataset[name] = [triple];\n    } else {\n      // add triple if unique to its graph\n      var unique = true;\n      var triples = dataset[name];\n      for(var ti = 0; unique && ti < triples.length; ++ti) {\n        if(_compareRDFTriples(triples[ti], triple)) {\n          unique = false;\n        }\n      }\n      if(unique) {\n        triples.push(triple);\n      }\n    }\n  }\n\n  return dataset;\n}\n\n// register the N-Quads RDF parser\njsonld.registerRDFParser('application/nquads', _parseNQuads);\n\n/**\n * Converts an RDF dataset to N-Quads.\n *\n * @param dataset the RDF dataset to convert.\n *\n * @return the N-Quads string.\n */\nfunction _toNQuads(dataset) {\n  var quads = [];\n  for(var graphName in dataset) {\n    var triples = dataset[graphName];\n    for(var ti = 0; ti < triples.length; ++ti) {\n      var triple = triples[ti];\n      if(graphName === '@default') {\n        graphName = null;\n      }\n      quads.push(_toNQuad(triple, graphName));\n    }\n  }\n  return quads.sort().join('');\n}\n\n/**\n * Converts an RDF triple and graph name to an N-Quad string (a single quad).\n *\n * @param triple the RDF triple or quad to convert (a triple or quad may be\n *          passed, if a triple is passed then `graphName` should be given\n *          to specify the name of the graph the triple is in, `null` for\n *          the default graph).\n * @param graphName the name of the graph containing the triple, null for\n *          the default graph.\n *\n * @return the N-Quad string.\n */\nfunction _toNQuad(triple, graphName) {\n  var s = triple.subject;\n  var p = triple.predicate;\n  var o = triple.object;\n  var g = graphName || null;\n  if('name' in triple && triple.name) {\n    g = triple.name.value;\n  }\n\n  var quad = '';\n\n  // subject is an IRI\n  if(s.type === 'IRI') {\n    quad += '<' + s.value + '>';\n  } else {\n    quad += s.value;\n  }\n  quad += ' ';\n\n  // predicate is an IRI\n  if(p.type === 'IRI') {\n    quad += '<' + p.value + '>';\n  } else {\n    quad += p.value;\n  }\n  quad += ' ';\n\n  // object is IRI, bnode, or literal\n  if(o.type === 'IRI') {\n    quad += '<' + o.value + '>';\n  } else if(o.type === 'blank node') {\n    quad += o.value;\n  } else {\n    var escaped = o.value\n      .replace(/\\\\/g, '\\\\\\\\')\n      .replace(/\\t/g, '\\\\t')\n      .replace(/\\n/g, '\\\\n')\n      .replace(/\\r/g, '\\\\r')\n      .replace(/\\\"/g, '\\\\\"');\n    quad += '\"' + escaped + '\"';\n    if(o.datatype === RDF_LANGSTRING) {\n      if(o.language) {\n        quad += '@' + o.language;\n      }\n    } else if(o.datatype !== XSD_STRING) {\n      quad += '^^<' + o.datatype + '>';\n    }\n  }\n\n  // graph\n  if(g !== null && g !== undefined) {\n    if(g.indexOf('_:') !== 0) {\n      quad += ' <' + g + '>';\n    } else {\n      quad += ' ' + g;\n    }\n  }\n\n  quad += ' .\\n';\n  return quad;\n}\n\n/**\n * Parses the RDF dataset found via the data object from the RDFa API.\n *\n * @param data the RDFa API data object.\n *\n * @return the RDF dataset.\n */\nfunction _parseRdfaApiData(data) {\n  var dataset = {};\n  dataset['@default'] = [];\n\n  var subjects = data.getSubjects();\n  for(var si = 0; si < subjects.length; ++si) {\n    var subject = subjects[si];\n    if(subject === null) {\n      continue;\n    }\n\n    // get all related triples\n    var triples = data.getSubjectTriples(subject);\n    if(triples === null) {\n      continue;\n    }\n    var predicates = triples.predicates;\n    for(var predicate in predicates) {\n      // iterate over objects\n      var objects = predicates[predicate].objects;\n      for(var oi = 0; oi < objects.length; ++oi) {\n        var object = objects[oi];\n\n        // create RDF triple\n        var triple = {};\n\n        // add subject\n        if(subject.indexOf('_:') === 0) {\n          triple.subject = {type: 'blank node', value: subject};\n        } else {\n          triple.subject = {type: 'IRI', value: subject};\n        }\n\n        // add predicate\n        if(predicate.indexOf('_:') === 0) {\n          triple.predicate = {type: 'blank node', value: predicate};\n        } else {\n          triple.predicate = {type: 'IRI', value: predicate};\n        }\n\n        // serialize XML literal\n        var value = object.value;\n        if(object.type === RDF_XML_LITERAL) {\n          // initialize XMLSerializer\n          if(!XMLSerializer) {\n            _defineXMLSerializer();\n          }\n          var serializer = new XMLSerializer();\n          value = '';\n          for(var x = 0; x < object.value.length; x++) {\n            if(object.value[x].nodeType === Node.ELEMENT_NODE) {\n              value += serializer.serializeToString(object.value[x]);\n            } else if(object.value[x].nodeType === Node.TEXT_NODE) {\n              value += object.value[x].nodeValue;\n            }\n          }\n        }\n\n        // add object\n        triple.object = {};\n\n        // object is an IRI\n        if(object.type === RDF_OBJECT) {\n          if(object.value.indexOf('_:') === 0) {\n            triple.object.type = 'blank node';\n          } else {\n            triple.object.type = 'IRI';\n          }\n        } else {\n          // object is a literal\n          triple.object.type = 'literal';\n          if(object.type === RDF_PLAIN_LITERAL) {\n            if(object.language) {\n              triple.object.datatype = RDF_LANGSTRING;\n              triple.object.language = object.language;\n            } else {\n              triple.object.datatype = XSD_STRING;\n            }\n          } else {\n            triple.object.datatype = object.type;\n          }\n        }\n        triple.object.value = value;\n\n        // add triple to dataset in default graph\n        dataset['@default'].push(triple);\n      }\n    }\n  }\n\n  return dataset;\n}\n\n// register the RDFa API RDF parser\njsonld.registerRDFParser('rdfa-api', _parseRdfaApiData);\n\n/**\n * Creates a new IdentifierIssuer. A IdentifierIssuer issues unique\n * identifiers, keeping track of any previously issued identifiers.\n *\n * @param prefix the prefix to use ('<prefix><counter>').\n */\nfunction IdentifierIssuer(prefix) {\n  this.prefix = prefix;\n  this.counter = 0;\n  this.existing = {};\n}\njsonld.IdentifierIssuer = IdentifierIssuer;\n// backwards-compability\njsonld.UniqueNamer = IdentifierIssuer;\n\n/**\n * Copies this IdentifierIssuer.\n *\n * @return a copy of this IdentifierIssuer.\n */\nIdentifierIssuer.prototype.clone = function() {\n  var copy = new IdentifierIssuer(this.prefix);\n  copy.counter = this.counter;\n  copy.existing = _clone(this.existing);\n  return copy;\n};\n\n/**\n * Gets the new identifier for the given old identifier, where if no old\n * identifier is given a new identifier will be generated.\n *\n * @param [old] the old identifier to get the new identifier for.\n *\n * @return the new identifier.\n */\nIdentifierIssuer.prototype.getId = function(old) {\n  // return existing old identifier\n  if(old && old in this.existing) {\n    return this.existing[old];\n  }\n\n  // get next identifier\n  var identifier = this.prefix + this.counter;\n  this.counter += 1;\n\n  // save mapping\n  if(old) {\n    this.existing[old] = identifier;\n  }\n\n  return identifier;\n};\n// alias\nIdentifierIssuer.prototype.getName = IdentifierIssuer.prototype.getName;\n\n/**\n * Returns true if the given old identifer has already been assigned a new\n * identifier.\n *\n * @param old the old identifier to check.\n *\n * @return true if the old identifier has been assigned a new identifier, false\n *   if not.\n */\nIdentifierIssuer.prototype.hasId = function(old) {\n  return (old in this.existing);\n};\n// alias\nIdentifierIssuer.prototype.isNamed = IdentifierIssuer.prototype.hasId;\n\n/**\n * A Permutator iterates over all possible permutations of the given array\n * of elements.\n *\n * @param list the array of elements to iterate over.\n */\nvar Permutator = function(list) {\n  // original array\n  this.list = list.sort();\n  // indicates whether there are more permutations\n  this.done = false;\n  // directional info for permutation algorithm\n  this.left = {};\n  for(var i = 0; i < list.length; ++i) {\n    this.left[list[i]] = true;\n  }\n};\n\n/**\n * Returns true if there is another permutation.\n *\n * @return true if there is another permutation, false if not.\n */\nPermutator.prototype.hasNext = function() {\n  return !this.done;\n};\n\n/**\n * Gets the next permutation. Call hasNext() to ensure there is another one\n * first.\n *\n * @return the next permutation.\n */\nPermutator.prototype.next = function() {\n  // copy current permutation\n  var rval = this.list.slice();\n\n  /* Calculate the next permutation using the Steinhaus-Johnson-Trotter\n   permutation algorithm. */\n\n  // get largest mobile element k\n  // (mobile: element is greater than the one it is looking at)\n  var k = null;\n  var pos = 0;\n  var length = this.list.length;\n  for(var i = 0; i < length; ++i) {\n    var element = this.list[i];\n    var left = this.left[element];\n    if((k === null || element > k) &&\n      ((left && i > 0 && element > this.list[i - 1]) ||\n      (!left && i < (length - 1) && element > this.list[i + 1]))) {\n      k = element;\n      pos = i;\n    }\n  }\n\n  // no more permutations\n  if(k === null) {\n    this.done = true;\n  } else {\n    // swap k and the element it is looking at\n    var swap = this.left[k] ? pos - 1 : pos + 1;\n    this.list[pos] = this.list[swap];\n    this.list[swap] = k;\n\n    // reverse the direction of all elements larger than k\n    for(var i = 0; i < length; ++i) {\n      if(this.list[i] > k) {\n        this.left[this.list[i]] = !this.left[this.list[i]];\n      }\n    }\n  }\n\n  return rval;\n};\n\n//////////////////////// DEFINE NORMALIZATION HASH API ////////////////////////\n\n/**\n * Creates a new NormalizeHash for use by the given normalization algorithm.\n *\n * @param algorithm the RDF Dataset Normalization algorithm to use:\n *          'URDNA2015' or 'URGNA2012'.\n */\nvar NormalizeHash = function(algorithm) {\n  if(!(this instanceof NormalizeHash)) {\n    return new NormalizeHash(algorithm);\n  }\n  if(['URDNA2015', 'URGNA2012'].indexOf(algorithm) === -1) {\n    throw new Error(\n      'Invalid RDF Dataset Normalization algorithm: ' + algorithm);\n  }\n  NormalizeHash._init.call(this, algorithm);\n};\nNormalizeHash.hashNQuads = function(algorithm, nquads) {\n  var md = new NormalizeHash(algorithm);\n  for(var i = 0; i < nquads.length; ++i) {\n    md.update(nquads[i]);\n  }\n  return md.digest();\n};\n\n// switch definition of NormalizeHash based on environment\n(function(_nodejs) {\n\nif(_nodejs) {\n  // define NormalizeHash using native crypto lib\n  var crypto = require('crypto');\n  NormalizeHash._init = function(algorithm) {\n    if(algorithm === 'URDNA2015') {\n      algorithm = 'sha256';\n    } else {\n      // assume URGNA2012\n      algorithm = 'sha1';\n    }\n    this.md = crypto.createHash(algorithm);\n  };\n  NormalizeHash.prototype.update = function(msg) {\n    return this.md.update(msg, 'utf8');\n  };\n  NormalizeHash.prototype.digest = function() {\n    return this.md.digest('hex');\n  };\n  return;\n}\n\n// define NormalizeHash using JavaScript\nNormalizeHash._init = function(algorithm) {\n  if(algorithm === 'URDNA2015') {\n    algorithm = new sha256.Algorithm();\n  } else {\n    // assume URGNA2012\n    algorithm = new sha1.Algorithm();\n  }\n  this.md = new MessageDigest(algorithm);\n};\nNormalizeHash.prototype.update = function(msg) {\n  return this.md.update(msg);\n};\nNormalizeHash.prototype.digest = function() {\n  return this.md.digest().toHex();\n};\n\n/////////////////////////// DEFINE MESSAGE DIGEST API /////////////////////////\n\n/**\n * Creates a new MessageDigest.\n *\n * @param algorithm the algorithm to use.\n */\nvar MessageDigest = function(algorithm) {\n  if(!(this instanceof MessageDigest)) {\n    return new MessageDigest(algorithm);\n  }\n\n  this._algorithm = algorithm;\n\n  // create shared padding as needed\n  if(!MessageDigest._padding ||\n    MessageDigest._padding.length < this._algorithm.blockSize) {\n    MessageDigest._padding = String.fromCharCode(128);\n    var c = String.fromCharCode(0x00);\n    var n = 64;\n    while(n > 0) {\n      if(n & 1) {\n        MessageDigest._padding += c;\n      }\n      n >>>= 1;\n      if(n > 0) {\n        c += c;\n      }\n    }\n  }\n\n  // start digest automatically for first time\n  this.start();\n};\n\n/**\n * Starts the digest.\n *\n * @return this digest object.\n */\nMessageDigest.prototype.start = function() {\n  // up to 56-bit message length for convenience\n  this.messageLength = 0;\n\n  // full message length\n  this.fullMessageLength = [];\n  var int32s = this._algorithm.messageLengthSize / 4;\n  for(var i = 0; i < int32s; ++i) {\n    this.fullMessageLength.push(0);\n  }\n\n  // input buffer\n  this._input = new MessageDigest.ByteBuffer();\n\n  // get starting state\n  this.state = this._algorithm.start();\n\n  return this;\n};\n\n/**\n * Updates the digest with the given message input. The input must be\n * a string of characters.\n *\n * @param msg the message input to update with (ByteBuffer or string).\n *\n * @return this digest object.\n */\nMessageDigest.prototype.update = function(msg) {\n  // encode message as a UTF-8 encoded binary string\n  msg = new MessageDigest.ByteBuffer(unescape(encodeURIComponent(msg)));\n\n  // update message length\n  this.messageLength += msg.length();\n  var len = msg.length();\n  len = [(len / 0x100000000) >>> 0, len >>> 0];\n  for(var i = this.fullMessageLength.length - 1; i >= 0; --i) {\n    this.fullMessageLength[i] += len[1];\n    len[1] = len[0] + ((this.fullMessageLength[i] / 0x100000000) >>> 0);\n    this.fullMessageLength[i] = this.fullMessageLength[i] >>> 0;\n    len[0] = ((len[1] / 0x100000000) >>> 0);\n  }\n\n  // add bytes to input buffer\n  this._input.putBytes(msg.bytes());\n\n  // digest blocks\n  while(this._input.length() >= this._algorithm.blockSize) {\n    this.state = this._algorithm.digest(this.state, this._input);\n  }\n\n  // compact input buffer every 2K or if empty\n  if(this._input.read > 2048 || this._input.length() === 0) {\n    this._input.compact();\n  }\n\n  return this;\n};\n\n/**\n * Produces the digest.\n *\n * @return a byte buffer containing the digest value.\n */\nMessageDigest.prototype.digest = function() {\n  /* Note: Here we copy the remaining bytes in the input buffer and add the\n  appropriate padding. Then we do the final update on a copy of the state so\n  that if the user wants to get intermediate digests they can do so. */\n\n  /* Determine the number of bytes that must be added to the message to\n  ensure its length is appropriately congruent. In other words, the data to\n  be digested must be a multiple of `blockSize`. This data includes the\n  message, some padding, and the length of the message. Since the length of\n  the message will be encoded as `messageLengthSize` bytes, that means that\n  the last segment of the data must have `blockSize` - `messageLengthSize`\n  bytes of message and padding. Therefore, the length of the message plus the\n  padding must be congruent to X mod `blockSize` because\n  `blockSize` - `messageLengthSize` = X.\n\n  For example, SHA-1 is congruent to 448 mod 512 and SHA-512 is congruent to\n  896 mod 1024. SHA-1 uses a `blockSize` of 64 bytes (512 bits) and a\n  `messageLengthSize` of 8 bytes (64 bits). SHA-512 uses a `blockSize` of\n  128 bytes (1024 bits) and a `messageLengthSize` of 16 bytes (128 bits).\n\n  In order to fill up the message length it must be filled with padding that\n  begins with 1 bit followed by all 0 bits. Padding must *always* be present,\n  so if the message length is already congruent, then `blockSize` padding bits\n  must be added. */\n\n  // create final block\n  var finalBlock = new MessageDigest.ByteBuffer();\n  finalBlock.putBytes(this._input.bytes());\n\n  // compute remaining size to be digested (include message length size)\n  var remaining = (\n    this.fullMessageLength[this.fullMessageLength.length - 1] +\n    this._algorithm.messageLengthSize);\n\n  // add padding for overflow blockSize - overflow\n  // _padding starts with 1 byte with first bit is set (byte value 128), then\n  // there may be up to (blockSize - 1) other pad bytes\n  var overflow = remaining & (this._algorithm.blockSize - 1);\n  finalBlock.putBytes(MessageDigest._padding.substr(\n    0, this._algorithm.blockSize - overflow));\n\n  // serialize message length in bits in big-endian order; since length\n  // is stored in bytes we multiply by 8 (left shift by 3 and merge in\n  // remainder from )\n  var messageLength = new MessageDigest.ByteBuffer();\n  for(var i = 0; i < this.fullMessageLength.length; ++i) {\n    messageLength.putInt32((this.fullMessageLength[i] << 3) |\n      (this.fullMessageLength[i + 1] >>> 28));\n  }\n\n  // write the length of the message (algorithm-specific)\n  this._algorithm.writeMessageLength(finalBlock, messageLength);\n\n  // digest final block\n  var state = this._algorithm.digest(this.state.copy(), finalBlock);\n\n  // write state to buffer\n  var rval = new MessageDigest.ByteBuffer();\n  state.write(rval);\n  return rval;\n};\n\n/**\n * Creates a simple byte buffer for message digest operations.\n *\n * @param data the data to put in the buffer.\n */\nMessageDigest.ByteBuffer = function(data) {\n  if(typeof data === 'string') {\n    this.data = data;\n  } else {\n    this.data = '';\n  }\n  this.read = 0;\n};\n\n/**\n * Puts a 32-bit integer into this buffer in big-endian order.\n *\n * @param i the 32-bit integer.\n */\nMessageDigest.ByteBuffer.prototype.putInt32 = function(i) {\n  this.data += (\n    String.fromCharCode(i >> 24 & 0xFF) +\n    String.fromCharCode(i >> 16 & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i & 0xFF));\n};\n\n/**\n * Gets a 32-bit integer from this buffer in big-endian order and\n * advances the read pointer by 4.\n *\n * @return the word.\n */\nMessageDigest.ByteBuffer.prototype.getInt32 = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) << 24 ^\n    this.data.charCodeAt(this.read + 1) << 16 ^\n    this.data.charCodeAt(this.read + 2) << 8 ^\n    this.data.charCodeAt(this.read + 3));\n  this.read += 4;\n  return rval;\n};\n\n/**\n * Puts the given bytes into this buffer.\n *\n * @param bytes the bytes as a binary-encoded string.\n */\nMessageDigest.ByteBuffer.prototype.putBytes = function(bytes) {\n  this.data += bytes;\n};\n\n/**\n * Gets the bytes in this buffer.\n *\n * @return a string full of UTF-8 encoded characters.\n */\nMessageDigest.ByteBuffer.prototype.bytes = function() {\n  return this.data.slice(this.read);\n};\n\n/**\n * Gets the number of bytes in this buffer.\n *\n * @return the number of bytes in this buffer.\n */\nMessageDigest.ByteBuffer.prototype.length = function() {\n  return this.data.length - this.read;\n};\n\n/**\n * Compacts this buffer.\n */\nMessageDigest.ByteBuffer.prototype.compact = function() {\n  this.data = this.data.slice(this.read);\n  this.read = 0;\n};\n\n/**\n * Converts this buffer to a hexadecimal string.\n *\n * @return a hexadecimal string.\n */\nMessageDigest.ByteBuffer.prototype.toHex = function() {\n  var rval = '';\n  for(var i = this.read; i < this.data.length; ++i) {\n    var b = this.data.charCodeAt(i);\n    if(b < 16) {\n      rval += '0';\n    }\n    rval += b.toString(16);\n  }\n  return rval;\n};\n\n///////////////////////////// DEFINE SHA-1 ALGORITHM //////////////////////////\n\nvar sha1 = {\n  // used for word storage\n  _w: null\n};\n\nsha1.Algorithm = function() {\n  this.name = 'sha1',\n  this.blockSize = 64;\n  this.digestLength = 20;\n  this.messageLengthSize = 8;\n};\n\nsha1.Algorithm.prototype.start = function() {\n  if(!sha1._w) {\n    sha1._w = new Array(80);\n  }\n  return sha1._createState();\n};\n\nsha1.Algorithm.prototype.writeMessageLength = function(\n  finalBlock, messageLength) {\n  // message length is in bits and in big-endian order; simply append\n  finalBlock.putBytes(messageLength.bytes());\n};\n\nsha1.Algorithm.prototype.digest = function(s, input) {\n  // consume 512 bit (64 byte) chunks\n  var t, a, b, c, d, e, f, i;\n  var len = input.length();\n  var _w = sha1._w;\n  while(len >= 64) {\n    // initialize hash value for this chunk\n    a = s.h0;\n    b = s.h1;\n    c = s.h2;\n    d = s.h3;\n    e = s.h4;\n\n    // the _w array will be populated with sixteen 32-bit big-endian words\n    // and then extended into 80 32-bit words according to SHA-1 algorithm\n    // and for 32-79 using Max Locktyukhin's optimization\n\n    // round 1\n    for(i = 0; i < 16; ++i) {\n      t = input.getInt32();\n      _w[i] = t;\n      f = d ^ (b & (c ^ d));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    for(; i < 20; ++i) {\n      t = (_w[i - 3] ^ _w[i - 8] ^ _w[i - 14] ^ _w[i - 16]);\n      t = (t << 1) | (t >>> 31);\n      _w[i] = t;\n      f = d ^ (b & (c ^ d));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    // round 2\n    for(; i < 32; ++i) {\n      t = (_w[i - 3] ^ _w[i - 8] ^ _w[i - 14] ^ _w[i - 16]);\n      t = (t << 1) | (t >>> 31);\n      _w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    for(; i < 40; ++i) {\n      t = (_w[i - 6] ^ _w[i - 16] ^ _w[i - 28] ^ _w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      _w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    // round 3\n    for(; i < 60; ++i) {\n      t = (_w[i - 6] ^ _w[i - 16] ^ _w[i - 28] ^ _w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      _w[i] = t;\n      f = (b & c) | (d & (b ^ c));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x8F1BBCDC + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    // round 4\n    for(; i < 80; ++i) {\n      t = (_w[i - 6] ^ _w[i - 16] ^ _w[i - 28] ^ _w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      _w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0xCA62C1D6 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n\n    // update hash state\n    s.h0 = (s.h0 + a) | 0;\n    s.h1 = (s.h1 + b) | 0;\n    s.h2 = (s.h2 + c) | 0;\n    s.h3 = (s.h3 + d) | 0;\n    s.h4 = (s.h4 + e) | 0;\n\n    len -= 64;\n  }\n\n  return s;\n};\n\nsha1._createState = function() {\n  var state = {\n    h0: 0x67452301,\n    h1: 0xEFCDAB89,\n    h2: 0x98BADCFE,\n    h3: 0x10325476,\n    h4: 0xC3D2E1F0\n  };\n  state.copy = function() {\n    var rval = sha1._createState();\n    rval.h0 = state.h0;\n    rval.h1 = state.h1;\n    rval.h2 = state.h2;\n    rval.h3 = state.h3;\n    rval.h4 = state.h4;\n    return rval;\n  };\n  state.write = function(buffer) {\n    buffer.putInt32(state.h0);\n    buffer.putInt32(state.h1);\n    buffer.putInt32(state.h2);\n    buffer.putInt32(state.h3);\n    buffer.putInt32(state.h4);\n  };\n  return state;\n};\n\n//////////////////////////// DEFINE SHA-256 ALGORITHM /////////////////////////\n\nvar sha256 = {\n  // shared state\n  _k: null,\n  _w: null\n};\n\nsha256.Algorithm = function() {\n  this.name = 'sha256',\n  this.blockSize = 64;\n  this.digestLength = 32;\n  this.messageLengthSize = 8;\n};\n\nsha256.Algorithm.prototype.start = function() {\n  if(!sha256._k) {\n    sha256._init();\n  }\n  return sha256._createState();\n};\n\nsha256.Algorithm.prototype.writeMessageLength = function(\n  finalBlock, messageLength) {\n  // message length is in bits and in big-endian order; simply append\n  finalBlock.putBytes(messageLength.bytes());\n};\n\nsha256.Algorithm.prototype.digest = function(s, input) {\n  // consume 512 bit (64 byte) chunks\n  var t1, t2, s0, s1, ch, maj, i, a, b, c, d, e, f, g, h;\n  var len = input.length();\n  var _k = sha256._k;\n  var _w = sha256._w;\n  while(len >= 64) {\n    // the w array will be populated with sixteen 32-bit big-endian words\n    // and then extended into 64 32-bit words according to SHA-256\n    for(i = 0; i < 16; ++i) {\n      _w[i] = input.getInt32();\n    }\n    for(; i < 64; ++i) {\n      // XOR word 2 words ago rot right 17, rot right 19, shft right 10\n      t1 = _w[i - 2];\n      t1 =\n        ((t1 >>> 17) | (t1 << 15)) ^\n        ((t1 >>> 19) | (t1 << 13)) ^\n        (t1 >>> 10);\n      // XOR word 15 words ago rot right 7, rot right 18, shft right 3\n      t2 = _w[i - 15];\n      t2 =\n        ((t2 >>> 7) | (t2 << 25)) ^\n        ((t2 >>> 18) | (t2 << 14)) ^\n        (t2 >>> 3);\n      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^32\n      _w[i] = (t1 + _w[i - 7] + t2 + _w[i - 16]) | 0;\n    }\n\n    // initialize hash value for this chunk\n    a = s.h0;\n    b = s.h1;\n    c = s.h2;\n    d = s.h3;\n    e = s.h4;\n    f = s.h5;\n    g = s.h6;\n    h = s.h7;\n\n    // round function\n    for(i = 0; i < 64; ++i) {\n      // Sum1(e)\n      s1 =\n        ((e >>> 6) | (e << 26)) ^\n        ((e >>> 11) | (e << 21)) ^\n        ((e >>> 25) | (e << 7));\n      // Ch(e, f, g) (optimized the same way as SHA-1)\n      ch = g ^ (e & (f ^ g));\n      // Sum0(a)\n      s0 =\n        ((a >>> 2) | (a << 30)) ^\n        ((a >>> 13) | (a << 19)) ^\n        ((a >>> 22) | (a << 10));\n      // Maj(a, b, c) (optimized the same way as SHA-1)\n      maj = (a & b) | (c & (a ^ b));\n\n      // main algorithm\n      t1 = h + s1 + ch + _k[i] + _w[i];\n      t2 = s0 + maj;\n      h = g;\n      g = f;\n      f = e;\n      e = (d + t1) | 0;\n      d = c;\n      c = b;\n      b = a;\n      a = (t1 + t2) | 0;\n    }\n\n    // update hash state\n    s.h0 = (s.h0 + a) | 0;\n    s.h1 = (s.h1 + b) | 0;\n    s.h2 = (s.h2 + c) | 0;\n    s.h3 = (s.h3 + d) | 0;\n    s.h4 = (s.h4 + e) | 0;\n    s.h5 = (s.h5 + f) | 0;\n    s.h6 = (s.h6 + g) | 0;\n    s.h7 = (s.h7 + h) | 0;\n    len -= 64;\n  }\n\n  return s;\n};\n\nsha256._createState = function() {\n  var state = {\n    h0: 0x6A09E667,\n    h1: 0xBB67AE85,\n    h2: 0x3C6EF372,\n    h3: 0xA54FF53A,\n    h4: 0x510E527F,\n    h5: 0x9B05688C,\n    h6: 0x1F83D9AB,\n    h7: 0x5BE0CD19\n  };\n  state.copy = function() {\n    var rval = sha256._createState();\n    rval.h0 = state.h0;\n    rval.h1 = state.h1;\n    rval.h2 = state.h2;\n    rval.h3 = state.h3;\n    rval.h4 = state.h4;\n    rval.h5 = state.h5;\n    rval.h6 = state.h6;\n    rval.h7 = state.h7;\n    return rval;\n  };\n  state.write = function(buffer) {\n    buffer.putInt32(state.h0);\n    buffer.putInt32(state.h1);\n    buffer.putInt32(state.h2);\n    buffer.putInt32(state.h3);\n    buffer.putInt32(state.h4);\n    buffer.putInt32(state.h5);\n    buffer.putInt32(state.h6);\n    buffer.putInt32(state.h7);\n  };\n  return state;\n};\n\nsha256._init = function() {\n  // create K table for SHA-256\n  sha256._k = [\n    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,\n    0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,\n    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,\n    0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,\n    0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,\n    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,\n    0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,\n    0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,\n    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2];\n\n  // used for word storage\n  sha256._w = new Array(64);\n};\n\n})(_nodejs); // end definition of NormalizeHash\n\nif(!XMLSerializer) {\n\nvar _defineXMLSerializer = function() {\n  XMLSerializer = require('xmldom').XMLSerializer;\n};\n\n} // end _defineXMLSerializer\n\n// define URL parser\n// parseUri 1.2.2\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\n// with local jsonld.js modifications\njsonld.url = {};\njsonld.url.parsers = {\n  simple: {\n    // RFC 3986 basic parts\n    keys: ['href','scheme','authority','path','query','fragment'],\n    regex: /^(?:([^:\\/?#]+):)?(?:\\/\\/([^\\/?#]*))?([^?#]*)(?:\\?([^#]*))?(?:#(.*))?/\n  },\n  full: {\n    keys: ['href','protocol','scheme','authority','auth','user','password','hostname','port','path','directory','file','query','fragment'],\n    regex: /^(([^:\\/?#]+):)?(?:\\/\\/((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?))?(?:(((?:[^?#\\/]*\\/)*)([^?#]*))(?:\\?([^#]*))?(?:#(.*))?)/\n  }\n};\njsonld.url.parse = function(str, parser) {\n  var parsed = {};\n  var o = jsonld.url.parsers[parser || 'full'];\n  var m = o.regex.exec(str);\n  var i = o.keys.length;\n  while(i--) {\n    parsed[o.keys[i]] = (m[i] === undefined) ? null : m[i];\n  }\n  parsed.normalizedPath = _removeDotSegments(parsed.path, !!parsed.authority);\n  return parsed;\n};\n\n/**\n * Removes dot segments from a URL path.\n *\n * @param path the path to remove dot segments from.\n * @param hasAuthority true if the URL has an authority, false if not.\n */\nfunction _removeDotSegments(path, hasAuthority) {\n  var rval = '';\n\n  if(path.indexOf('/') === 0) {\n    rval = '/';\n  }\n\n  // RFC 3986 5.2.4 (reworked)\n  var input = path.split('/');\n  var output = [];\n  while(input.length > 0) {\n    if(input[0] === '.' || (input[0] === '' && input.length > 1)) {\n      input.shift();\n      continue;\n    }\n    if(input[0] === '..') {\n      input.shift();\n      if(hasAuthority ||\n        (output.length > 0 && output[output.length - 1] !== '..')) {\n        output.pop();\n      } else {\n        // leading relative URL '..'\n        output.push('..');\n      }\n      continue;\n    }\n    output.push(input.shift());\n  }\n\n  return rval + output.join('/');\n}\n\nif(_nodejs) {\n  // use node document loader by default\n  jsonld.useDocumentLoader('node');\n} else if(typeof XMLHttpRequest !== 'undefined') {\n  // use xhr document loader by default\n  jsonld.useDocumentLoader('xhr');\n}\n\nif(_nodejs) {\n  jsonld.use = function(extension) {\n    switch(extension) {\n      // TODO: Deprecated as of 0.4.0. Remove at some point.\n      case 'request':\n        // use node JSON-LD request extension\n        jsonld.request = require('jsonld-request');\n        break;\n      default:\n        throw new JsonLdError(\n          'Unknown extension.',\n          'jsonld.UnknownExtension', {extension: extension});\n    }\n  };\n\n  // expose version\n  var _module = {exports: {}, filename: __dirname};\n  require('pkginfo')(_module, 'version');\n  jsonld.version = _module.exports.version;\n}\n\n// end of jsonld API factory\nreturn jsonld;\n};\n\n// external APIs:\n\n// used to generate a new jsonld API instance\nvar factory = function() {\n  return wrapper(function() {\n    return factory();\n  });\n};\n\nif(!_nodejs && (typeof define === 'function' && define.amd)) {\n  // export AMD API\n  define([], function() {\n    // now that module is defined, wrap main jsonld API instance\n    wrapper(factory);\n    return factory;\n  });\n} else {\n  // wrap the main jsonld API instance\n  wrapper(factory);\n\n  if(typeof require === 'function' &&\n    typeof module !== 'undefined' && module.exports) {\n    // export CommonJS/nodejs API\n    module.exports = factory;\n  }\n\n  if(_browser) {\n    // export simple browser API\n    if(typeof jsonld === 'undefined') {\n      jsonld = jsonldjs = factory;\n    } else {\n      jsonldjs = factory;\n    }\n  }\n}\n\nreturn factory;\n\n})();\n","/home/travis/build/npmtest/node-npmtest-jsonld/node_modules/jsonld/browser/ignore.js":"// Ignore module for browserify (see package.json)"}